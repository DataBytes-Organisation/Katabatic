{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWzSg1kf4Twk",
        "outputId": "853e659a-377b-42c1-c74e-9116307e6bcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "─── DATASET SANITY CHECK ───\n",
            "Shape: 12960 rows × 9 cols\n",
            "\n",
            "Column dtypes:\n",
            "object    9 \n",
            "\n",
            "No missing values.\n",
            "\n",
            "Target distribution (class):\n",
            "class\n",
            "not_recom     33.33%\\n\n",
            "priority      32.92%\\n\n",
            "spec_prior     31.2%\\n\n",
            "very_recom     2.53%\\n\n",
            "recommend      0.02%\\n\n",
            "Name: proportion, dtype: object\n",
            "Suggested numeric (interval) cols (5): ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
            "Suggested categorical cols (8): ['parents', 'has_nurs', 'form', 'children', 'housing', 'finance', 'social', 'health']\n",
            "\n",
            "──────────────────────────────\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import List, Optional\n",
        "\n",
        "def dataset_sanity_check(\n",
        "    df: pd.DataFrame,\n",
        "    target_col: str,\n",
        "    interval_cols: Optional[List[str]] = None,\n",
        "    max_unique_for_cat: int = 50\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Prints a summary of df:\n",
        "     - shape, dtype counts\n",
        "     - missing values per column\n",
        "     - target distribution\n",
        "     - suggested interval vs categorical splits\n",
        "    Args:\n",
        "      df: raw DataFrame\n",
        "      target_col: name of the target column\n",
        "      interval_cols: optional list of numeric feature names;\n",
        "                     if None, they'll be inferred by dtype and unique count\n",
        "      max_unique_for_cat: if dtype==object but unique<=this, treat as cat\n",
        "    \"\"\"\n",
        "    print(\"─── DATASET SANITY CHECK ───\")\n",
        "    print(f\"Shape: {df.shape[0]} rows × {df.shape[1]} cols\")\n",
        "    print(\"\\nColumn dtypes:\")\n",
        "    print(df.dtypes.value_counts().to_string(), \"\\n\")\n",
        "\n",
        "    # Missing\n",
        "    missing = df.isna().sum()\n",
        "    if missing.any():\n",
        "        print(\"Missing values:\")\n",
        "        print(missing[missing>0].sort_values(), \"\\n\")\n",
        "    else:\n",
        "        print(\"No missing values.\\n\")\n",
        "\n",
        "    # Target distribution\n",
        "    if target_col not in df.columns:\n",
        "        raise ValueError(f\"Target column '{target_col}' not found in DataFrame!\")\n",
        "    print(f\"Target distribution ({target_col}):\")\n",
        "    print(df[target_col].value_counts(normalize=True).mul(100).round(2).astype(str) + \"%\\n\")\n",
        "\n",
        "    # Feature type suggestions\n",
        "    if interval_cols is None:\n",
        "        # infer numeric by dtype\n",
        "        num = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        # treat low‐card object cols as categorical too\n",
        "        obj = [\n",
        "            c for c in df.select_dtypes(include=[\"object\"]).columns\n",
        "            if df[c].nunique() <= max_unique_for_cat and c != target_col\n",
        "        ]\n",
        "        interval_cols = num\n",
        "        cat_cols = [c for c in df.columns if c not in interval_cols + [target_col]]\n",
        "    else:\n",
        "        # user‐provided\n",
        "        cat_cols = [c for c in df.columns if c not in interval_cols + [target_col]]\n",
        "\n",
        "    print(f\"Suggested numeric (interval) cols ({len(interval_cols)}): {interval_cols}\")\n",
        "    print(f\"Suggested categorical cols ({len(cat_cols)}): {cat_cols}\\n\")\n",
        "\n",
        "    # Warn about very small or very large datasets\n",
        "    if df.shape[0] < 100:\n",
        "        print(\"⚠️  Warning: fewer than 100 samples—GANs may overfit or collapse.\")\n",
        "    elif df.shape[0] > 200_000:\n",
        "        print(\"⚠️  Warning: very large dataset—training may be slow.\")\n",
        "\n",
        "    print(\"──────────────────────────────\\n\")\n",
        "\n",
        "\n",
        "# ─── Example usage ───\n",
        "if __name__ == \"__main__\":\n",
        "    # Load any dataset\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Katabatic/Data/Nursery/nursery.csv\")\n",
        "\n",
        "    # Run the check\n",
        "    dataset_sanity_check(\n",
        "      df,\n",
        "      target_col=\"class\",\n",
        "      # you can also explicitly tell it which interval cols to use:\n",
        "      interval_cols=[\"age\",\"education-num\",\"capital-gain\",\"capital-loss\",\"hours-per-week\"]\n",
        "    )\n"
      ]
    }
  ]
}