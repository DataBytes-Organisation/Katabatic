{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ctgan_adapter import CtganAdapter\n",
    "from ctgan_benchmark import evaluate_ctgan, print_evaluation_results\n",
    "from ctgan_utils import preprocess_data, get_tstr_results\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load configuration\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(\"# Load configuration\")\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1. Load and prepare the dataset\n",
      "Columns in dataset: ['Buying', 'Maint', 'Doors', 'Persons', 'Lug_boot', 'Safety', 'Class']\n",
      "Dataset shape: (1728, 7)\n",
      "  Buying  Maint Doors Persons Lug_boot Safety  Class\n",
      "0  vhigh  vhigh     2       2    small    low  unacc\n",
      "1  vhigh  vhigh     2       2    small    med  unacc\n",
      "2  vhigh  vhigh     2       2    small   high  unacc\n",
      "3  vhigh  vhigh     2       2      med    low  unacc\n",
      "4  vhigh  vhigh     2       2      med    med  unacc\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare the dataset\n",
    "print(\"# 1. Load and prepare the dataset\")\n",
    "data_raw = pd.read_csv(\"car.csv\")\n",
    "print(f\"Columns in dataset: {data_raw.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {data_raw.shape}\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:14:56,024 - INFO - Converted Buying to category type (has 4 unique values)\n",
      "2025-03-30 16:14:56,026 - INFO - Converted Maint to category type (has 4 unique values)\n",
      "2025-03-30 16:14:56,029 - INFO - Converted Doors to category type (has 4 unique values)\n",
      "2025-03-30 16:14:56,031 - INFO - Converted Persons to category type (has 3 unique values)\n",
      "2025-03-30 16:14:56,033 - INFO - Converted Lug_boot to category type (has 3 unique values)\n",
      "2025-03-30 16:14:56,034 - INFO - Converted Safety to category type (has 3 unique values)\n",
      "2025-03-30 16:14:56,037 - INFO - Converted Class to category type (has 4 unique values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 2. Preprocess data and detect categorical columns\n",
      "Detected categorical columns: ['Buying', 'Maint', 'Doors', 'Persons', 'Lug_boot', 'Safety', 'Class']\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocess data and detect categorical columns\n",
    "print(\"\\n# 2. Preprocess data and detect categorical columns\")\n",
    "data, categorical_columns = preprocess_data(data_raw)\n",
    "print(f\"Detected categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3. Define the target column for this dataset\n",
      "Target column: Class\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the target column for this dataset\n",
    "print(\"\\n# 3. Define the target column for this dataset\")\n",
    "target_column = \"Class\"\n",
    "print(f\"Target column: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 4. Split the data into features and target\n",
      "Features shape: (1728, 6)\n",
      "Target shape: (1728,)\n",
      "Target distribution:\n",
      "Class\n",
      "unacc    1210\n",
      "acc       384\n",
      "good       69\n",
      "vgood      65\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Split the data into features and target\n",
    "print(\"\\n# 4. Split the data into features and target\")\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 5. Initialize and train CTGAN\n",
      "Training CTGAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 1/300 [00:03<19:20,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss D: 25.1800, Loss G: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|█         | 31/300 [01:59<17:07,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss D: 0.2164, Loss G: 0.0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 61/300 [04:02<16:41,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss D: 0.1760, Loss G: 0.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|███       | 91/300 [05:46<11:10,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Loss D: 0.5814, Loss G: -0.0236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|████      | 121/300 [07:12<08:29,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, Loss D: 0.4691, Loss G: -0.8783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|█████     | 151/300 [08:37<07:05,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, Loss D: 0.3995, Loss G: -0.7371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|██████    | 181/300 [10:02<05:36,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180, Loss D: 0.2164, Loss G: -0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|███████   | 211/300 [11:27<04:09,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210, Loss D: 0.2455, Loss G: -0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|████████  | 241/300 [12:53<02:51,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240, Loss D: 0.1894, Loss G: -0.6769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|█████████ | 271/300 [14:17<01:20,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270, Loss D: 0.0132, Loss G: -0.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [15:40<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize and train CTGAN\n",
    "print(\"\\n# 5. Initialize and train CTGAN\")\n",
    "ctgan = CtganAdapter(**config[\"ctgan_params\"])\n",
    "print(\"Training CTGAN model...\")\n",
    "ctgan.fit(X, y)\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 6. Generate synthetic data\n",
      "Generating 1000 synthetic samples...\n",
      "Generated 1000 synthetic samples\n",
      "Synthetic data head:\n",
      "  Buying  Maint  Doors Persons Lug_boot Safety  Class\n",
      "0   high    med  5more    more      med    med    acc\n",
      "1    low   high      2       2      big    med  unacc\n",
      "2  vhigh    low      2       2      big   high  unacc\n",
      "3  vhigh  vhigh  5more       2      med   high    acc\n",
      "4    low  vhigh      3       2      med    low  unacc\n"
     ]
    }
   ],
   "source": [
    "# 6. Generate synthetic data\n",
    "print(\"\\n# 6. Generate synthetic data\")\n",
    "n_samples = 1000  \n",
    "print(f\"Generating {n_samples} synthetic samples...\")\n",
    "synthetic_data = ctgan.generate(n_samples)\n",
    "print(f\"Generated {len(synthetic_data)} synthetic samples\")\n",
    "print(\"Synthetic data head:\")\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 16:44:34,514 - WARNING - No numerical columns found for likelihood fitness evaluation\n",
      "2025-03-30 16:44:34,542 - INFO - Encoded categorical target with mapping: {'acc': 0, 'good': 1, 'unacc': 2, 'vgood': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 7. Evaluate quality using TSTR and other metrics\n",
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:44:36] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-03-30 16:44:37,108 - INFO - Encoded categorical targets with mapping: {'acc': 0, 'good': 1, 'unacc': 2, 'vgood': 3}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:44:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-03-30 16:44:42,199 - INFO - CTGAN Evaluation Results:\n",
      "2025-03-30 16:44:42,201 - INFO - \n",
      "Likelihood Fitness: Not applicable for fully categorical data\n",
      "2025-03-30 16:44:42,201 - INFO - \n",
      "Statistical Similarity Metrics:\n",
      "2025-03-30 16:44:42,202 - INFO -   - Jensen-Shannon Divergence Mean (Categorical): 0.0335\n",
      "2025-03-30 16:44:42,202 - INFO - \n",
      "Machine Learning Efficacy Metrics on Real Data:\n",
      "2025-03-30 16:44:42,203 - INFO -   LogisticRegression:\n",
      "2025-03-30 16:44:42,203 - INFO -     - Accuracy: 0.9162\n",
      "2025-03-30 16:44:42,204 - INFO -     - F1: 0.9163\n",
      "2025-03-30 16:44:42,205 - INFO -   RandomForest:\n",
      "2025-03-30 16:44:42,205 - INFO -     - Accuracy: 0.9682\n",
      "2025-03-30 16:44:42,205 - INFO -     - F1: 0.9696\n",
      "2025-03-30 16:44:42,205 - INFO -   MLP:\n",
      "2025-03-30 16:44:42,207 - INFO -     - Accuracy: 0.9827\n",
      "2025-03-30 16:44:42,207 - INFO -     - F1: 0.9832\n",
      "2025-03-30 16:44:42,208 - INFO -   XGBoost:\n",
      "2025-03-30 16:44:42,208 - INFO -     - Accuracy: 0.9798\n",
      "2025-03-30 16:44:42,209 - INFO -     - F1: 0.9818\n",
      "2025-03-30 16:44:42,209 - INFO - \n",
      "Machine Learning Utility using TSTR Approach:\n",
      "2025-03-30 16:44:42,210 - INFO -   LogisticRegression:\n",
      "2025-03-30 16:44:42,210 - INFO -     - Accuracy: 0.7853\n",
      "2025-03-30 16:44:42,211 - INFO -     - F1: 0.7413\n",
      "2025-03-30 16:44:42,211 - INFO -   RandomForest:\n",
      "2025-03-30 16:44:42,212 - INFO -     - Accuracy: 0.7431\n",
      "2025-03-30 16:44:42,212 - INFO -     - F1: 0.7078\n",
      "2025-03-30 16:44:42,213 - INFO -   MLP:\n",
      "2025-03-30 16:44:42,213 - INFO -     - Accuracy: 0.7216\n",
      "2025-03-30 16:44:42,214 - INFO -     - F1: 0.6950\n",
      "2025-03-30 16:44:42,214 - INFO -   XGBoost:\n",
      "2025-03-30 16:44:42,215 - INFO -     - Accuracy: 0.7297\n",
      "2025-03-30 16:44:42,215 - INFO -     - F1: 0.7041\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate quality using TSTR and other metrics\n",
    "print(\"\\n# 7. Evaluate quality using TSTR and other metrics\")\n",
    "print(\"Running evaluation...\")\n",
    "evaluation_results = evaluate_ctgan(data, synthetic_data, target_column=target_column)\n",
    "print_evaluation_results(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 8. TSTR Performance Results\n",
      "                    Accuracy        F1\n",
      "LogisticRegression  0.785301  0.741253\n",
      "RandomForest        0.743056  0.707837\n",
      "MLP                 0.721644  0.695015\n",
      "XGBoost             0.729745  0.704093\n"
     ]
    }
   ],
   "source": [
    "# 8. Extract and display TSTR results specifically\n",
    "print(\"\\n# 8. TSTR Performance Results\")\n",
    "tstr_results = get_tstr_results(evaluation_results)\n",
    "if tstr_results is not None:\n",
    "    print(tstr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 9. Save synthetic data\n",
      "Synthetic data saved to bank_loan_synthetic.csv\n",
      "\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9. Save the synthetic data\n",
    "print(\"\\n# 9. Save synthetic data\")\n",
    "output_path = \"bank_loan_synthetic.csv\"\n",
    "synthetic_data.to_csv(output_path, index=False)\n",
    "print(f\"Synthetic data saved to {output_path}\")\n",
    "\n",
    "print(\"\\nTest completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit378",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
