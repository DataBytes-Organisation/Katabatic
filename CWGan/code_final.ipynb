{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8d824f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "游대 Repeat 1/3\n",
      "\n",
      "游댃 Fold 1/2\n",
      "\n",
      "游늵 TSTR Accuracy:\n",
      "LogReg: 0.7588\n",
      "MLP: 0.7528\n",
      "RF: 0.7758\n",
      "XGBT: 0.7722\n",
      "\n",
      "游댧 JSD: 0.5025 | WD: 1.2743\n",
      "\n",
      "游댃 Fold 2/2\n",
      "\n",
      "游늵 TSTR Accuracy:\n",
      "LogReg: 0.7656\n",
      "MLP: 0.7702\n",
      "RF: 0.7782\n",
      "XGBT: 0.7784\n",
      "\n",
      "游댧 JSD: 0.5116 | WD: 1.4590\n",
      "\n",
      "游대 Repeat 2/3\n",
      "\n",
      "游댃 Fold 1/2\n",
      "\n",
      "游늵 TSTR Accuracy:\n",
      "LogReg: 0.7273\n",
      "MLP: 0.6779\n",
      "RF: 0.7786\n",
      "XGBT: 0.7743\n",
      "\n",
      "游댧 JSD: 0.5047 | WD: 1.4928\n",
      "\n",
      "游댃 Fold 2/2\n",
      "\n",
      "游늵 TSTR Accuracy:\n",
      "LogReg: 0.7028\n",
      "MLP: 0.7229\n",
      "RF: 0.7424\n",
      "XGBT: 0.7180\n",
      "\n",
      "游댧 JSD: 0.5056 | WD: 1.3454\n",
      "\n",
      "游대 Repeat 3/3\n",
      "\n",
      "游댃 Fold 1/2\n",
      "\n",
      "游늵 TSTR Accuracy:\n",
      "LogReg: 0.6712\n",
      "MLP: 0.6716\n",
      "RF: 0.7740\n",
      "XGBT: 0.7140\n",
      "\n",
      "游댧 JSD: 0.5030 | WD: 1.2092\n",
      "\n",
      "游댃 Fold 2/2\n",
      "\n",
      "游늵 TSTR Accuracy:\n",
      "LogReg: 0.6829\n",
      "MLP: 0.6840\n",
      "RF: 0.7758\n",
      "XGBT: 0.7252\n",
      "\n",
      "游댧 JSD: 0.5002 | WD: 1.3722\n",
      "\n",
      "游늳 FINAL AVERAGE RESULTS ACROSS 3x2 CV:\n",
      "LogReg TSTR Accuracy: 0.7181\n",
      "MLP TSTR Accuracy: 0.7132\n",
      "RF TSTR Accuracy: 0.7708\n",
      "XGBT TSTR Accuracy: 0.7470\n",
      "\n",
      "JSD: 0.5046\n",
      "Wasserstein Distance: 1.3588\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import entropy, wasserstein_distance\n",
    "from scipy.io import arff\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ===== Load + Clean ARFF =====\n",
    "data, meta = arff.loadarff(\"adult 1.arff\")\n",
    "df = pd.DataFrame(data)\n",
    "for col in df.select_dtypes([object]).columns:\n",
    "    df[col] = df[col].str.decode(\"utf-8\").str.replace(r\"[\\\\'\\\"]\", \"\", regex=True)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# ===== Encode Categorical =====\n",
    "encoders = {}\n",
    "for col in df.columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"]\n",
    "input_dim = X.shape[1]\n",
    "num_classes = y.nunique()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== Metrics =====\n",
    "def compute_jsd(p, q):\n",
    "    p, q = np.array(p) + 1e-10, np.array(q) + 1e-10\n",
    "    p, q = p / p.sum(), q / q.sum()\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (entropy(p, m) + entropy(q, m))\n",
    "\n",
    "def evaluate_jsd_wd(real_df, synth_df):\n",
    "    jsd_scores, wd_scores = [], []\n",
    "    for col in real_df.columns:\n",
    "        real, synth = real_df[col].values, synth_df[col].values\n",
    "        jsd = compute_jsd(np.histogram(real, bins=20)[0], np.histogram(synth, bins=20)[0])\n",
    "        wd = wasserstein_distance(real, synth)\n",
    "        jsd_scores.append(jsd)\n",
    "        wd_scores.append(wd)\n",
    "    return np.mean(jsd_scores), np.mean(wd_scores)\n",
    "\n",
    "# ===== CW-GAN Models =====\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(32 + num_classes, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "    def forward(self, z, labels):\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat((z, c), dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + num_classes, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x, labels):\n",
    "        c = self.label_emb(labels)\n",
    "        d_in = torch.cat((x, c), dim=1)\n",
    "        return self.model(d_in)\n",
    "\n",
    "def compute_gp(critic, real_samples, fake_samples, labels, device):\n",
    "    alpha = torch.rand(real_samples.size(0), 1).to(device)\n",
    "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "    d_interpolates = critic(interpolates, labels)\n",
    "    fake = torch.ones_like(d_interpolates)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates, inputs=interpolates, grad_outputs=fake,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "# ===== Experiment Setup =====\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "all_results = defaultdict(list)\n",
    "\n",
    "for repeat in range(3):\n",
    "    print(f\"\\n游대 Repeat {repeat+1}/3\")\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"\\n游댃 Fold {fold+1}/2\")\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        X_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        y_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "        loader = DataLoader(TensorDataset(X_tensor, y_tensor), batch_size=128, shuffle=True)\n",
    "\n",
    "        generator = Generator().to(device)\n",
    "        critic = Critic().to(device)\n",
    "        opt_G = torch.optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "        opt_C = torch.optim.Adam(critic.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "\n",
    "        for epoch in range(100):\n",
    "            for i, (real_samples, labels) in enumerate(loader):\n",
    "                real_samples, labels = real_samples.to(device), labels.to(device)\n",
    "                opt_C.zero_grad()\n",
    "                z = torch.randn(real_samples.size(0), 32).to(device)\n",
    "                fake_samples = generator(z, labels)\n",
    "                real_validity = critic(real_samples, labels)\n",
    "                fake_validity = critic(fake_samples.detach(), labels)\n",
    "                gp = compute_gp(critic, real_samples, fake_samples, labels, device)\n",
    "                c_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + 10 * gp\n",
    "                c_loss.backward()\n",
    "                opt_C.step()\n",
    "                if i % 5 == 0:\n",
    "                    opt_G.zero_grad()\n",
    "                    gen_samples = generator(z, labels)\n",
    "                    g_loss = -torch.mean(critic(gen_samples, labels))\n",
    "                    g_loss.backward()\n",
    "                    opt_G.step()\n",
    "\n",
    "        # Generate synthetic data\n",
    "        synth_size = len(X_train) // 2\n",
    "        z = torch.randn(synth_size, 32).to(device)\n",
    "        synth_labels = torch.randint(0, num_classes, (synth_size,), dtype=torch.long).to(device)\n",
    "        gen_data = generator(z, synth_labels).detach().cpu().numpy()\n",
    "        synth_df = pd.DataFrame(gen_data, columns=X.columns)\n",
    "        synth_df[\"class\"] = synth_labels.cpu().numpy()\n",
    "\n",
    "        # Classifier Evaluation (TSTR)\n",
    "        print(\"\\n游늵 TSTR Accuracy:\")\n",
    "        models = {\n",
    "            \"LogReg\": LogisticRegression(max_iter=300),\n",
    "            \"MLP\": MLPClassifier(max_iter=300),\n",
    "            \"RF\": RandomForestClassifier(),\n",
    "            \"XGBT\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "        }\n",
    "\n",
    "        for name, model in models.items():\n",
    "            model.fit(synth_df.drop(columns=[\"class\"]), synth_df[\"class\"])\n",
    "            y_pred = model.predict(X_test)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            all_results[f\"{name}_acc\"].append(acc)\n",
    "            print(f\"{name}: {acc:.4f}\")\n",
    "\n",
    "        # JSD + WD\n",
    "        jsd, wd = evaluate_jsd_wd(X_train, synth_df.drop(columns=[\"class\"]))\n",
    "        all_results[\"jsd\"].append(jsd)\n",
    "        all_results[\"wd\"].append(wd)\n",
    "        print(f\"\\n游댧 JSD: {jsd:.4f} | WD: {wd:.4f}\")\n",
    "\n",
    "# ===== Final Average Summary =====\n",
    "print(\"\\n游늳 FINAL AVERAGE RESULTS ACROSS 3x2 CV:\")\n",
    "for name in [\"LogReg\", \"MLP\", \"RF\", \"XGBT\"]:\n",
    "    avg = np.mean(all_results[f\"{name}_acc\"])\n",
    "    print(f\"{name} TSTR Accuracy: {avg:.4f}\")\n",
    "\n",
    "print(f\"\\nJSD: {np.mean(all_results['jsd']):.4f}\")\n",
    "print(f\"Wasserstein Distance: {np.mean(all_results['wd']):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
