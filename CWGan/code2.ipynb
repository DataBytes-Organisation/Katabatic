{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------- #\n",
    "#          IMPORTS             #\n",
    "# ----------------------------- #\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# ----------------------------- #\n",
    "#      CW-GAN PIPELINE         #\n",
    "# ----------------------------- #\n",
    "\n",
    "def run_cwgan_pipeline(csv_file, target_column, epochs=300, num_samples=2000):\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    df_encoded = df.copy()\n",
    "    encoders = {}\n",
    "    for col in df_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "        encoders[col] = le\n",
    "\n",
    "    X = df_encoded.drop(columns=[target_column])\n",
    "    y = df_encoded[target_column]\n",
    "    num_classes = y.nunique()\n",
    "    input_dim = X.shape[1]\n",
    "\n",
    "    # Create tensor dataset\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    # Generator model\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(32 + num_classes, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, input_dim)\n",
    "            )\n",
    "        def forward(self, z, labels):\n",
    "            c = self.label_emb(labels)\n",
    "            x = torch.cat((z, c), dim=1)\n",
    "            return self.model(x)\n",
    "\n",
    "    # Critic model\n",
    "    class Critic(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(input_dim + num_classes, 128),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Linear(128, 64),\n",
    "                nn.LeakyReLU(0.2),\n",
    "                nn.Linear(64, 1)\n",
    "            )\n",
    "        def forward(self, x, labels):\n",
    "            c = self.label_emb(labels)\n",
    "            d_in = torch.cat((x, c), dim=1)\n",
    "            return self.model(d_in)\n",
    "\n",
    "    def compute_gp(critic, real_samples, fake_samples, labels):\n",
    "        alpha = torch.rand(real_samples.size(0), 1).to(device)\n",
    "        interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "        d_interpolates = critic(interpolates, labels)\n",
    "        fake = torch.ones_like(d_interpolates)\n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=d_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=fake,\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        return ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "    # Training setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    generator = Generator().to(device)\n",
    "    critic = Critic().to(device)\n",
    "    optimizer_G = torch.optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "    optimizer_C = torch.optim.Adam(critic.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
    "\n",
    "    # Train GAN\n",
    "    for epoch in range(epochs):\n",
    "        for i, (real_samples, labels) in enumerate(loader):\n",
    "            real_samples = real_samples.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer_C.zero_grad()\n",
    "            z = torch.randn(real_samples.size(0), 32).to(device)\n",
    "            fake_samples = generator(z, labels)\n",
    "            real_validity = critic(real_samples, labels)\n",
    "            fake_validity = critic(fake_samples.detach(), labels)\n",
    "            gp = compute_gp(critic, real_samples.data, fake_samples.data, labels)\n",
    "            c_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + 10 * gp\n",
    "            c_loss.backward()\n",
    "            optimizer_C.step()\n",
    "\n",
    "            if i % 5 == 0:\n",
    "                optimizer_G.zero_grad()\n",
    "                gen_samples = generator(z, labels)\n",
    "                g_loss = -torch.mean(critic(gen_samples, labels))\n",
    "                g_loss.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "         # Print every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "             print(f\"[{csv_file}] Epoch {epoch+1}/{epochs} | Critic Loss: {c_loss.item():.4f} | Generator Loss: {g_loss.item():.4f}\")\n",
    "        \n",
    "    # Generate synthetic data\n",
    "    z = torch.randn(num_samples, 32).to(device)\n",
    "    labels = torch.randint(0, num_classes, (num_samples,), dtype=torch.long).to(device)\n",
    "    gen_data = generator(z, labels).detach().cpu().numpy()\n",
    "    label_arr = labels.cpu().numpy()\n",
    "\n",
    "    gen_df = pd.DataFrame(gen_data, columns=X.columns)\n",
    "    decoded_df = gen_df.copy()\n",
    "    for col in decoded_df.columns:\n",
    "        valid_indices = np.arange(len(encoders[col].classes_))\n",
    "        rounded = np.round(decoded_df[col]).clip(min(valid_indices), max(valid_indices)).astype(int)\n",
    "        decoded_df[col] = encoders[col].inverse_transform(rounded)\n",
    "    decoded_df[target_column] = encoders[target_column].inverse_transform(label_arr)\n",
    "\n",
    "    # Re-encode synthetic data\n",
    "    X_synth = decoded_df.drop(columns=[target_column])\n",
    "    y_synth = decoded_df[target_column]\n",
    "    X_encoded = pd.DataFrame()\n",
    "    for col in X_synth.columns:\n",
    "        X_encoded[col] = encoders[col].transform(X_synth[col])\n",
    "    y_encoded = encoders[target_column].transform(y_synth)\n",
    "\n",
    "    # Define classifiers\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"MLPClassifier\": MLPClassifier(max_iter=500),\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=300),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "    }\n",
    "\n",
    "    # ==== 10-chunk classifier evaluation on synthetic data ====\n",
    "    full_df = X_encoded.copy()\n",
    "    full_df['target'] = y_encoded\n",
    "    total_samples = len(full_df)\n",
    "    chunk_size = total_samples // 5\n",
    "    accuracy_results = defaultdict(list)\n",
    "\n",
    "    for repeat in range(2):  # Before and after shuffle\n",
    "        print(f\"\\nüîÅ Starting round {repeat + 1} (Shuffle: {'Yes' if repeat == 1 else 'No'})\")\n",
    "\n",
    "        if repeat == 1:\n",
    "            full_df = shuffle(full_df, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        for chunk in range(5):\n",
    "            start = chunk * chunk_size\n",
    "            end = start + chunk_size if chunk < 4 else total_samples\n",
    "            chunk_df = full_df.iloc[start:end]\n",
    "\n",
    "            X_chunk = chunk_df.drop(columns=['target'])\n",
    "            y_chunk = chunk_df['target']\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_chunk, y_chunk, test_size=0.2, random_state=42)\n",
    "\n",
    "            print(f\"\\nüß™ Training on Chunk {chunk + 1}/5 of Round {repeat + 1} (Rows {start} to {end})\")\n",
    "\n",
    "            for name, model in models.items():\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                accuracy_results[name].append(acc)\n",
    "                print(f\"{name} - Accuracy: {acc:.4f}\")\n",
    "\n",
    "    print(\"\\nüìä Final Average Accuracy on SYNTHETIC data:\")\n",
    "    for name, scores in accuracy_results.items():\n",
    "        avg_acc = np.mean(scores)\n",
    "        print(f\"{name}: Average Accuracy = {avg_acc:.4f}\")\n",
    "\n",
    "\n",
    "# ----------------------------- #\n",
    "#  BASELINE ON REAL DATASET    #\n",
    "# ----------------------------- #\n",
    "\n",
    "# def evaluate_on_real_data(csv_file, target_column):\n",
    "#     df = pd.read_csv(csv_file)\n",
    "\n",
    "#     # Encode\n",
    "#     df_encoded = df.copy()\n",
    "#     encoders = {}\n",
    "#     for col in df_encoded.columns:\n",
    "#         le = LabelEncoder()\n",
    "#         df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "#         encoders[col] = le\n",
    "\n",
    "#     X = df_encoded.drop(columns=[target_column])\n",
    "#     y = df_encoded[target_column]\n",
    "\n",
    "#     # Stratified split to avoid class mismatch\n",
    "#     sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "#     for train_idx, test_idx in sss.split(X, y):\n",
    "#         X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "#         y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "#     # Define models\n",
    "#     models = {\n",
    "#         \"RandomForest\": RandomForestClassifier(),\n",
    "#         \"MLPClassifier\": MLPClassifier(max_iter=500),\n",
    "#         \"LogisticRegression\": LogisticRegression(max_iter=300),\n",
    "#         \"XGBoost\": XGBClassifier(eval_metric=\"mlogloss\")\n",
    "#     }\n",
    "\n",
    "#     print(\"\\nüìä Accuracy of classifiers trained on REAL data:\")\n",
    "\n",
    "#     for name, model in models.items():\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         acc = accuracy_score(y_test, y_pred)\n",
    "#         print(f\"{name}: Accuracy = {acc:.4f}\")\n",
    "\n",
    "# ----------------------------- #\n",
    "#           RUN IT             #\n",
    "# ----------------------------- #\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nursery.csv] Epoch 10/300 | Critic Loss: -2.4461 | Generator Loss: -1.4058\n",
      "[nursery.csv] Epoch 20/300 | Critic Loss: -2.0401 | Generator Loss: 0.6440\n",
      "[nursery.csv] Epoch 30/300 | Critic Loss: -1.1191 | Generator Loss: 0.7584\n",
      "[nursery.csv] Epoch 40/300 | Critic Loss: 0.1267 | Generator Loss: 1.6083\n",
      "[nursery.csv] Epoch 50/300 | Critic Loss: -0.0140 | Generator Loss: 4.4617\n",
      "[nursery.csv] Epoch 60/300 | Critic Loss: -0.1062 | Generator Loss: 1.3424\n",
      "[nursery.csv] Epoch 70/300 | Critic Loss: -0.4795 | Generator Loss: 2.1275\n",
      "[nursery.csv] Epoch 80/300 | Critic Loss: 0.5315 | Generator Loss: 4.0256\n",
      "[nursery.csv] Epoch 90/300 | Critic Loss: -0.2322 | Generator Loss: 5.6971\n",
      "[nursery.csv] Epoch 100/300 | Critic Loss: -0.2482 | Generator Loss: 6.7590\n",
      "[nursery.csv] Epoch 110/300 | Critic Loss: -0.2759 | Generator Loss: 4.8370\n",
      "[nursery.csv] Epoch 120/300 | Critic Loss: -0.0928 | Generator Loss: 4.7405\n",
      "[nursery.csv] Epoch 130/300 | Critic Loss: -0.2252 | Generator Loss: 5.1103\n",
      "[nursery.csv] Epoch 140/300 | Critic Loss: -0.0517 | Generator Loss: 5.8083\n",
      "[nursery.csv] Epoch 150/300 | Critic Loss: -0.1982 | Generator Loss: 6.2606\n",
      "[nursery.csv] Epoch 160/300 | Critic Loss: -0.1102 | Generator Loss: 5.7166\n",
      "[nursery.csv] Epoch 170/300 | Critic Loss: -0.2564 | Generator Loss: 4.1744\n",
      "[nursery.csv] Epoch 180/300 | Critic Loss: -0.0434 | Generator Loss: 5.3528\n",
      "[nursery.csv] Epoch 190/300 | Critic Loss: -0.3293 | Generator Loss: 7.3059\n",
      "[nursery.csv] Epoch 200/300 | Critic Loss: -0.0930 | Generator Loss: 5.2434\n",
      "[nursery.csv] Epoch 210/300 | Critic Loss: -0.5631 | Generator Loss: 7.1017\n",
      "[nursery.csv] Epoch 220/300 | Critic Loss: -0.4839 | Generator Loss: 4.7518\n",
      "[nursery.csv] Epoch 230/300 | Critic Loss: -0.2411 | Generator Loss: 6.9452\n",
      "[nursery.csv] Epoch 240/300 | Critic Loss: -0.2437 | Generator Loss: 6.9391\n",
      "[nursery.csv] Epoch 250/300 | Critic Loss: -0.2136 | Generator Loss: 6.6975\n",
      "[nursery.csv] Epoch 260/300 | Critic Loss: -0.4533 | Generator Loss: 8.1045\n",
      "[nursery.csv] Epoch 270/300 | Critic Loss: -0.1814 | Generator Loss: 8.3713\n",
      "[nursery.csv] Epoch 280/300 | Critic Loss: -0.5976 | Generator Loss: 9.4283\n",
      "[nursery.csv] Epoch 290/300 | Critic Loss: -0.5602 | Generator Loss: 9.6643\n",
      "[nursery.csv] Epoch 300/300 | Critic Loss: -0.5144 | Generator Loss: 9.7107\n",
      "\n",
      "üîÅ Starting round 1 (Shuffle: No)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 1 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.4625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.4750\n",
      "LogisticRegression - Accuracy: 0.5250\n",
      "XGBoost - Accuracy: 0.4500\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 1 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.4625\n",
      "LogisticRegression - Accuracy: 0.4750\n",
      "XGBoost - Accuracy: 0.4750\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 1 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.5500\n",
      "LogisticRegression - Accuracy: 0.5250\n",
      "XGBoost - Accuracy: 0.4750\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 1 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.4500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.4625\n",
      "LogisticRegression - Accuracy: 0.5000\n",
      "XGBoost - Accuracy: 0.4500\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 1 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.5375\n",
      "LogisticRegression - Accuracy: 0.6125\n",
      "XGBoost - Accuracy: 0.5125\n",
      "\n",
      "üîÅ Starting round 2 (Shuffle: Yes)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 2 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.4750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.5625\n",
      "LogisticRegression - Accuracy: 0.5625\n",
      "XGBoost - Accuracy: 0.4750\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 2 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.5125\n",
      "LogisticRegression - Accuracy: 0.4875\n",
      "XGBoost - Accuracy: 0.5125\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 2 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.3875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.4000\n",
      "LogisticRegression - Accuracy: 0.3625\n",
      "XGBoost - Accuracy: 0.4500\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 2 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.4875\n",
      "LogisticRegression - Accuracy: 0.4750\n",
      "XGBoost - Accuracy: 0.5000\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 2 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.5000\n",
      "MLPClassifier - Accuracy: 0.5500\n",
      "LogisticRegression - Accuracy: 0.5875\n",
      "XGBoost - Accuracy: 0.5375\n",
      "\n",
      "üìä Final Average Accuracy on SYNTHETIC data:\n",
      "RandomForest: Average Accuracy = 0.4775\n",
      "MLPClassifier: Average Accuracy = 0.5000\n",
      "LogisticRegression: Average Accuracy = 0.5112\n",
      "XGBoost: Average Accuracy = 0.4837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:57:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Adjust CSV path as needed\n",
    "csv_path = \"nursery.csv\"\n",
    "target = \"Target\"\n",
    "\n",
    "run_cwgan_pipeline(csv_path, target)\n",
    "#evaluate_on_real_data(csv_path, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[letter-recognition-2.csv] Epoch 10/300 | Critic Loss: -18.5876 | Generator Loss: -17.0938\n",
      "[letter-recognition-2.csv] Epoch 20/300 | Critic Loss: -7.4032 | Generator Loss: -2.3815\n",
      "[letter-recognition-2.csv] Epoch 30/300 | Critic Loss: -6.5988 | Generator Loss: -1.1215\n",
      "[letter-recognition-2.csv] Epoch 40/300 | Critic Loss: -5.4533 | Generator Loss: -1.4681\n",
      "[letter-recognition-2.csv] Epoch 50/300 | Critic Loss: -2.8873 | Generator Loss: -0.4209\n",
      "[letter-recognition-2.csv] Epoch 60/300 | Critic Loss: -2.8446 | Generator Loss: 3.0356\n",
      "[letter-recognition-2.csv] Epoch 70/300 | Critic Loss: -3.5078 | Generator Loss: 1.4259\n",
      "[letter-recognition-2.csv] Epoch 80/300 | Critic Loss: -1.7420 | Generator Loss: -1.0205\n",
      "[letter-recognition-2.csv] Epoch 90/300 | Critic Loss: -0.5450 | Generator Loss: 0.1197\n",
      "[letter-recognition-2.csv] Epoch 100/300 | Critic Loss: -2.6525 | Generator Loss: 2.2407\n",
      "[letter-recognition-2.csv] Epoch 110/300 | Critic Loss: -1.7055 | Generator Loss: 0.8824\n",
      "[letter-recognition-2.csv] Epoch 120/300 | Critic Loss: -1.2968 | Generator Loss: 2.6802\n",
      "[letter-recognition-2.csv] Epoch 130/300 | Critic Loss: -1.2356 | Generator Loss: -1.3367\n",
      "[letter-recognition-2.csv] Epoch 140/300 | Critic Loss: -1.1487 | Generator Loss: 1.6382\n",
      "[letter-recognition-2.csv] Epoch 150/300 | Critic Loss: -1.6868 | Generator Loss: 0.3318\n",
      "[letter-recognition-2.csv] Epoch 160/300 | Critic Loss: -1.2257 | Generator Loss: -0.3062\n",
      "[letter-recognition-2.csv] Epoch 170/300 | Critic Loss: -1.4047 | Generator Loss: 3.6352\n",
      "[letter-recognition-2.csv] Epoch 180/300 | Critic Loss: -1.8331 | Generator Loss: 4.0715\n",
      "[letter-recognition-2.csv] Epoch 190/300 | Critic Loss: -2.2797 | Generator Loss: 0.9145\n",
      "[letter-recognition-2.csv] Epoch 200/300 | Critic Loss: -1.4144 | Generator Loss: 2.9009\n",
      "[letter-recognition-2.csv] Epoch 210/300 | Critic Loss: -1.5882 | Generator Loss: 2.6595\n",
      "[letter-recognition-2.csv] Epoch 220/300 | Critic Loss: -1.2689 | Generator Loss: 1.7919\n",
      "[letter-recognition-2.csv] Epoch 230/300 | Critic Loss: -1.9164 | Generator Loss: 0.5025\n",
      "[letter-recognition-2.csv] Epoch 240/300 | Critic Loss: -1.5397 | Generator Loss: 1.3219\n",
      "[letter-recognition-2.csv] Epoch 250/300 | Critic Loss: -1.1120 | Generator Loss: 0.4810\n",
      "[letter-recognition-2.csv] Epoch 260/300 | Critic Loss: -1.9632 | Generator Loss: 1.5633\n",
      "[letter-recognition-2.csv] Epoch 270/300 | Critic Loss: -1.3326 | Generator Loss: 0.4006\n",
      "[letter-recognition-2.csv] Epoch 280/300 | Critic Loss: -0.9757 | Generator Loss: 3.1060\n",
      "[letter-recognition-2.csv] Epoch 290/300 | Critic Loss: -1.0649 | Generator Loss: 0.3927\n",
      "[letter-recognition-2.csv] Epoch 300/300 | Critic Loss: -1.3851 | Generator Loss: 4.8305\n",
      "\n",
      "üîÅ Starting round 1 (Shuffle: No)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 1 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.7000\n",
      "LogisticRegression - Accuracy: 0.6875\n",
      "XGBoost - Accuracy: 0.6375\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 1 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.6125\n",
      "LogisticRegression - Accuracy: 0.5625\n",
      "XGBoost - Accuracy: 0.5500\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 1 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.6625\n",
      "LogisticRegression - Accuracy: 0.6750\n",
      "XGBoost - Accuracy: 0.5875\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 1 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.6625\n",
      "LogisticRegression - Accuracy: 0.6875\n",
      "XGBoost - Accuracy: 0.6000\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 1 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.5500\n",
      "LogisticRegression - Accuracy: 0.6625\n",
      "XGBoost - Accuracy: 0.5625\n",
      "\n",
      "üîÅ Starting round 2 (Shuffle: Yes)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 2 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.6500\n",
      "LogisticRegression - Accuracy: 0.6375\n",
      "XGBoost - Accuracy: 0.6000\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 2 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.7125\n",
      "LogisticRegression - Accuracy: 0.6875\n",
      "XGBoost - Accuracy: 0.4875\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 2 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.6250\n",
      "LogisticRegression - Accuracy: 0.6125\n",
      "XGBoost - Accuracy: 0.5750\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 2 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.6375\n",
      "LogisticRegression - Accuracy: 0.6875\n",
      "XGBoost - Accuracy: 0.4875\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 2 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.6125\n",
      "MLPClassifier - Accuracy: 0.6875\n",
      "LogisticRegression - Accuracy: 0.6750\n",
      "XGBoost - Accuracy: 0.5500\n",
      "\n",
      "üìä Final Average Accuracy on SYNTHETIC data:\n",
      "RandomForest: Average Accuracy = 0.5900\n",
      "MLPClassifier: Average Accuracy = 0.6500\n",
      "LogisticRegression: Average Accuracy = 0.6575\n",
      "XGBoost: Average Accuracy = 0.5637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [12:58:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "run_cwgan_pipeline(\"letter-recognition-2.csv\", \"letter\")\n",
    "#evaluate_on_real_data(\"letter-recognition-2.csv\", \"letter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[satellite.csv] Epoch 10/300 | Critic Loss: -474.2088 | Generator Loss: -0.0243\n",
      "[satellite.csv] Epoch 20/300 | Critic Loss: -1489.9869 | Generator Loss: -0.4603\n",
      "[satellite.csv] Epoch 30/300 | Critic Loss: -3141.7512 | Generator Loss: -2.6643\n",
      "[satellite.csv] Epoch 40/300 | Critic Loss: -4848.3130 | Generator Loss: -9.9609\n",
      "[satellite.csv] Epoch 50/300 | Critic Loss: -8936.9209 | Generator Loss: -27.1223\n",
      "[satellite.csv] Epoch 60/300 | Critic Loss: -13003.3477 | Generator Loss: -59.3526\n",
      "[satellite.csv] Epoch 70/300 | Critic Loss: -17558.8945 | Generator Loss: -112.6599\n",
      "[satellite.csv] Epoch 80/300 | Critic Loss: -19841.2422 | Generator Loss: -207.1697\n",
      "[satellite.csv] Epoch 90/300 | Critic Loss: -28666.8379 | Generator Loss: -335.4250\n",
      "[satellite.csv] Epoch 100/300 | Critic Loss: -39275.1719 | Generator Loss: -527.4099\n",
      "[satellite.csv] Epoch 110/300 | Critic Loss: -44569.0781 | Generator Loss: -834.6372\n",
      "[satellite.csv] Epoch 120/300 | Critic Loss: -44989.5938 | Generator Loss: -1155.3904\n",
      "[satellite.csv] Epoch 130/300 | Critic Loss: -64286.6484 | Generator Loss: -1552.8215\n",
      "[satellite.csv] Epoch 140/300 | Critic Loss: -49725.4648 | Generator Loss: -2087.4375\n",
      "[satellite.csv] Epoch 150/300 | Critic Loss: -53480.8594 | Generator Loss: -2455.0679\n",
      "[satellite.csv] Epoch 160/300 | Critic Loss: -45323.2266 | Generator Loss: -3117.2048\n",
      "[satellite.csv] Epoch 170/300 | Critic Loss: -52109.1055 | Generator Loss: -3440.1401\n",
      "[satellite.csv] Epoch 180/300 | Critic Loss: -46841.4062 | Generator Loss: -4083.8301\n",
      "[satellite.csv] Epoch 190/300 | Critic Loss: -50246.5273 | Generator Loss: -4452.4824\n",
      "[satellite.csv] Epoch 200/300 | Critic Loss: -53682.2266 | Generator Loss: -5279.5903\n",
      "[satellite.csv] Epoch 210/300 | Critic Loss: -60961.3281 | Generator Loss: -5817.5078\n",
      "[satellite.csv] Epoch 220/300 | Critic Loss: -58912.9219 | Generator Loss: -7033.1821\n",
      "[satellite.csv] Epoch 230/300 | Critic Loss: -55535.8828 | Generator Loss: -7420.2930\n",
      "[satellite.csv] Epoch 240/300 | Critic Loss: -41272.7578 | Generator Loss: -7458.3867\n",
      "[satellite.csv] Epoch 250/300 | Critic Loss: -54362.8164 | Generator Loss: -9168.9023\n",
      "[satellite.csv] Epoch 260/300 | Critic Loss: -54136.9961 | Generator Loss: -10113.7012\n",
      "[satellite.csv] Epoch 270/300 | Critic Loss: -42554.7930 | Generator Loss: -10529.5391\n",
      "[satellite.csv] Epoch 280/300 | Critic Loss: -43304.1016 | Generator Loss: -11322.9648\n",
      "[satellite.csv] Epoch 290/300 | Critic Loss: -34387.8672 | Generator Loss: -12147.0977\n",
      "[satellite.csv] Epoch 300/300 | Critic Loss: -64212.2734 | Generator Loss: -12463.8848\n",
      "\n",
      "üîÅ Starting round 1 (Shuffle: No)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 1 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.3250\n",
      "MLPClassifier - Accuracy: 0.1875\n",
      "LogisticRegression - Accuracy: 0.3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Accuracy: 0.3375\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 1 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.2500\n",
      "MLPClassifier - Accuracy: 0.1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy: 0.3625\n",
      "XGBoost - Accuracy: 0.2250\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 1 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.3625\n",
      "MLPClassifier - Accuracy: 0.2125\n",
      "LogisticRegression - Accuracy: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Accuracy: 0.3500\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 1 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.2750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3000\n",
      "LogisticRegression - Accuracy: 0.3750\n",
      "XGBoost - Accuracy: 0.3000\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 1 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.4125\n",
      "LogisticRegression - Accuracy: 0.3500\n",
      "XGBoost - Accuracy: 0.3000\n",
      "\n",
      "üîÅ Starting round 2 (Shuffle: Yes)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 2 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.2750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.2125\n",
      "LogisticRegression - Accuracy: 0.3375\n",
      "XGBoost - Accuracy: 0.2750\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 2 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.3250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3125\n",
      "LogisticRegression - Accuracy: 0.3625\n",
      "XGBoost - Accuracy: 0.2500\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 2 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3000\n",
      "LogisticRegression - Accuracy: 0.4000\n",
      "XGBoost - Accuracy: 0.3750\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 2 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.2500\n",
      "MLPClassifier - Accuracy: 0.1750\n",
      "LogisticRegression - Accuracy: 0.3625\n",
      "XGBoost - Accuracy: 0.3125\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 2 (Rows 1600 to 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.2750\n",
      "MLPClassifier - Accuracy: 0.2250\n",
      "LogisticRegression - Accuracy: 0.4000\n",
      "XGBoost - Accuracy: 0.2500\n",
      "\n",
      "üìä Final Average Accuracy on SYNTHETIC data:\n",
      "RandomForest: Average Accuracy = 0.3062\n",
      "MLPClassifier: Average Accuracy = 0.2487\n",
      "LogisticRegression: Average Accuracy = 0.3612\n",
      "XGBoost: Average Accuracy = 0.2975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:07:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"satellite.csv\"\n",
    "target = \"Purpose\"  # <-- Change this if your target column has a different name\n",
    "\n",
    "run_cwgan_pipeline(csv_path, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Bank_Personal_Loan.csv] Epoch 10/300 | Critic Loss: -5447.5850 | Generator Loss: -2.0383\n",
      "[Bank_Personal_Loan.csv] Epoch 20/300 | Critic Loss: -20116.5215 | Generator Loss: -19.5606\n",
      "[Bank_Personal_Loan.csv] Epoch 30/300 | Critic Loss: -43128.8359 | Generator Loss: -70.6840\n",
      "[Bank_Personal_Loan.csv] Epoch 40/300 | Critic Loss: -77634.7812 | Generator Loss: -188.8972\n",
      "[Bank_Personal_Loan.csv] Epoch 50/300 | Critic Loss: -102706.7734 | Generator Loss: -427.1605\n",
      "[Bank_Personal_Loan.csv] Epoch 60/300 | Critic Loss: -242935.9844 | Generator Loss: -863.9886\n",
      "[Bank_Personal_Loan.csv] Epoch 70/300 | Critic Loss: -124384.5781 | Generator Loss: -1562.5706\n",
      "[Bank_Personal_Loan.csv] Epoch 80/300 | Critic Loss: -179174.8281 | Generator Loss: -2125.1792\n",
      "[Bank_Personal_Loan.csv] Epoch 90/300 | Critic Loss: -237937.1875 | Generator Loss: -2707.3740\n",
      "[Bank_Personal_Loan.csv] Epoch 100/300 | Critic Loss: -178342.6094 | Generator Loss: -3252.7529\n",
      "[Bank_Personal_Loan.csv] Epoch 110/300 | Critic Loss: -19687.3750 | Generator Loss: -4223.9033\n",
      "[Bank_Personal_Loan.csv] Epoch 120/300 | Critic Loss: 4387.7031 | Generator Loss: -5110.6274\n",
      "[Bank_Personal_Loan.csv] Epoch 130/300 | Critic Loss: -205532.0938 | Generator Loss: -6302.4668\n",
      "[Bank_Personal_Loan.csv] Epoch 140/300 | Critic Loss: -190680.9688 | Generator Loss: -7235.0396\n",
      "[Bank_Personal_Loan.csv] Epoch 150/300 | Critic Loss: -244407.9062 | Generator Loss: -8704.3760\n",
      "[Bank_Personal_Loan.csv] Epoch 160/300 | Critic Loss: -135464.3750 | Generator Loss: -10066.7012\n",
      "[Bank_Personal_Loan.csv] Epoch 170/300 | Critic Loss: -198746.7500 | Generator Loss: -11495.5039\n",
      "[Bank_Personal_Loan.csv] Epoch 180/300 | Critic Loss: -183174.4688 | Generator Loss: -13040.1709\n",
      "[Bank_Personal_Loan.csv] Epoch 190/300 | Critic Loss: -57609.2344 | Generator Loss: -14793.7197\n",
      "[Bank_Personal_Loan.csv] Epoch 200/300 | Critic Loss: -148975.9688 | Generator Loss: -16461.7285\n",
      "[Bank_Personal_Loan.csv] Epoch 210/300 | Critic Loss: -124508.2500 | Generator Loss: -18430.5449\n",
      "[Bank_Personal_Loan.csv] Epoch 220/300 | Critic Loss: -130862.9062 | Generator Loss: -20907.3359\n",
      "[Bank_Personal_Loan.csv] Epoch 230/300 | Critic Loss: -5025.5312 | Generator Loss: -23012.1934\n",
      "[Bank_Personal_Loan.csv] Epoch 240/300 | Critic Loss: -233836.0469 | Generator Loss: -25279.3164\n",
      "[Bank_Personal_Loan.csv] Epoch 250/300 | Critic Loss: -136813.9062 | Generator Loss: -27336.7422\n",
      "[Bank_Personal_Loan.csv] Epoch 260/300 | Critic Loss: -173964.4688 | Generator Loss: -30197.4062\n",
      "[Bank_Personal_Loan.csv] Epoch 270/300 | Critic Loss: -154686.9531 | Generator Loss: -32888.8086\n",
      "[Bank_Personal_Loan.csv] Epoch 280/300 | Critic Loss: -129941.1328 | Generator Loss: -36216.3281\n",
      "[Bank_Personal_Loan.csv] Epoch 290/300 | Critic Loss: -188879.7812 | Generator Loss: -38746.2031\n",
      "[Bank_Personal_Loan.csv] Epoch 300/300 | Critic Loss: -195860.0156 | Generator Loss: -42963.1406\n",
      "\n",
      "üîÅ Starting round 1 (Shuffle: No)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 1 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.6250\n",
      "MLPClassifier - Accuracy: 0.5625\n",
      "LogisticRegression - Accuracy: 0.6250\n",
      "XGBoost - Accuracy: 0.6000\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 1 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.6875\n",
      "MLPClassifier - Accuracy: 0.6500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - Accuracy: 0.7125\n",
      "XGBoost - Accuracy: 0.6750\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 1 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.6000\n",
      "MLPClassifier - Accuracy: 0.5000\n",
      "LogisticRegression - Accuracy: 0.6500\n",
      "XGBoost - Accuracy: 0.5125\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 1 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.5500\n",
      "LogisticRegression - Accuracy: 0.6250\n",
      "XGBoost - Accuracy: 0.5750\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 1 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.6000\n",
      "MLPClassifier - Accuracy: 0.5875\n",
      "LogisticRegression - Accuracy: 0.6500\n",
      "XGBoost - Accuracy: 0.6500\n",
      "\n",
      "üîÅ Starting round 2 (Shuffle: Yes)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 2 (Rows 0 to 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.6000\n",
      "MLPClassifier - Accuracy: 0.4625\n",
      "LogisticRegression - Accuracy: 0.5375\n",
      "XGBoost - Accuracy: 0.6250\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 2 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.6000\n",
      "MLPClassifier - Accuracy: 0.5500\n",
      "LogisticRegression - Accuracy: 0.6250\n",
      "XGBoost - Accuracy: 0.6000\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 2 (Rows 800 to 1200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.5500\n",
      "MLPClassifier - Accuracy: 0.5375\n",
      "LogisticRegression - Accuracy: 0.5875\n",
      "XGBoost - Accuracy: 0.4750\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 2 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.5250\n",
      "MLPClassifier - Accuracy: 0.5250\n",
      "LogisticRegression - Accuracy: 0.6375\n",
      "XGBoost - Accuracy: 0.5125\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 2 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.6875\n",
      "MLPClassifier - Accuracy: 0.5875\n",
      "LogisticRegression - Accuracy: 0.6250\n",
      "XGBoost - Accuracy: 0.5875\n",
      "\n",
      "üìä Final Average Accuracy on SYNTHETIC data:\n",
      "RandomForest: Average Accuracy = 0.6038\n",
      "MLPClassifier: Average Accuracy = 0.5513\n",
      "LogisticRegression: Average Accuracy = 0.6275\n",
      "XGBoost: Average Accuracy = 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:17:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"Bank_Personal_Loan.csv\"\n",
    "target = \"Personal Loan\"  # <-- Confirm exact spelling\n",
    "\n",
    "run_cwgan_pipeline(csv_path, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[car.csv] Epoch 10/300 | Critic Loss: 1.5182 | Generator Loss: -0.1121\n",
      "[car.csv] Epoch 20/300 | Critic Loss: -1.5539 | Generator Loss: -0.3556\n",
      "[car.csv] Epoch 30/300 | Critic Loss: -2.4864 | Generator Loss: -0.3204\n",
      "[car.csv] Epoch 40/300 | Critic Loss: -2.6487 | Generator Loss: -0.4396\n",
      "[car.csv] Epoch 50/300 | Critic Loss: -2.4681 | Generator Loss: -0.7271\n",
      "[car.csv] Epoch 60/300 | Critic Loss: -2.2503 | Generator Loss: -0.6793\n",
      "[car.csv] Epoch 70/300 | Critic Loss: -2.0241 | Generator Loss: -0.0542\n",
      "[car.csv] Epoch 80/300 | Critic Loss: -1.8537 | Generator Loss: 0.3844\n",
      "[car.csv] Epoch 90/300 | Critic Loss: -1.9097 | Generator Loss: 0.4858\n",
      "[car.csv] Epoch 100/300 | Critic Loss: -1.6346 | Generator Loss: 0.6216\n",
      "[car.csv] Epoch 110/300 | Critic Loss: -1.6748 | Generator Loss: 0.6661\n",
      "[car.csv] Epoch 120/300 | Critic Loss: -1.7652 | Generator Loss: 0.8484\n",
      "[car.csv] Epoch 130/300 | Critic Loss: -1.5449 | Generator Loss: 0.6940\n",
      "[car.csv] Epoch 140/300 | Critic Loss: -1.4842 | Generator Loss: 0.7578\n",
      "[car.csv] Epoch 150/300 | Critic Loss: -1.3745 | Generator Loss: 0.7465\n",
      "[car.csv] Epoch 160/300 | Critic Loss: -1.3594 | Generator Loss: 0.7860\n",
      "[car.csv] Epoch 170/300 | Critic Loss: -1.0508 | Generator Loss: 0.8072\n",
      "[car.csv] Epoch 180/300 | Critic Loss: -0.9784 | Generator Loss: 0.8009\n",
      "[car.csv] Epoch 190/300 | Critic Loss: -0.8463 | Generator Loss: 0.6400\n",
      "[car.csv] Epoch 200/300 | Critic Loss: -0.5158 | Generator Loss: 0.6169\n",
      "[car.csv] Epoch 210/300 | Critic Loss: -0.7384 | Generator Loss: 0.7975\n",
      "[car.csv] Epoch 220/300 | Critic Loss: -0.5976 | Generator Loss: 0.8550\n",
      "[car.csv] Epoch 230/300 | Critic Loss: -0.3580 | Generator Loss: 1.3140\n",
      "[car.csv] Epoch 240/300 | Critic Loss: -0.2465 | Generator Loss: 1.1916\n",
      "[car.csv] Epoch 250/300 | Critic Loss: 0.0240 | Generator Loss: 1.1479\n",
      "[car.csv] Epoch 260/300 | Critic Loss: -0.2552 | Generator Loss: 1.4069\n",
      "[car.csv] Epoch 270/300 | Critic Loss: 0.0602 | Generator Loss: 2.0238\n",
      "[car.csv] Epoch 280/300 | Critic Loss: 0.0402 | Generator Loss: 1.0036\n",
      "[car.csv] Epoch 290/300 | Critic Loss: 0.3449 | Generator Loss: -0.6603\n",
      "[car.csv] Epoch 300/300 | Critic Loss: 0.4934 | Generator Loss: -0.0265\n",
      "\n",
      "üîÅ Starting round 1 (Shuffle: No)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 1 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.3750\n",
      "MLPClassifier - Accuracy: 0.3000\n",
      "LogisticRegression - Accuracy: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Accuracy: 0.3125\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 1 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3625\n",
      "LogisticRegression - Accuracy: 0.3250\n",
      "XGBoost - Accuracy: 0.3875\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 1 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.2625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3375\n",
      "LogisticRegression - Accuracy: 0.3500\n",
      "XGBoost - Accuracy: 0.2750\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 1 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3250\n",
      "LogisticRegression - Accuracy: 0.3125\n",
      "XGBoost - Accuracy: 0.2625\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 1 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.3500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3750\n",
      "LogisticRegression - Accuracy: 0.4250\n",
      "XGBoost - Accuracy: 0.3000\n",
      "\n",
      "üîÅ Starting round 2 (Shuffle: Yes)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 2 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.3375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3625\n",
      "LogisticRegression - Accuracy: 0.3250\n",
      "XGBoost - Accuracy: 0.3125\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 2 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.3375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3500\n",
      "LogisticRegression - Accuracy: 0.3250\n",
      "XGBoost - Accuracy: 0.3625\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 2 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3875\n",
      "LogisticRegression - Accuracy: 0.3750\n",
      "XGBoost - Accuracy: 0.3000\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 2 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.2875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier - Accuracy: 0.3375\n",
      "LogisticRegression - Accuracy: 0.4625\n",
      "XGBoost - Accuracy: 0.2500\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 2 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.3750\n",
      "MLPClassifier - Accuracy: 0.4125\n",
      "LogisticRegression - Accuracy: 0.5250\n",
      "XGBoost - Accuracy: 0.3250\n",
      "\n",
      "üìä Final Average Accuracy on SYNTHETIC data:\n",
      "RandomForest: Average Accuracy = 0.3425\n",
      "MLPClassifier: Average Accuracy = 0.3550\n",
      "LogisticRegression: Average Accuracy = 0.3787\n",
      "XGBoost: Average Accuracy = 0.3088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:19:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"car.csv\"\n",
    "target = \"Class\"  # Or possibly \"Acceptability\" ‚Äì depends on exact column names\n",
    "\n",
    "run_cwgan_pipeline(csv_path, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[games.csv] Epoch 10/300 | Critic Loss: -1135931.1250 | Generator Loss: -871.4750\n",
      "[games.csv] Epoch 20/300 | Critic Loss: -5138733.5000 | Generator Loss: -20126.5742\n",
      "[games.csv] Epoch 30/300 | Critic Loss: -7885935.0000 | Generator Loss: -102314.1484\n",
      "[games.csv] Epoch 40/300 | Critic Loss: -7948184.5000 | Generator Loss: -205883.0156\n",
      "[games.csv] Epoch 50/300 | Critic Loss: -7926738.5000 | Generator Loss: -370425.0312\n",
      "[games.csv] Epoch 60/300 | Critic Loss: -7225608.5000 | Generator Loss: -607534.6250\n",
      "[games.csv] Epoch 70/300 | Critic Loss: -6899740.5000 | Generator Loss: -902128.0625\n",
      "[games.csv] Epoch 80/300 | Critic Loss: -6264729.0000 | Generator Loss: -1211364.7500\n",
      "[games.csv] Epoch 90/300 | Critic Loss: -6226793.5000 | Generator Loss: -1767550.5000\n",
      "[games.csv] Epoch 100/300 | Critic Loss: -5446475.5000 | Generator Loss: -2187105.5000\n",
      "[games.csv] Epoch 110/300 | Critic Loss: -4845916.0000 | Generator Loss: -2678300.2500\n",
      "[games.csv] Epoch 120/300 | Critic Loss: -3995768.2500 | Generator Loss: -2940709.5000\n",
      "[games.csv] Epoch 130/300 | Critic Loss: -3702144.7500 | Generator Loss: -3769214.5000\n",
      "[games.csv] Epoch 140/300 | Critic Loss: -2399135.2500 | Generator Loss: -3438935.5000\n",
      "[games.csv] Epoch 150/300 | Critic Loss: -1572571.0000 | Generator Loss: -3650752.5000\n",
      "[games.csv] Epoch 160/300 | Critic Loss: -1342958.0000 | Generator Loss: -2927942.5000\n",
      "[games.csv] Epoch 170/300 | Critic Loss: -553035.0000 | Generator Loss: -2038601.8750\n",
      "[games.csv] Epoch 180/300 | Critic Loss: -309674.7500 | Generator Loss: -888674.3750\n",
      "[games.csv] Epoch 190/300 | Critic Loss: -368711.1562 | Generator Loss: -25488.6621\n",
      "[games.csv] Epoch 200/300 | Critic Loss: -289136.4688 | Generator Loss: 18527.9219\n",
      "[games.csv] Epoch 210/300 | Critic Loss: -286070.4062 | Generator Loss: 409001.1250\n",
      "[games.csv] Epoch 220/300 | Critic Loss: -433106.3125 | Generator Loss: 541624.8750\n",
      "[games.csv] Epoch 230/300 | Critic Loss: -702305.0000 | Generator Loss: -93568.1562\n",
      "[games.csv] Epoch 240/300 | Critic Loss: -1164983.5000 | Generator Loss: -1091773.3750\n",
      "[games.csv] Epoch 250/300 | Critic Loss: -1200964.5000 | Generator Loss: 29139.7793\n",
      "[games.csv] Epoch 260/300 | Critic Loss: -1505681.6250 | Generator Loss: 35807.5703\n",
      "[games.csv] Epoch 270/300 | Critic Loss: -1593882.1250 | Generator Loss: 63177.8711\n",
      "[games.csv] Epoch 280/300 | Critic Loss: -1804741.3750 | Generator Loss: 41541.2070\n",
      "[games.csv] Epoch 290/300 | Critic Loss: -1646876.0000 | Generator Loss: 40242.4375\n",
      "[games.csv] Epoch 300/300 | Critic Loss: -1634941.5000 | Generator Loss: -21222.2227\n",
      "\n",
      "üîÅ Starting round 1 (Shuffle: No)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 1 (Rows 0 to 400)\n",
      "RandomForest - Accuracy: 0.7500\n",
      "MLPClassifier - Accuracy: 0.4000\n",
      "LogisticRegression - Accuracy: 0.7500\n",
      "XGBoost - Accuracy: 0.8125\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 1 (Rows 400 to 800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.8125\n",
      "MLPClassifier - Accuracy: 0.3125\n",
      "LogisticRegression - Accuracy: 0.7750\n",
      "XGBoost - Accuracy: 0.7875\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 1 (Rows 800 to 1200)\n",
      "RandomForest - Accuracy: 0.7750\n",
      "MLPClassifier - Accuracy: 0.2875\n",
      "LogisticRegression - Accuracy: 0.7375\n",
      "XGBoost - Accuracy: 0.7625\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 1 (Rows 1200 to 1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.8625\n",
      "MLPClassifier - Accuracy: 0.3625\n",
      "LogisticRegression - Accuracy: 0.6625\n",
      "XGBoost - Accuracy: 0.8125\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 1 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.7375\n",
      "MLPClassifier - Accuracy: 0.3750\n",
      "LogisticRegression - Accuracy: 0.6875\n",
      "XGBoost - Accuracy: 0.7250\n",
      "\n",
      "üîÅ Starting round 2 (Shuffle: Yes)\n",
      "\n",
      "üß™ Training on Chunk 1/5 of Round 2 (Rows 0 to 400)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.7375\n",
      "MLPClassifier - Accuracy: 0.3375\n",
      "LogisticRegression - Accuracy: 0.6250\n",
      "XGBoost - Accuracy: 0.7500\n",
      "\n",
      "üß™ Training on Chunk 2/5 of Round 2 (Rows 400 to 800)\n",
      "RandomForest - Accuracy: 0.7000\n",
      "MLPClassifier - Accuracy: 0.2750\n",
      "LogisticRegression - Accuracy: 0.6375\n",
      "XGBoost - Accuracy: 0.7250\n",
      "\n",
      "üß™ Training on Chunk 3/5 of Round 2 (Rows 800 to 1200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Accuracy: 0.8500\n",
      "MLPClassifier - Accuracy: 0.4875\n",
      "LogisticRegression - Accuracy: 0.7125\n",
      "XGBoost - Accuracy: 0.7750\n",
      "\n",
      "üß™ Training on Chunk 4/5 of Round 2 (Rows 1200 to 1600)\n",
      "RandomForest - Accuracy: 0.8625\n",
      "MLPClassifier - Accuracy: 0.3625\n",
      "LogisticRegression - Accuracy: 0.7250\n",
      "XGBoost - Accuracy: 0.8500\n",
      "\n",
      "üß™ Training on Chunk 5/5 of Round 2 (Rows 1600 to 2000)\n",
      "RandomForest - Accuracy: 0.8125\n",
      "MLPClassifier - Accuracy: 0.3625\n",
      "LogisticRegression - Accuracy: 0.6625\n",
      "XGBoost - Accuracy: 0.7875\n",
      "\n",
      "üìä Final Average Accuracy on SYNTHETIC data:\n",
      "RandomForest: Average Accuracy = 0.7900\n",
      "MLPClassifier: Average Accuracy = 0.3562\n",
      "LogisticRegression: Average Accuracy = 0.6975\n",
      "XGBoost: Average Accuracy = 0.7787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/dhananjaychoudhari/.pyenv/versions/3.9.18/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [13:25:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"games.csv\"\n",
    "target = \"winner\"  # Best choice for this dataset\n",
    "\n",
    "run_cwgan_pipeline(csv_path, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
