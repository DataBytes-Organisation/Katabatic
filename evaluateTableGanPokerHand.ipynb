{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---FIT TableGAN Model with high privacy setting\n",
      "---Initialise TableGAN Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: [D loss: -0.5744] [G loss: 1.1233] [C loss: 0.9404]\n",
      "Epoch 20/100: [D loss: -0.3417] [G loss: 1.5270] [C loss: 0.9075]\n",
      "Epoch 30/100: [D loss: -0.3101] [G loss: 2.0770] [C loss: 0.8507]\n",
      "Epoch 40/100: [D loss: -0.3058] [G loss: 2.0176] [C loss: 0.7879]\n",
      "Epoch 50/100: [D loss: -0.3303] [G loss: 3.3233] [C loss: 0.7254]\n",
      "Epoch 60/100: [D loss: -0.3206] [G loss: 3.2439] [C loss: 0.6727]\n",
      "Epoch 70/100: [D loss: -0.3863] [G loss: 2.8209] [C loss: 0.6295]\n",
      "Epoch 80/100: [D loss: -0.4183] [G loss: 0.0558] [C loss: 0.5917]\n",
      "Epoch 90/100: [D loss: -0.3886] [G loss: -1.6258] [C loss: 0.5598]\n",
      "Epoch 100/100: [D loss: -0.3947] [G loss: -1.0898] [C loss: 0.5300]\n"
     ]
    }
   ],
   "source": [
    "from katabatic.models.TableGAN import TableGANAdapter, TableGAN, preprocess_data, postprocess_data\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_data_path = 'data/PokerHand/poker-hand-training-true.data'\n",
    "test_data_path = 'data/PokerHand/poker-hand-testing.data'\n",
    "\n",
    "# Initialize the adapter with a specific privacy setting\n",
    "tablegan_adapter = TableGANAdapter(type='continuous', privacy_setting='high')\n",
    "# load data\n",
    "df_train = pd.read_csv(train_data_path, header = None)\n",
    "df_test = pd.read_csv(test_data_path, header = None)\n",
    "x_train = df_train.drop(10, axis = 1).values\n",
    "y_train = df_train[10].values\n",
    "x_test = df_test.drop(10, axis = 1).values\n",
    "y_test = df_test[10].values\n",
    "\n",
    "# Fit the model\n",
    "#tablegan_adapter.fit(x_train, y_train, epochs=200, batch_size=64)\n",
    "tablegan_adapter.fit(x_train, y_train, epochs=100, batch_size=64)\n",
    "#tablegan_adapter.fit(x_train, y_train, epochs=25, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Generate from TableGAN Model\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "synthetic_data = tablegan_adapter.generate(size=25010)\n",
    "#synthetic_data = tablegan_adapter.generate(size=100)\n",
    "\n",
    "# Check the shape of synthetic data\n",
    "synthetic_df = pd.DataFrame(synthetic_data).astype(int)\n",
    "x_sync_train = synthetic_df.drop(10, axis = 1).values\n",
    "y_sync_train = synthetic_df[10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:47:58] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:49:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluated Item        LR        RF       MLP      XGBT\n",
      "0           TSTR  0.472759  0.492685  0.636337  0.666819\n",
      "1           TRTR  0.501067  0.616169  0.977174  0.931637\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# evaluate\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "lbe = LabelEncoder()\n",
    "#y_train = np.append(y_train, -1)\n",
    "#y_sync_train = np.append(y_sync_train, -1)\n",
    "for index, value in enumerate(y_test):\n",
    "    if value not in y_sync_train:\n",
    "        y_test[index] = 0\n",
    "\n",
    "# TRTR\n",
    "x_train_ohe = ohe.fit_transform(x_train)\n",
    "x_test_ohe = ohe.transform(x_test)\n",
    "y_train_lbe = lbe.fit_transform(y_train).astype(int)\n",
    "y_test_lbe = lbe.transform(y_test).astype(int)\n",
    "trtr_score_lr  = LogisticRegression().fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\n",
    "trtr_score_rf  = RandomForestClassifier().fit(x_train, y_train_lbe).score(x_test, y_test_lbe)\n",
    "trtr_score_mlp = MLPClassifier().fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\n",
    "xgbt_classifier = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "trtr_score_xgbt = xgbt_classifier.fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\n",
    "\n",
    "# TSTR\n",
    "x_train_ohe = ohe.fit_transform(x_sync_train)\n",
    "x_test_ohe = ohe.transform(x_test)\n",
    "y_train_lbe = lbe.fit_transform(y_sync_train).astype(int)\n",
    "y_test_lbe = lbe.transform(y_test).astype(int)\n",
    "tstr_score_lr  = LogisticRegression().fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\n",
    "tstr_score_rf  = RandomForestClassifier().fit(x_train, y_train_lbe).score(x_test, y_test_lbe)\n",
    "tstr_score_mlp = MLPClassifier().fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\n",
    "xgbt_classifier = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "tstr_score_xgbt = xgbt_classifier.fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\n",
    "\n",
    "df_evaluate = pd.DataFrame([\n",
    "    ['TSTR', tstr_score_lr, tstr_score_rf, tstr_score_mlp, tstr_score_xgbt],\n",
    "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp, trtr_score_xgbt]\n",
    "], columns=['Evaluated Item', 'LR', 'RF', 'MLP', 'XGBT'])\n",
    "print(df_evaluate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
