{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47c8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Direct imports from the same directory\n",
    "from tabddpm_adapter import TabDDPMAdapter\n",
    "from tabddpm_benchmark import evaluate_tabddpm, print_evaluation_results\n",
    "from tabddpm_utils import preprocess_data, get_tstr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ce2f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load configuration\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(\"# Load configuration\")\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0750d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1. Load and prepare the dataset\n",
      "Columns in dataset: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36']\n",
      "Dataset shape: (4435, 37)\n",
      "    0    1    2   3   4    5    6   7   8    9  ...   27  28   29   30   31  \\\n",
      "0  92  115  120  94  84  102  106  79  84  102  ...  104  88  121  128  100   \n",
      "1  84  102  106  79  84  102  102  83  80  102  ...  100  84  107  113   87   \n",
      "2  84  102  102  83  80  102  102  79  84   94  ...   87  84   99  104   79   \n",
      "3  80  102  102  79  84   94  102  79  80   94  ...   79  84   99  104   79   \n",
      "4  84   94  102  79  80   94   98  76  80  102  ...   79  84  103  104   79   \n",
      "\n",
      "   32   33   34  35  36  \n",
      "0  84  107  113  87   3  \n",
      "1  84   99  104  79   3  \n",
      "2  84   99  104  79   3  \n",
      "3  84  103  104  79   3  \n",
      "4  79  107  109  87   3  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare the dataset\n",
    "print(\"# 1. Load and prepare the dataset\")\n",
    "data_raw = pd.read_csv(\"Satellite.csv\")\n",
    "print(f\"Columns in dataset: {data_raw.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {data_raw.shape}\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb50c14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 11:32:29,077 - INFO - Converted 36 to category type (has 6 unique values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 2. Preprocess data and detect categorical columns\n",
      "Detected categorical columns: ['36']\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocess data and detect categorical columns\n",
    "print(\"\\n# 2. Preprocess data and detect categorical columns\")\n",
    "data, categorical_columns = preprocess_data(data_raw)\n",
    "print(f\"Detected categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf3cc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3. Define the target column for this dataset\n",
      "Target column: 36\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the target column for this dataset\n",
    "print(\"\\n# 3. Define the target column for this dataset\")\n",
    "target_column = \"36\"\n",
    "print(f\"Target column: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d73d3ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 4. Split the data into features and target\n",
      "Features shape: (4435, 36)\n",
      "Target shape: (4435,)\n",
      "Target distribution:\n",
      "36\n",
      "1    1072\n",
      "7    1038\n",
      "3     961\n",
      "2     479\n",
      "5     470\n",
      "4     415\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Split the data into features and target\n",
    "print(\"\\n# 4. Split the data into features and target\")\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d049f39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 5. Initialize and train TabDDPM\n",
      "Training TabDDPM model...\n",
      "Original data shape: (4435, 37), Target column: 36\n",
      "Added StandardScaler for 36 numerical columns\n",
      "Target '36' identified as categorical with 6 classes\n",
      "Class mapping: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5}\n",
      "\n",
      "Preprocessing Summary:\n",
      "- Number of numerical features: 36\n",
      "- Number of categorical features: 0\n",
      "- Categorical columns: []\n",
      "- Target column: 36\n",
      "- Target type: Categorical\n",
      "- Number of target classes: 6\n",
      "X shape: (4435, 36), y shape: (4435,)\n",
      "X_tensor shape: torch.Size([4435, 36]), y_tensor shape: torch.Size([4435])\n",
      "X_tensor shape: torch.Size([4435, 36])\n",
      "y_tensor shape: torch.Size([4435])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, Loss: 0.2726: 100%|██████████| 300/300 [01:51<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize and train TabDDPM\n",
    "print(\"\\n# 5. Initialize and train TabDDPM\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tabddpm = TabDDPMAdapter(**config[\"tabddpm_params\"], device=device)\n",
    "print(\"Training TabDDPM model...\")\n",
    "tabddpm.fit(X, y)\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c016c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 6. Generate synthetic data\n",
      "Generating 1000 synthetic samples...\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Debug - out_dict type: <class 'torch.Tensor'>\n",
      "Added target column '36' with 6 unique values\n",
      "Final columns in synthetic data: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36']\n",
      "Generated 1000 synthetic samples\n",
      "Synthetic data head:\n",
      "            0          1           2           3           4           5  \\\n",
      "0  107.148330  148.00000  148.400000  166.100000  108.200000  148.000000   \n",
      "1   33.600000   16.00000   47.600000   20.900000   33.800000   16.000000   \n",
      "2  110.400000  148.00000  148.400000  166.100000   40.370002   16.000000   \n",
      "3  110.400000  148.00000  148.400000  166.100000   59.809354   16.000000   \n",
      "4   48.103817   77.46911   85.726173   69.955294   39.709753   51.123032   \n",
      "\n",
      "            6           7           8           9  ...          27  \\\n",
      "0  154.500000  169.800000  110.400000  140.300000  ...  166.000000   \n",
      "1   40.500000   16.200000   33.600000   16.700000  ...   38.064682   \n",
      "2   40.500000   16.200000   33.600000   16.700000  ...  166.000000   \n",
      "3   40.500000   16.200000   33.600000   16.700000  ...  166.000000   \n",
      "4   67.110869   54.457699   33.711874   50.246599  ...   83.215383   \n",
      "\n",
      "           28          29          30          31          32          33  \\\n",
      "0   80.966157  138.100000  154.500000  169.800000  110.400000  140.300000   \n",
      "1   32.500000   26.326326   40.500000   16.200000   33.600000   16.700000   \n",
      "2  110.500000  138.100000  154.500000  159.569653   33.600000   16.700000   \n",
      "3   32.500000  108.789960   64.379390   39.766089   33.600000   16.700000   \n",
      "4   46.585799   77.288237   94.605147   76.231029   41.216794   64.162231   \n",
      "\n",
      "           34          35  36  \n",
      "0  154.500000  169.800000   4  \n",
      "1   40.500000   16.349240   5  \n",
      "2   40.500000   16.200000   3  \n",
      "3   40.500000   16.200000   5  \n",
      "4   70.446017   59.536895   5  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "# 6. Generate synthetic data\n",
    "print(\"\\n# 6. Generate synthetic data\")\n",
    "n_samples = 1000  \n",
    "print(f\"Generating {n_samples} synthetic samples...\")\n",
    "synthetic_data = tabddpm.generate(n_samples)\n",
    "print(f\"Generated {len(synthetic_data)} synthetic samples\")\n",
    "print(\"Synthetic data head:\")\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51d4a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 7. Evaluate quality using TSTR and other metrics\n",
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 11:35:03,124 - INFO - Encoded categorical target with mapping: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:35:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-27 11:35:29,418 - INFO - Encoded categorical targets with mapping: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 7: 5}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:35:34] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-27 11:35:36,538 - INFO - TabDDPM Evaluation Results:\n",
      "2025-04-27 11:35:36,540 - INFO - \n",
      "Likelihood Fitness Metrics:\n",
      "2025-04-27 11:35:36,542 - INFO -   - Lsyn (Synthetic Data Log-Likelihood): -80.0902\n",
      "2025-04-27 11:35:36,544 - INFO -   - Ltest (Real Data Log-Likelihood under Synthetic Model): -125.8065\n",
      "2025-04-27 11:35:36,546 - INFO - \n",
      "Statistical Similarity Metrics:\n",
      "2025-04-27 11:35:36,548 - INFO -   - Wasserstein Distance Mean (Numerical): 34.0298\n",
      "2025-04-27 11:35:36,550 - INFO - \n",
      "Machine Learning Efficacy Metrics on Real Data:\n",
      "2025-04-27 11:35:36,550 - INFO -   LogisticRegression:\n",
      "2025-04-27 11:35:36,552 - INFO -     - Accuracy: 0.8591\n",
      "2025-04-27 11:35:36,554 - INFO -     - F1: 0.8559\n",
      "2025-04-27 11:35:36,557 - INFO -   RandomForest:\n",
      "2025-04-27 11:35:36,559 - INFO -     - Accuracy: 0.9042\n",
      "2025-04-27 11:35:36,560 - INFO -     - F1: 0.9031\n",
      "2025-04-27 11:35:36,563 - INFO -   MLP:\n",
      "2025-04-27 11:35:36,564 - INFO -     - Accuracy: 0.9030\n",
      "2025-04-27 11:35:36,567 - INFO -     - F1: 0.9040\n",
      "2025-04-27 11:35:36,567 - INFO -   XGBoost:\n",
      "2025-04-27 11:35:36,571 - INFO -     - Accuracy: 0.9030\n",
      "2025-04-27 11:35:36,573 - INFO -     - F1: 0.9032\n",
      "2025-04-27 11:35:36,573 - INFO - \n",
      "Machine Learning Utility using TSTR Approach:\n",
      "2025-04-27 11:35:36,575 - INFO -   LogisticRegression:\n",
      "2025-04-27 11:35:36,577 - INFO -     - Accuracy: 0.2681\n",
      "2025-04-27 11:35:36,578 - INFO -     - F1: 0.2113\n",
      "2025-04-27 11:35:36,579 - INFO -   RandomForest:\n",
      "2025-04-27 11:35:36,581 - INFO -     - Accuracy: 0.2746\n",
      "2025-04-27 11:35:36,586 - INFO -     - F1: 0.2888\n",
      "2025-04-27 11:35:36,588 - INFO -   MLP:\n",
      "2025-04-27 11:35:36,599 - INFO -     - Accuracy: 0.3351\n",
      "2025-04-27 11:35:36,601 - INFO -     - F1: 0.3226\n",
      "2025-04-27 11:35:36,605 - INFO -   XGBoost:\n",
      "2025-04-27 11:35:36,607 - INFO -     - Accuracy: 0.2841\n",
      "2025-04-27 11:35:36,609 - INFO -     - F1: 0.3101\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate quality using TSTR and other metrics\n",
    "print(\"\\n# 7. Evaluate quality using TSTR and other metrics\")\n",
    "print(\"Running evaluation...\")\n",
    "evaluation_results = evaluate_tabddpm(data, synthetic_data, target_column=target_column)\n",
    "print_evaluation_results(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69f2fd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 8. TSTR Performance Results\n",
      "                    Accuracy        F1\n",
      "LogisticRegression  0.268095  0.211255\n",
      "RandomForest        0.274634  0.288762\n",
      "MLP                 0.335062  0.322576\n",
      "XGBoost             0.284104  0.310095\n"
     ]
    }
   ],
   "source": [
    "# 8. Extract and display TSTR results specifically\n",
    "print(\"\\n# 8. TSTR Performance Results\")\n",
    "tstr_results = get_tstr_results(evaluation_results)\n",
    "if tstr_results is not None:\n",
    "    print(tstr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16498b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 9. Save synthetic data\n",
      "Synthetic data saved to Satellite_synthetic.csv\n",
      "\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9. Save the synthetic data\n",
    "print(\"\\n# 9. Save synthetic data\")\n",
    "output_path = \"Satellite_synthetic.csv\"\n",
    "synthetic_data.to_csv(output_path, index=False)\n",
    "print(f\"Synthetic data saved to {output_path}\")\n",
    "\n",
    "print(\"\\nTest completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit378",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
