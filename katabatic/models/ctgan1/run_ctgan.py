import os
import sys
import json
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris, load_breast_cancer, load_wine, load_digits
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import logging

# Add the project root directory to the Python path to allow module imports
project_root = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

# Import custom CTGAN adapter and evaluation functions from the katabatic package
from katabatic.models.ctgan.ctgan_adapter import CtganAdapter
from katabatic.models.ctgan.ctgan_benchmark import evaluate_ctgan, print_evaluation_results

# Configure logging to display information-level messages with timestamps
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_config(config_path="katabatic/models/ctgan/config.json"):
    """
    Load the configuration settings from a JSON file.
    
    Args:
        config_path (str): Path to the configuration JSON file.
    
    Returns:
        dict: Configuration settings.
    """
    with open(config_path, "r") as f:
        return json.load(f)

def load_data():
    """
    Load and preprocess multiple datasets for experimentation.
    
    Returns:
        dict: A dictionary containing processed DataFrames for each dataset.
    """
    # Load predefined datasets from scikit-learn
    datasets = {
        "iris": load_iris(),
        "breast_cancer": load_breast_cancer(),
        "wine": load_wine(),
        "digits": load_digits()
    }
    
    processed_datasets = {}
    
    # Iterate over each dataset to preprocess
    for name, dataset in datasets.items():
        # Create a DataFrame for feature data
        X = pd.DataFrame(dataset.data, columns=dataset.feature_names)
        # Create a Series for target labels
        y = pd.Series(dataset.target, name="Category")
        
        # Create a categorical feature by binning the first numerical feature into three categories
        X["categorical_feature"] = pd.cut(X.iloc[:, 0], bins=3, labels=["low", "medium", "high"])
        
        # Combine features and target into a single DataFrame
        data = pd.concat([X, y], axis=1)
        
        # Store the processed DataFrame in the dictionary
        processed_datasets[name] = data
    
    return processed_datasets

def visualize_comparison(real_data, synthetic_data, dataset_name, config):
    """
    Generate and save visual comparisons between real and synthetic data distributions.
    
    Args:
        real_data (pd.DataFrame): The real dataset.
        synthetic_data (pd.DataFrame): The synthetic dataset generated by CTGAN.
        dataset_name (str): Name of the dataset being processed.
        config (dict): Configuration settings containing visualization parameters.
    """
    # Determine the number of features to visualize, ensuring it doesn't exceed available features
    n_features = min(config["visualization"]["n_features"], len(real_data.columns) - 1)
    features = real_data.columns[:n_features]
    
    # Set up subplots for distribution and relationship plots
    fig, axes = plt.subplots(n_features, 2, figsize=tuple(config["visualization"]["figsize"]))
    fig.suptitle(f"Real vs Synthetic Data Distribution - {dataset_name}")
    
    # Iterate over each feature to create plots
    for i, feature in enumerate(features):
        try:
            if real_data[feature].dtype == 'object' or real_data[feature].dtype.name == 'category':
                # For categorical features, plot normalized value counts as bar charts
                real_counts = real_data[feature].value_counts(normalize=True)
                synth_counts = synthetic_data[feature].value_counts(normalize=True)
                pd.concat([real_counts, synth_counts], axis=1, keys=['Real', 'Synthetic']).plot(
                    kind='bar', ax=axes[i, 0]
                )
            else:
                # For numerical features, plot overlapping histograms with KDE
                sns.histplot(real_data[feature], kde=True, ax=axes[i, 0], color='blue', label='Real', stat="density")
                sns.histplot(synthetic_data[feature], kde=True, ax=axes[i, 0], color='red', label='Synthetic', stat="density")
            axes[i, 0].set_title(f"{feature} Distribution")
            axes[i, 0].legend()
        except Exception as e:
            logging.error(f"Error plotting histogram for {feature}: {str(e)}")
        
        try:
            if real_data[feature].dtype == 'object' or real_data[feature].dtype.name == 'category':
                # For categorical features, plot boxen plots against the target variable
                sns.boxenplot(x=feature, y=real_data.columns[-1], data=real_data, ax=axes[i, 1], color='blue')
                sns.boxenplot(x=feature, y=real_data.columns[-1], data=synthetic_data, ax=axes[i, 1], color='red')
            else:
                # For numerical features, plot scatter plots against the target variable
                sns.scatterplot(data=real_data, x=feature, y=real_data.columns[-1], ax=axes[i, 1], color='blue', label='Real')
                sns.scatterplot(data=synthetic_data, x=feature, y=synthetic_data.columns[-1], ax=axes[i, 1], color='red', label='Synthetic')
            axes[i, 1].set_title(f"{feature} vs Category")
            # Consolidate legend to avoid duplicate entries
            handles, labels = axes[i, 1].get_legend_handles_labels()
            by_label = dict(zip(labels, handles))
            axes[i, 1].legend(by_label.values(), by_label.keys())
        except Exception as e:
            logging.error(f"Error plotting scatter for {feature}: {str(e)}")
    
    # Adjust layout to prevent overlap and save the figure
    plt.tight_layout()
    plt.savefig(f"{dataset_name}_comparison.png")
    plt.close()

def run_experiment(dataset_name, X, y, config):
    """
    Conduct the CTGAN training, synthetic data generation, evaluation, and visualization for a given dataset.
    
    Args:
        dataset_name (str): Name of the dataset being processed.
        X (pd.DataFrame): Feature data.
        y (pd.Series): Target labels.
        config (dict): Configuration settings.
    
    Returns:
        dict: Results of the experiment, including evaluation metrics and synthetic data.
    """
    print(f"\nProcessing {dataset_name} dataset")
    
    # Split the data into training and testing sets based on configuration
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, 
        test_size=config["evaluation"]["test_size"],
        random_state=config["evaluation"]["random_state"]
    )

    # Initialize the CTGAN adapter with specified parameters
    ctgan = CtganAdapter(**config["ctgan_params"])
    try:
        # Train the CTGAN model on the training data
        ctgan.fit(X_train, y_train)
    except Exception as e:
        print(f"Error fitting CTGAN model for {dataset_name}: {str(e)}")
        return {"dataset": dataset_name, "error": str(e)}

    try:
        # Generate synthetic data matching the size of the training set
        synthetic_data = ctgan.generate(X_train.shape[0])
    except Exception as e:
        print(f"Error generating synthetic data for {dataset_name}: {str(e)}")
        return {"dataset": dataset_name, "error": str(e)}

    # Combine features and target labels for the real test set
    real_data = pd.concat([X_test, y_test], axis=1)
    try:
        # Evaluate the CTGAN-generated synthetic data against the real data
        evaluation_results = evaluate_ctgan(real_data, synthetic_data)
    except Exception as e:
        print(f"Error evaluating CTGAN for {dataset_name}: {str(e)}")
        return {"dataset": dataset_name, "error": str(e)}

    # Generate and save visual comparisons between real and synthetic data
    visualize_comparison(real_data, synthetic_data, dataset_name, config)

    # Display the evaluation results
    print(f"\n{dataset_name} Dataset Results:")
    print_evaluation_results(evaluation_results)

    return {"dataset": dataset_name, "evaluation_results": evaluation_results, "synthetic_data": synthetic_data}

def main():
    """
    Main function to execute the CTGAN experiments on multiple datasets.
    """
    # Load configuration settings
    config = load_config()
    print("Loaded configuration:", json.dumps(config, indent=2))
    
    # Load and preprocess datasets
    datasets = load_data()

    results = []
    # Iterate over each dataset to perform experiments
    for dataset_name, data in datasets.items():
        X = data.drop("Category", axis=1)
        y = data["Category"]
        # Run the experiment and collect results
        result = run_experiment(dataset_name, X, y, config)
        results.append(result)
        
        if "evaluation_results" in result:
            # Print raw and formatted evaluation results
            print(f"\n{dataset_name} Dataset Results:")
            print("Raw evaluation results:")
            print(json.dumps(result["evaluation_results"], indent=2))
            print("\nFormatted evaluation results:")
            print_evaluation_results(result["evaluation_results"])
        else:
            # Print error messages if any step failed
            print(f"\nError processing {dataset_name} dataset: {result.get('error', 'Unknown error')}")
    
    # Save synthetic data for each successful experiment
    for result in results:
        if "synthetic_data" in result:
            output_file = f"{result['dataset']}_synthetic_data.csv"
            result["synthetic_data"].to_csv(output_file, index=False)
            print(f"\nSynthetic data for {result['dataset']} saved to {output_file}")
        else:
            print(f"\nFailed to generate synthetic data for {result['dataset']}")

    print("\nExperiment completed.")

if __name__ == "__main__":
    main()