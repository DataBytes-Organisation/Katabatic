{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDqMJ3YDwaED",
        "outputId": "f9697eff-9faf-4441-9b52-3c9c0e9ec258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Katabatic/Data/shuttle/shuttle.trn'\n",
        "df = pd.read_csv(file_path, sep='\\s+', header=None)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WozNbqhpwf0x",
        "outputId": "fcd275eb-7619-412d-aa35-959cada3018b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    0   1   2  3   4   5   6   7   8  9\n",
              "0  50  21  77  0  28   0  27  48  22  2\n",
              "1  55   0  92  0   0  26  36  92  56  4\n",
              "2  53   0  82  0  52  -5  29  30   2  1\n",
              "3  37   0  76  0  28  18  40  48   8  1\n",
              "4  37   0  79  0  34 -26  43  46   2  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2850611-bf31-4d35-b9cd-9ac0698f7da9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50</td>\n",
              "      <td>21</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>48</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "      <td>0</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>36</td>\n",
              "      <td>92</td>\n",
              "      <td>56</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>-5</td>\n",
              "      <td>29</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>18</td>\n",
              "      <td>40</td>\n",
              "      <td>48</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>-26</td>\n",
              "      <td>43</td>\n",
              "      <td>46</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2850611-bf31-4d35-b9cd-9ac0698f7da9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2850611-bf31-4d35-b9cd-9ac0698f7da9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2850611-bf31-4d35-b9cd-9ac0698f7da9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2e73df7e-7311-4f1d-9066-c076702b6cfd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e73df7e-7311-4f1d-9066-c076702b6cfd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2e73df7e-7311-4f1d-9066-c076702b6cfd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 43500,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 27,\n        \"max\": 126,\n        \"num_unique_values\": 72,\n        \"samples\": [\n          85,\n          111,\n          76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78,\n        \"min\": -4821,\n        \"max\": 5075,\n        \"num_unique_values\": 177,\n        \"samples\": [\n          -38,\n          -14,\n          -25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 21,\n        \"max\": 149,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          85,\n          73,\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41,\n        \"min\": -3939,\n        \"max\": 3830,\n        \"num_unique_values\": 121,\n        \"samples\": [\n          -45,\n          -17,\n          -2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": -188,\n        \"max\": 436,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          56,\n          10,\n          64\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 179,\n        \"min\": -13839,\n        \"max\": 13148,\n        \"num_unique_values\": 261,\n        \"samples\": [\n          15,\n          -267,\n          91\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13,\n        \"min\": -48,\n        \"max\": 105,\n        \"num_unique_values\": 83,\n        \"samples\": [\n          44,\n          27,\n          58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": -353,\n        \"max\": 270,\n        \"num_unique_values\": 120,\n        \"samples\": [\n          64,\n          103,\n          83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": -356,\n        \"max\": 266,\n        \"num_unique_values\": 75,\n        \"samples\": [\n          80,\n          52,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2,\n          4,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Data Preparation\n",
        "class ShuttleDataset(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        # Load data with whitespace delimiter; no header in file\n",
        "        self.data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "        # All columns except the last are features; last column is label (adjust from 1-7 to 0-6)\n",
        "        self.features = self.data.iloc[:, :-1].values\n",
        "        self.labels = self.data.iloc[:, -1].values - 1\n",
        "        self.features = self.scaler.fit_transform(self.features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.features[idx]), torch.LongTensor([self.labels[idx]])\n",
        "\n",
        "# Set the file path (adjust to your Google Drive folder structure)\n",
        "file_path = \"/content/drive/MyDrive/Katabatic/Data/shuttle/shuttle.trn\"\n",
        "dataset = ShuttleDataset(file_path)\n",
        "\n",
        "# Split the Dataset\n",
        "# Use random_split to divide the dataset into train (80%) and test (20%)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# Alternatively, you can use train_test_split on the entire dataset features/labels\n",
        "# X_train, X_test, y_train, y_test = train_test_split(dataset.features, dataset.labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define Network Component\n",
        "# Deeper Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, output_dim),\n",
        "            nn.Tanh()  # Tanh squashes outputs to [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.fc(z)\n",
        "\n",
        "# Deeper Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()  # Output probability\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "#Initialize Models\n",
        "latent_dim = 100\n",
        "generator = Generator(latent_dim, dataset.features.shape[1])\n",
        "discriminator = Discriminator(dataset.features.shape[1])\n",
        "\n",
        "#Train CRAMERGAN with Learning Rate Schedulers\n",
        "def train_cramer_gan(generator, discriminator, dataloader, epochs=100):\n",
        "    device = torch.device('cpu')  # Force CPU for stability\n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "\n",
        "    optimizer_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "    # Learning rate schedulers: reduce LR every 20 epochs by half\n",
        "    scheduler_g = optim.lr_scheduler.StepLR(optimizer_g, step_size=20, gamma=0.5)\n",
        "    scheduler_d = optim.lr_scheduler.StepLR(optimizer_d, step_size=20, gamma=0.5)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for real_data, _ in dataloader:\n",
        "            real_data = real_data.to(device)\n",
        "            batch_size = real_data.size(0)\n",
        "\n",
        "            # Train Discriminator\n",
        "            optimizer_d.zero_grad()\n",
        "            z = torch.randn(batch_size, latent_dim).to(device)\n",
        "            fake_data = generator(z).detach()\n",
        "            real_labels = torch.ones(batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "            loss_real = criterion(discriminator(real_data), real_labels)\n",
        "            loss_fake = criterion(discriminator(fake_data), fake_labels)\n",
        "            loss_d = loss_real + loss_fake\n",
        "            loss_d.backward()\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # Train Generator\n",
        "            optimizer_g.zero_grad()\n",
        "            z = torch.randn(batch_size, latent_dim).to(device)\n",
        "            fake_data = generator(z)\n",
        "            loss_g = criterion(discriminator(fake_data), real_labels)\n",
        "            loss_g.backward()\n",
        "            optimizer_g.step()\n",
        "\n",
        "        scheduler_g.step()\n",
        "        scheduler_d.step()\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] - Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}\")\n",
        "\n",
        "# Train CRAMERGAN on the training set only\n",
        "train_cramer_gan(generator, discriminator, train_dataloader, epochs=100)\n",
        "\n",
        "# Generate Synthetic Data\n",
        "def generate_synthetic_data(generator, num_samples, latent_dim):\n",
        "    device = torch.device('cpu')\n",
        "    generator.eval()\n",
        "    z = torch.randn(num_samples, latent_dim).to(device)\n",
        "    synthetic_data = generator(z).detach().cpu().numpy()\n",
        "    return synthetic_data\n",
        "\n",
        "# Generate synthetic samples equal to the number of training samples\n",
        "num_synthetic_samples = len(train_dataset)\n",
        "synthetic_data = generate_synthetic_data(generator, num_synthetic_samples, latent_dim)\n",
        "\n",
        "# Inverse transform synthetic data to original scale\n",
        "scaler = dataset.scaler\n",
        "synthetic_data = scaler.inverse_transform(synthetic_data)\n",
        "\n",
        "# Benchmark: Print number of synthetic samples generated\n",
        "print(\"Number of synthetic samples generated:\", synthetic_data.shape[0])\n",
        "\n",
        "#Evaluate Models\n",
        "# For classifier training, we will mix real and synthetic training data 50/50.\n",
        "# Extract real training data (features and labels) from train_dataset\n",
        "train_indices = train_dataset.indices  # These are the indices from the original dataset\n",
        "X_train_real = dataset.features[train_indices]\n",
        "y_train_real = np.array(dataset.labels)[train_indices]\n",
        "\n",
        "# Combine synthetic data with real training data\n",
        "combined_data = np.concatenate([X_train_real, synthetic_data], axis=0)\n",
        "combined_labels = np.concatenate([y_train_real, y_train_real], axis=0)\n",
        "\n",
        "# Use test set from random_split for evaluation\n",
        "test_indices = test_dataset.indices\n",
        "X_test = dataset.features[test_indices]\n",
        "y_test = np.array(dataset.labels)[test_indices]\n",
        "\n",
        "# Initialize classifiers with tuned hyperparameters\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=5000, solver='lbfgs', C=1.0),\n",
        "    \"MLP\": MLPClassifier(hidden_layer_sizes=(128,64), max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=200),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=200, max_depth=6, learning_rate=0.1)\n",
        "}\n",
        "\n",
        "results = []\n",
        "print(\"\\nClassifier Evaluation Results (trained on 50/50 combined data, tested on real test set):\")\n",
        "for name, model in models.items():\n",
        "    model.fit(combined_data, combined_labels)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    results.append((name, acc))\n",
        "    print(f\"{name}: {acc:.4f}\")\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\"])\n",
        "print(\"\\n\", results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4J6jZiSwlbb",
        "outputId": "086ab134-a21f-411b-9b14-b506bc7d491c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-71910d76cbc1>:22: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  self.data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] - Loss D: 0.4429, Loss G: 2.2246\n",
            "Epoch [2/100] - Loss D: 0.4622, Loss G: 2.1171\n",
            "Epoch [3/100] - Loss D: 0.6123, Loss G: 1.9669\n",
            "Epoch [4/100] - Loss D: 0.8521, Loss G: 1.5285\n",
            "Epoch [5/100] - Loss D: 1.2542, Loss G: 0.9948\n",
            "Epoch [6/100] - Loss D: 0.9271, Loss G: 1.0488\n",
            "Epoch [7/100] - Loss D: 1.1312, Loss G: 0.9343\n",
            "Epoch [8/100] - Loss D: 0.9351, Loss G: 1.0368\n",
            "Epoch [9/100] - Loss D: 1.0200, Loss G: 1.0565\n",
            "Epoch [10/100] - Loss D: 1.0402, Loss G: 1.0515\n",
            "Epoch [11/100] - Loss D: 1.0065, Loss G: 0.9572\n",
            "Epoch [12/100] - Loss D: 1.0739, Loss G: 0.9508\n",
            "Epoch [13/100] - Loss D: 1.0857, Loss G: 0.9819\n",
            "Epoch [14/100] - Loss D: 0.8548, Loss G: 1.0965\n",
            "Epoch [15/100] - Loss D: 1.0152, Loss G: 1.1284\n",
            "Epoch [16/100] - Loss D: 1.0332, Loss G: 1.0676\n",
            "Epoch [17/100] - Loss D: 0.8859, Loss G: 1.0870\n",
            "Epoch [18/100] - Loss D: 1.0951, Loss G: 1.1138\n",
            "Epoch [19/100] - Loss D: 0.9584, Loss G: 1.1423\n",
            "Epoch [20/100] - Loss D: 0.8521, Loss G: 1.1208\n",
            "Epoch [21/100] - Loss D: 0.9601, Loss G: 1.0708\n",
            "Epoch [22/100] - Loss D: 1.0702, Loss G: 1.1169\n",
            "Epoch [23/100] - Loss D: 0.8955, Loss G: 1.1757\n",
            "Epoch [24/100] - Loss D: 0.8391, Loss G: 1.1196\n",
            "Epoch [25/100] - Loss D: 0.8846, Loss G: 1.1035\n",
            "Epoch [26/100] - Loss D: 0.9842, Loss G: 1.1064\n",
            "Epoch [27/100] - Loss D: 0.9714, Loss G: 1.1717\n",
            "Epoch [28/100] - Loss D: 0.6407, Loss G: 1.2995\n",
            "Epoch [29/100] - Loss D: 0.8883, Loss G: 1.1377\n",
            "Epoch [30/100] - Loss D: 1.0258, Loss G: 1.1196\n",
            "Epoch [31/100] - Loss D: 1.1283, Loss G: 1.2421\n",
            "Epoch [32/100] - Loss D: 0.8781, Loss G: 1.1422\n",
            "Epoch [33/100] - Loss D: 0.7460, Loss G: 1.1707\n",
            "Epoch [34/100] - Loss D: 0.9978, Loss G: 1.0784\n",
            "Epoch [35/100] - Loss D: 0.9237, Loss G: 1.1570\n",
            "Epoch [36/100] - Loss D: 0.8877, Loss G: 1.2526\n",
            "Epoch [37/100] - Loss D: 0.8325, Loss G: 1.2006\n",
            "Epoch [38/100] - Loss D: 0.8145, Loss G: 1.1519\n",
            "Epoch [39/100] - Loss D: 0.9498, Loss G: 1.1750\n",
            "Epoch [40/100] - Loss D: 0.8073, Loss G: 1.0909\n",
            "Epoch [41/100] - Loss D: 0.7588, Loss G: 1.1005\n",
            "Epoch [42/100] - Loss D: 0.9316, Loss G: 1.1113\n",
            "Epoch [43/100] - Loss D: 0.8114, Loss G: 1.1614\n",
            "Epoch [44/100] - Loss D: 0.9010, Loss G: 1.1888\n",
            "Epoch [45/100] - Loss D: 0.9902, Loss G: 1.1525\n",
            "Epoch [46/100] - Loss D: 0.9715, Loss G: 1.2120\n",
            "Epoch [47/100] - Loss D: 0.9797, Loss G: 1.1086\n",
            "Epoch [48/100] - Loss D: 1.0715, Loss G: 1.1600\n",
            "Epoch [49/100] - Loss D: 1.0108, Loss G: 1.1114\n",
            "Epoch [50/100] - Loss D: 0.9779, Loss G: 1.0895\n",
            "Epoch [51/100] - Loss D: 0.9314, Loss G: 1.1112\n",
            "Epoch [52/100] - Loss D: 0.8233, Loss G: 1.1055\n",
            "Epoch [53/100] - Loss D: 1.1087, Loss G: 1.1757\n",
            "Epoch [54/100] - Loss D: 1.0162, Loss G: 1.1485\n",
            "Epoch [55/100] - Loss D: 0.8437, Loss G: 1.0970\n",
            "Epoch [56/100] - Loss D: 0.8622, Loss G: 1.1449\n",
            "Epoch [57/100] - Loss D: 0.8712, Loss G: 1.1083\n",
            "Epoch [58/100] - Loss D: 0.8326, Loss G: 1.0987\n",
            "Epoch [59/100] - Loss D: 0.9469, Loss G: 1.1942\n",
            "Epoch [60/100] - Loss D: 0.9298, Loss G: 1.1227\n",
            "Epoch [61/100] - Loss D: 0.9528, Loss G: 1.1342\n",
            "Epoch [62/100] - Loss D: 0.9208, Loss G: 1.1483\n",
            "Epoch [63/100] - Loss D: 0.9791, Loss G: 1.1617\n",
            "Epoch [64/100] - Loss D: 0.9131, Loss G: 1.1392\n",
            "Epoch [65/100] - Loss D: 0.9453, Loss G: 1.1772\n",
            "Epoch [66/100] - Loss D: 1.0238, Loss G: 1.2160\n",
            "Epoch [67/100] - Loss D: 0.7128, Loss G: 1.1091\n",
            "Epoch [68/100] - Loss D: 0.8431, Loss G: 1.1655\n",
            "Epoch [69/100] - Loss D: 0.8951, Loss G: 1.1652\n",
            "Epoch [70/100] - Loss D: 0.8624, Loss G: 1.1641\n",
            "Epoch [71/100] - Loss D: 0.8793, Loss G: 1.1820\n",
            "Epoch [72/100] - Loss D: 0.9211, Loss G: 1.1494\n",
            "Epoch [73/100] - Loss D: 0.9839, Loss G: 1.1333\n",
            "Epoch [74/100] - Loss D: 0.8713, Loss G: 1.1236\n",
            "Epoch [75/100] - Loss D: 1.0231, Loss G: 1.1899\n",
            "Epoch [76/100] - Loss D: 1.1103, Loss G: 1.1661\n",
            "Epoch [77/100] - Loss D: 0.8701, Loss G: 1.1799\n",
            "Epoch [78/100] - Loss D: 0.8758, Loss G: 1.1634\n",
            "Epoch [79/100] - Loss D: 0.9042, Loss G: 1.1535\n",
            "Epoch [80/100] - Loss D: 0.9206, Loss G: 1.1116\n",
            "Epoch [81/100] - Loss D: 0.9776, Loss G: 1.1522\n",
            "Epoch [82/100] - Loss D: 0.8368, Loss G: 1.1508\n",
            "Epoch [83/100] - Loss D: 0.9138, Loss G: 1.1403\n",
            "Epoch [84/100] - Loss D: 0.9338, Loss G: 1.1073\n",
            "Epoch [85/100] - Loss D: 1.0153, Loss G: 1.1426\n",
            "Epoch [86/100] - Loss D: 0.8996, Loss G: 1.1252\n",
            "Epoch [87/100] - Loss D: 0.8073, Loss G: 1.1226\n",
            "Epoch [88/100] - Loss D: 0.9601, Loss G: 1.1478\n",
            "Epoch [89/100] - Loss D: 0.9012, Loss G: 1.1469\n",
            "Epoch [90/100] - Loss D: 0.9413, Loss G: 1.1550\n",
            "Epoch [91/100] - Loss D: 1.0380, Loss G: 1.1337\n",
            "Epoch [92/100] - Loss D: 0.9667, Loss G: 1.1577\n",
            "Epoch [93/100] - Loss D: 0.8355, Loss G: 1.1437\n",
            "Epoch [94/100] - Loss D: 0.8643, Loss G: 1.1146\n",
            "Epoch [95/100] - Loss D: 0.9505, Loss G: 1.1498\n",
            "Epoch [96/100] - Loss D: 0.9385, Loss G: 1.1358\n",
            "Epoch [97/100] - Loss D: 0.7746, Loss G: 1.0983\n",
            "Epoch [98/100] - Loss D: 1.0637, Loss G: 1.1606\n",
            "Epoch [99/100] - Loss D: 0.9923, Loss G: 1.1366\n",
            "Epoch [100/100] - Loss D: 0.9519, Loss G: 1.1609\n",
            "Number of synthetic samples generated: 34800\n",
            "\n",
            "Classifier Evaluation Results (trained on 50/50 combined data, tested on real test set):\n",
            "Logistic Regression: 0.8409\n",
            "MLP: 0.9990\n",
            "Random Forest: 0.9994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [08:28:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost: 0.9994\n",
            "\n",
            "                  Model  Accuracy\n",
            "0  Logistic Regression  0.840920\n",
            "1                  MLP  0.998966\n",
            "2        Random Forest  0.999425\n",
            "3              XGBoost  0.999425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Generate Synthetic Data and Save to CSV ---\n",
        "\n",
        "# Define the synthetic data generation function if not already defined\n",
        "def generate_synthetic_data(generator, num_samples, latent_dim):\n",
        "    import torch\n",
        "    device = torch.device('cpu')  # using CPU\n",
        "    generator.eval()\n",
        "    # Generate synthetic samples using random noise\n",
        "    z = torch.randn(num_samples, latent_dim).to(device)\n",
        "    synthetic_data = generator(z).detach().cpu().numpy()\n",
        "    return synthetic_data\n",
        "\n",
        "# Generate synthetic data equal to the number of real samples in the dataset\n",
        "num_synthetic_samples = len(dataset)  # Or change to desired number\n",
        "synthetic_data = generate_synthetic_data(generator, num_synthetic_samples, latent_dim)\n",
        "\n",
        "# Inverse transform synthetic data to the original scale using the dataset's scaler\n",
        "scaler = dataset.scaler\n",
        "synthetic_data = scaler.inverse_transform(synthetic_data)\n",
        "\n",
        "# Convert the synthetic data to a DataFrame\n",
        "import pandas as pd\n",
        "synthetic_df = pd.DataFrame(synthetic_data, columns=[f\"Feature {i}\" for i in range(synthetic_data.shape[1])])\n",
        "\n",
        "# Display the first few rows and the number of synthetic samples generated\n",
        "print(\"Synthetic Data Sample:\")\n",
        "print(synthetic_df.head())\n",
        "print(\"Number of synthetic samples generated:\", synthetic_df.shape[0])\n",
        "csv_save_path = \"/content/drive/MyDrive/Katabatic/Data/shuttle/synthetic_shuttle_data.csv\"\n",
        "synthetic_df.to_csv(csv_save_path, index=False)\n",
        "print(\"Synthetic data saved to:\", csv_save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjHoB88fN6Bl",
        "outputId": "020b60a5-cbd9-4f34-c71e-f05670f19b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic Data Sample:\n",
            "   Feature 0  Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  \\\n",
            "0  43.970901  -2.194612  76.998077  -1.191187  44.705463   8.539552   \n",
            "1  37.018997  -4.740286  76.980888   1.130539  36.164509  12.483049   \n",
            "2  46.616024  -2.046196  78.349693  -1.913286  46.613731  11.427321   \n",
            "3  36.798141  -5.676992  76.970856   1.376222  34.304890   0.064882   \n",
            "4  46.290962  -1.709328  79.283478  -1.689941  45.675858   1.922915   \n",
            "\n",
            "   Feature 6  Feature 7  Feature 8  \n",
            "0  33.353672  32.578854   0.402071  \n",
            "1  40.154476  40.740238   0.924166  \n",
            "2  31.749687  31.007275   0.517446  \n",
            "3  40.178055  42.646454   2.346477  \n",
            "4  33.028225  32.559162   0.246216  \n",
            "Number of synthetic samples generated: 43500\n",
            "Synthetic data saved to: /content/drive/MyDrive/Katabatic/Data/shuttle/synthetic_shuttle_data.csv\n"
          ]
        }
      ]
    }
  ]
}