{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\61411\\AppData\\Local\\Temp\\ipykernel_34420\\532753869.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(\"C:/Users/61411/OneDrive - Deakin University/Desktop/Local_Katabatic_Repository/Katabatic/data/shuttle/shuttle.trn\", delim_whitespace=True, header=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>92</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>-5</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>-26</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2  3   4   5   6   7   8  9\n",
       "0  50  21  77  0  28   0  27  48  22  2\n",
       "1  55   0  92  0   0  26  36  92  56  4\n",
       "2  53   0  82  0  52  -5  29  30   2  1\n",
       "3  37   0  76  0  28  18  40  48   8  1\n",
       "4  37   0  79  0  34 -26  43  46   2  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "#Load shuttle dataset\n",
    "df = pd.read_csv(\"C:/Users/61411/OneDrive - Deakin University/Desktop/Local_Katabatic_Repository/Katabatic/data/shuttle/shuttle.trn\", delim_whitespace=True, header=None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\61411\\AppData\\Local\\Temp\\ipykernel_34420\\2235807836.py:12: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  self.data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss D: 0.7294900417327881, Loss G: 1.514638900756836\n",
      "Epoch [2/100], Loss D: 0.3036311864852905, Loss G: 2.7119061946868896\n",
      "Epoch [3/100], Loss D: 0.9956610202789307, Loss G: 1.7124689817428589\n",
      "Epoch [4/100], Loss D: 0.8497650623321533, Loss G: 1.3429328203201294\n",
      "Epoch [5/100], Loss D: 1.0902647972106934, Loss G: 0.9602717757225037\n",
      "Epoch [6/100], Loss D: 0.9476759433746338, Loss G: 1.0110349655151367\n",
      "Epoch [7/100], Loss D: 0.9747903943061829, Loss G: 0.9251346588134766\n",
      "Epoch [8/100], Loss D: 1.034498691558838, Loss G: 0.9583221673965454\n",
      "Epoch [9/100], Loss D: 1.1529650688171387, Loss G: 0.9314464330673218\n",
      "Epoch [10/100], Loss D: 1.0188404321670532, Loss G: 0.9554740786552429\n",
      "Epoch [11/100], Loss D: 1.0794105529785156, Loss G: 1.0219515562057495\n",
      "Epoch [12/100], Loss D: 1.0655839443206787, Loss G: 0.9548749327659607\n",
      "Epoch [13/100], Loss D: 1.0265991687774658, Loss G: 1.015663981437683\n",
      "Epoch [14/100], Loss D: 1.0152918100357056, Loss G: 1.067575216293335\n",
      "Epoch [15/100], Loss D: 0.9317060708999634, Loss G: 0.9701204299926758\n",
      "Epoch [16/100], Loss D: 1.0145742893218994, Loss G: 0.9945839047431946\n",
      "Epoch [17/100], Loss D: 1.0182640552520752, Loss G: 0.9765535593032837\n",
      "Epoch [18/100], Loss D: 1.0279128551483154, Loss G: 1.0536901950836182\n",
      "Epoch [19/100], Loss D: 0.845953106880188, Loss G: 1.1145281791687012\n",
      "Epoch [20/100], Loss D: 1.0962932109832764, Loss G: 0.9951658844947815\n",
      "Epoch [21/100], Loss D: 1.0673718452453613, Loss G: 1.0098999738693237\n",
      "Epoch [22/100], Loss D: 0.9619136452674866, Loss G: 1.1122088432312012\n",
      "Epoch [23/100], Loss D: 0.8406808376312256, Loss G: 1.0234744548797607\n",
      "Epoch [24/100], Loss D: 0.9508376121520996, Loss G: 0.9842624664306641\n",
      "Epoch [25/100], Loss D: 0.8495309352874756, Loss G: 1.114998698234558\n",
      "Epoch [26/100], Loss D: 1.1170520782470703, Loss G: 1.0040242671966553\n",
      "Epoch [27/100], Loss D: 0.942298948764801, Loss G: 1.1005741357803345\n",
      "Epoch [28/100], Loss D: 0.8717340230941772, Loss G: 1.1956720352172852\n",
      "Epoch [29/100], Loss D: 1.0562649965286255, Loss G: 1.0848902463912964\n",
      "Epoch [30/100], Loss D: 0.9261074662208557, Loss G: 1.031364917755127\n",
      "Epoch [31/100], Loss D: 0.9064286351203918, Loss G: 1.0598421096801758\n",
      "Epoch [32/100], Loss D: 0.948113203048706, Loss G: 1.0668941736221313\n",
      "Epoch [33/100], Loss D: 1.0330792665481567, Loss G: 1.1083515882492065\n",
      "Epoch [34/100], Loss D: 0.9283108711242676, Loss G: 1.1188260316848755\n",
      "Epoch [35/100], Loss D: 0.8378547430038452, Loss G: 1.1147602796554565\n",
      "Epoch [36/100], Loss D: 1.0041868686676025, Loss G: 1.0844851732254028\n",
      "Epoch [37/100], Loss D: 0.7796425819396973, Loss G: 1.0821185111999512\n",
      "Epoch [38/100], Loss D: 0.9958100318908691, Loss G: 1.2118210792541504\n",
      "Epoch [39/100], Loss D: 1.017215371131897, Loss G: 1.1049574613571167\n",
      "Epoch [40/100], Loss D: 1.0027940273284912, Loss G: 1.186252236366272\n",
      "Epoch [41/100], Loss D: 0.7763730883598328, Loss G: 1.1414042711257935\n",
      "Epoch [42/100], Loss D: 0.9499332904815674, Loss G: 1.2031588554382324\n",
      "Epoch [43/100], Loss D: 0.8240153789520264, Loss G: 1.1640740633010864\n",
      "Epoch [44/100], Loss D: 0.9860117435455322, Loss G: 1.2006515264511108\n",
      "Epoch [45/100], Loss D: 0.8177937269210815, Loss G: 1.0895652770996094\n",
      "Epoch [46/100], Loss D: 0.9759132862091064, Loss G: 1.1734728813171387\n",
      "Epoch [47/100], Loss D: 1.0180604457855225, Loss G: 1.2162855863571167\n",
      "Epoch [48/100], Loss D: 0.8703606724739075, Loss G: 1.167583703994751\n",
      "Epoch [49/100], Loss D: 0.9876485466957092, Loss G: 1.1019153594970703\n",
      "Epoch [50/100], Loss D: 0.9258719086647034, Loss G: 1.161539912223816\n",
      "Epoch [51/100], Loss D: 0.85843425989151, Loss G: 1.0678473711013794\n",
      "Epoch [52/100], Loss D: 0.9046468734741211, Loss G: 1.1617296934127808\n",
      "Epoch [53/100], Loss D: 0.78651362657547, Loss G: 1.1529301404953003\n",
      "Epoch [54/100], Loss D: 0.9743080139160156, Loss G: 1.011536955833435\n",
      "Epoch [55/100], Loss D: 1.138403296470642, Loss G: 1.1089226007461548\n",
      "Epoch [56/100], Loss D: 0.861437201499939, Loss G: 1.1732966899871826\n",
      "Epoch [57/100], Loss D: 0.8797118663787842, Loss G: 1.2203391790390015\n",
      "Epoch [58/100], Loss D: 0.9465507864952087, Loss G: 1.1597167253494263\n",
      "Epoch [59/100], Loss D: 0.8648619651794434, Loss G: 1.0979082584381104\n",
      "Epoch [60/100], Loss D: 0.8614389896392822, Loss G: 1.1495184898376465\n",
      "Epoch [61/100], Loss D: 0.8758397102355957, Loss G: 1.2523669004440308\n",
      "Epoch [62/100], Loss D: 1.032734751701355, Loss G: 1.1432738304138184\n",
      "Epoch [63/100], Loss D: 0.9681646823883057, Loss G: 1.097525715827942\n",
      "Epoch [64/100], Loss D: 0.8500451445579529, Loss G: 1.154548168182373\n",
      "Epoch [65/100], Loss D: 0.9438854455947876, Loss G: 1.1274887323379517\n",
      "Epoch [66/100], Loss D: 0.9277380704879761, Loss G: 1.172542691230774\n",
      "Epoch [67/100], Loss D: 0.9723795652389526, Loss G: 1.185698390007019\n",
      "Epoch [68/100], Loss D: 1.0490705966949463, Loss G: 1.1463509798049927\n",
      "Epoch [69/100], Loss D: 0.9647747278213501, Loss G: 1.127048373222351\n",
      "Epoch [70/100], Loss D: 0.9852101802825928, Loss G: 1.114888072013855\n",
      "Epoch [71/100], Loss D: 0.9372011423110962, Loss G: 1.1428718566894531\n",
      "Epoch [72/100], Loss D: 0.9300076961517334, Loss G: 1.1550244092941284\n",
      "Epoch [73/100], Loss D: 0.8172842860221863, Loss G: 1.0908281803131104\n",
      "Epoch [74/100], Loss D: 0.9838345050811768, Loss G: 1.1295990943908691\n",
      "Epoch [75/100], Loss D: 1.041738748550415, Loss G: 1.0409858226776123\n",
      "Epoch [76/100], Loss D: 1.0071064233779907, Loss G: 1.190679669380188\n",
      "Epoch [77/100], Loss D: 0.9209483861923218, Loss G: 1.1093164682388306\n",
      "Epoch [78/100], Loss D: 1.0235586166381836, Loss G: 1.1886426210403442\n",
      "Epoch [79/100], Loss D: 0.7725293636322021, Loss G: 1.094688057899475\n",
      "Epoch [80/100], Loss D: 1.1858298778533936, Loss G: 1.1299721002578735\n",
      "Epoch [81/100], Loss D: 1.0211124420166016, Loss G: 1.1170672178268433\n",
      "Epoch [82/100], Loss D: 0.9446086883544922, Loss G: 1.2457175254821777\n",
      "Epoch [83/100], Loss D: 0.9195581674575806, Loss G: 1.0480284690856934\n",
      "Epoch [84/100], Loss D: 0.8558295965194702, Loss G: 1.2128541469573975\n",
      "Epoch [85/100], Loss D: 0.9346048831939697, Loss G: 1.1007579565048218\n",
      "Epoch [86/100], Loss D: 1.0160932540893555, Loss G: 1.1212761402130127\n",
      "Epoch [87/100], Loss D: 1.0051683187484741, Loss G: 1.085033655166626\n",
      "Epoch [88/100], Loss D: 1.0432218313217163, Loss G: 1.0680850744247437\n",
      "Epoch [89/100], Loss D: 0.9316378831863403, Loss G: 1.1566424369812012\n",
      "Epoch [90/100], Loss D: 1.0302947759628296, Loss G: 1.106465458869934\n",
      "Epoch [91/100], Loss D: 1.0205103158950806, Loss G: 1.1878275871276855\n",
      "Epoch [92/100], Loss D: 0.9100689888000488, Loss G: 1.0984752178192139\n",
      "Epoch [93/100], Loss D: 0.9528415203094482, Loss G: 1.076836109161377\n",
      "Epoch [94/100], Loss D: 1.135929822921753, Loss G: 1.0911468267440796\n",
      "Epoch [95/100], Loss D: 1.0150094032287598, Loss G: 1.0768803358078003\n",
      "Epoch [96/100], Loss D: 1.107234001159668, Loss G: 1.1142090559005737\n",
      "Epoch [97/100], Loss D: 0.8029165863990784, Loss G: 1.2200405597686768\n",
      "Epoch [98/100], Loss D: 0.952438235282898, Loss G: 1.1235454082489014\n",
      "Epoch [99/100], Loss D: 0.9243069291114807, Loss G: 1.1756969690322876\n",
      "Epoch [100/100], Loss D: 0.9252034425735474, Loss G: 1.1539758443832397\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Data Preparation\n",
    "class ShuttleDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.data = pd.read_csv(file_path, delim_whitespace=True, header=None)\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "        # Last column is the label\n",
    "        self.features = self.data.iloc[:, :-1].values\n",
    "        self.labels = self.data.iloc[:, -1].values - 1\n",
    "        \n",
    "        self.features = self.scaler.fit_transform(self.features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.features[idx]), torch.LongTensor([self.labels[idx]])\n",
    "\n",
    "# Load the Shuttle dataset (.trn file)\n",
    "dataset = ShuttleDataset(\"C:/Users/61411/OneDrive - Deakin University/Desktop/Local_Katabatic_Repository/Katabatic/data/shuttle/shuttle.trn\")\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 2. Define Network Components\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.fc(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Initialize models\n",
    "latent_dim = 100\n",
    "generator = Generator(latent_dim, dataset.features.shape[1])\n",
    "discriminator = Discriminator(dataset.features.shape[1])\n",
    "\n",
    "# 3. Training Loop\n",
    "def train_cramer_gan(generator, discriminator, dataloader, epochs=100):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    generator.to(device)\n",
    "    discriminator.to(device)\n",
    "    \n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for real_data, _ in dataloader:\n",
    "            real_data = real_data.to(device)\n",
    "            batch_size = real_data.size(0)\n",
    "            \n",
    "            # Train Discriminator\n",
    "            optimizer_d.zero_grad()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_data = generator(z).detach()\n",
    "            \n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "            loss_real = criterion(discriminator(real_data), real_labels)\n",
    "            loss_fake = criterion(discriminator(fake_data), fake_labels)\n",
    "            loss_d = loss_real + loss_fake\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "\n",
    "            # Train Generator\n",
    "            optimizer_g.zero_grad()\n",
    "            z = torch.randn(batch_size, latent_dim).to(device)\n",
    "            fake_data = generator(z)\n",
    "            loss_g = criterion(discriminator(fake_data), real_labels)\n",
    "            loss_g.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss D: {loss_d.item()}, Loss G: {loss_g.item()}')\n",
    "\n",
    "# Start Training\n",
    "train_cramer_gan(generator, discriminator, dataloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.7837\n",
      "MLP: 0.7841\n",
      "RF: 0.7451\n",
      "XGBT: 0.7302\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "generator.eval()\n",
    "num_samples = len(dataset)\n",
    "z = torch.randn(num_samples, latent_dim).to('cpu')  # Match real data count\n",
    "synthetic_data = generator(z).detach().numpy()\n",
    "real_labels = dataset.labels  # from the Dataset class\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train and evaluate\n",
    "models = {\n",
    "    \"LR\": LogisticRegression(),\n",
    "    \"MLP\": MLPClassifier(),\n",
    "    \"RF\": RandomForestClassifier(),\n",
    "    \"XGBT\": XGBClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(synthetic_data, real_labels)\n",
    "    preds = model.predict(dataset.features)  # Evaluate on real data\n",
    "    acc = accuracy_score(real_labels, preds)\n",
    "    print(f\"{name}: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.209404</td>\n",
       "      <td>-0.063460</td>\n",
       "      <td>-0.344881</td>\n",
       "      <td>0.065880</td>\n",
       "      <td>0.494913</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>-0.042471</td>\n",
       "      <td>-0.638542</td>\n",
       "      <td>-0.520761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.915200</td>\n",
       "      <td>-0.021878</td>\n",
       "      <td>-0.908336</td>\n",
       "      <td>0.012734</td>\n",
       "      <td>-0.471409</td>\n",
       "      <td>0.030079</td>\n",
       "      <td>0.267926</td>\n",
       "      <td>0.124677</td>\n",
       "      <td>-0.067652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194794</td>\n",
       "      <td>-0.048422</td>\n",
       "      <td>0.151622</td>\n",
       "      <td>0.018783</td>\n",
       "      <td>0.663420</td>\n",
       "      <td>-0.061387</td>\n",
       "      <td>-0.087623</td>\n",
       "      <td>-0.561768</td>\n",
       "      <td>-0.466256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.505625</td>\n",
       "      <td>-0.043630</td>\n",
       "      <td>-0.375797</td>\n",
       "      <td>0.013232</td>\n",
       "      <td>0.345206</td>\n",
       "      <td>0.017632</td>\n",
       "      <td>0.201714</td>\n",
       "      <td>-0.436891</td>\n",
       "      <td>-0.527415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.483685</td>\n",
       "      <td>-0.053000</td>\n",
       "      <td>0.184205</td>\n",
       "      <td>0.014867</td>\n",
       "      <td>0.370311</td>\n",
       "      <td>-0.018831</td>\n",
       "      <td>0.589455</td>\n",
       "      <td>-0.219688</td>\n",
       "      <td>-0.505142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.209404 -0.063460 -0.344881  0.065880  0.494913  0.010283 -0.042471   \n",
       "1 -0.915200 -0.021878 -0.908336  0.012734 -0.471409  0.030079  0.267926   \n",
       "2  0.194794 -0.048422  0.151622  0.018783  0.663420 -0.061387 -0.087623   \n",
       "3 -0.505625 -0.043630 -0.375797  0.013232  0.345206  0.017632  0.201714   \n",
       "4 -0.483685 -0.053000  0.184205  0.014867  0.370311 -0.018831  0.589455   \n",
       "\n",
       "          7         8  \n",
       "0 -0.638542 -0.520761  \n",
       "1  0.124677 -0.067652  \n",
       "2 -0.561768 -0.466256  \n",
       "3 -0.436891 -0.527415  \n",
       "4 -0.219688 -0.505142  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "\n",
    "# View the first few synthetic samples\n",
    "synthetic_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43500, 9)\n"
     ]
    }
   ],
   "source": [
    "print(synthetic_data.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Team_Project_A_Katabatic_Git_Repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
