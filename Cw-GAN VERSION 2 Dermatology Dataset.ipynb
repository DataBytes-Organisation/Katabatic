{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dfbc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Repeat 1/3\n",
      "üîÑ Fold 1/2\n",
      "üìä TSTR Accuracy:\n",
      "LogReg: 0.4693\n",
      "MLP: 0.6927\n",
      "RF: 0.9441\n",
      "XGBT: 0.7374\n",
      "üî¨ JSD: 0.5549 | WD: 0.6076\n",
      "üîÑ Fold 2/2\n",
      "üìä TSTR Accuracy:\n",
      "LogReg: 0.6927\n",
      "MLP: 0.8883\n",
      "RF: 0.8156\n",
      "XGBT: 0.4581\n",
      "üî¨ JSD: 0.5665 | WD: 0.5486\n",
      "üîÅ Repeat 2/3\n",
      "üîÑ Fold 1/2\n",
      "üìä TSTR Accuracy:\n",
      "LogReg: 0.4916\n",
      "MLP: 0.8547\n",
      "RF: 0.8268\n",
      "XGBT: 0.5698\n",
      "üî¨ JSD: 0.5422 | WD: 0.5840\n",
      "üîÑ Fold 2/2\n",
      "üìä TSTR Accuracy:\n",
      "LogReg: 0.3631\n",
      "MLP: 0.6983\n",
      "RF: 0.8212\n",
      "XGBT: 0.7542\n",
      "üî¨ JSD: 0.5404 | WD: 0.6827\n",
      "üîÅ Repeat 3/3\n",
      "üîÑ Fold 1/2\n",
      "üìä TSTR Accuracy:\n",
      "LogReg: 0.8045\n",
      "MLP: 0.7989\n",
      "RF: 0.8268\n",
      "XGBT: 0.6145\n",
      "üî¨ JSD: 0.5656 | WD: 0.5613\n",
      "üîÑ Fold 2/2\n",
      "üìä TSTR Accuracy:\n",
      "LogReg: 0.8659\n",
      "MLP: 0.8380\n",
      "RF: 0.7709\n",
      "XGBT: 0.6480\n",
      "üî¨ JSD: 0.5627 | WD: 0.4822\n",
      "\\nüìä AVERAGE TSTR Accuracy:\n",
      "LogReg: 0.6145\n",
      "MLP: 0.7952\n",
      "RF: 0.8343\n",
      "XGBT: 0.6304\n",
      "\\nüî¨ Average JSD: 0.5554\n",
      "üî¨ Average WD: 0.5777\n",
      "\\nüíæ Generating final synthetic dataset (50% size of original)\n",
      "‚úÖ Saved to synthetic_dermatology_half_verified V2.csv\n",
      "Original dataset size: 358\n",
      "Synthetic dataset size: 179\n",
      "Percentage of original: 50.0%\n"
     ]
    }
   ],
   "source": [
    "# ===== CW-GAN-GP on Dermatology Dataset with Final Average Metric Summary =====\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import entropy, wasserstein_distance\n",
    "from scipy.io import arff\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ===== Load and Preprocess =====\n",
    "data, meta = arff.loadarff(\"dermatology.arff\")\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df[\"Age\"] = df[\"Age\"].apply(lambda x: x.decode(\"utf-8\") if isinstance(x, bytes) else str(x))\n",
    "df[\"Age\"] = df[\"Age\"].str.replace(r\"[\\\"'\\\\\\\\]\", \"\", regex=True).str.strip()\n",
    "df[\"Age\"] = df[\"Age\"].replace({\"missing\": np.nan, \"(-inf-14]\": 10, \"(14-inf)\": 30})\n",
    "df = df.dropna(subset=[\"Age\"])\n",
    "df[\"Age\"] = df[\"Age\"].astype(int)\n",
    "\n",
    "encoders = {}\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == object:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        encoders[col] = le\n",
    "    else:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "X = df.drop(columns=[\"class\"])\n",
    "y = df[\"class\"]\n",
    "input_dim = X.shape[1]\n",
    "num_classes = y.nunique()\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# ===== Metrics =====\n",
    "def compute_jsd(p, q):\n",
    "    p, q = np.array(p) + 1e-10, np.array(q) + 1e-10\n",
    "    p, q = p / p.sum(), q / p.sum()\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (entropy(p, m) + entropy(q, m))\n",
    "\n",
    "def evaluate_jsd_wd(real_df, synth_df):\n",
    "    jsd_scores, wd_scores = [], []\n",
    "    for col in real_df.columns:\n",
    "        real, synth = real_df[col].values, synth_df[col].values\n",
    "        jsd = compute_jsd(np.histogram(real, bins=20)[0], np.histogram(synth, bins=20)[0])\n",
    "        wd = wasserstein_distance(real, synth)\n",
    "        jsd_scores.append(jsd)\n",
    "        wd_scores.append(wd)\n",
    "    return np.mean(jsd_scores), np.mean(wd_scores)\n",
    "\n",
    "# ===== Models =====\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, 32)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(64, 128), nn.ReLU(), nn.BatchNorm1d(128), nn.Dropout(0.2),\n",
    "            nn.Linear(128, 256), nn.ReLU(), nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128), nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "    def forward(self, z, labels):\n",
    "        c = self.label_emb(labels)\n",
    "        return self.model(torch.cat((z, c), dim=1))\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, 32)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim + 32, 256), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 64), nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x, labels):\n",
    "        c = self.label_emb(labels)\n",
    "        return self.model(torch.cat((x, c), dim=1))\n",
    "\n",
    "def compute_gp(critic, real_samples, fake_samples, labels):\n",
    "    alpha = torch.rand(real_samples.size(0), 1).to(device)\n",
    "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "    d_interpolates = critic(interpolates, labels)\n",
    "    fake = torch.ones_like(d_interpolates)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates, inputs=interpolates, grad_outputs=fake,\n",
    "        create_graph=True, retain_graph=True, only_inputs=True\n",
    "    )[0]\n",
    "    return ((gradients.view(gradients.size(0), -1).norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "# ===== Train and Evaluate =====\n",
    "results = defaultdict(list)\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "for repeat in range(3):\n",
    "    print(f\"üîÅ Repeat {repeat+1}/3\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"üîÑ Fold {fold+1}/2\")\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        loader = DataLoader(TensorDataset(torch.tensor(X_train.values, dtype=torch.float32),\n",
    "                                          torch.tensor(y_train.values, dtype=torch.long)), batch_size=64, shuffle=True)\n",
    "\n",
    "        generator, critic = Generator().to(device), Critic().to(device)\n",
    "        opt_G = torch.optim.Adam(generator.parameters(), lr=2e-4, betas=(0.5, 0.9))\n",
    "        opt_C = torch.optim.Adam(critic.parameters(), lr=2e-4, betas=(0.5, 0.9))\n",
    "\n",
    "        for epoch in range(200):\n",
    "            for i, (real_samples, labels) in enumerate(loader):\n",
    "                real_samples, labels = real_samples.to(device), labels.to(device)\n",
    "\n",
    "                for _ in range(5):\n",
    "                    z = torch.randn(real_samples.size(0), 32).to(device)\n",
    "                    fake_samples = generator(z, labels)\n",
    "                    real_validity = critic(real_samples, labels)\n",
    "                    fake_validity = critic(fake_samples.detach(), labels)\n",
    "                    gp = compute_gp(critic, real_samples, fake_samples, labels)\n",
    "                    c_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + 10 * gp\n",
    "                    opt_C.zero_grad(); c_loss.backward(); opt_C.step()\n",
    "\n",
    "                if i % 5 == 0:\n",
    "                    z = torch.randn(real_samples.size(0), 32).to(device)\n",
    "                    gen_samples = generator(z, labels)\n",
    "                    g_loss = -torch.mean(critic(gen_samples, labels))\n",
    "                    opt_G.zero_grad(); g_loss.backward(); opt_G.step()\n",
    "\n",
    "        synth_size = len(X_train) // 2\n",
    "        real_dist = y_train.value_counts(normalize=True).sort_index().values\n",
    "        synth_labels = torch.tensor(np.random.choice(num_classes, size=synth_size, p=real_dist), dtype=torch.long).to(device)\n",
    "        z = torch.randn(synth_size, 32).to(device)\n",
    "        gen_data = generator(z, synth_labels).detach().cpu().numpy()\n",
    "        synth_df = pd.DataFrame(gen_data, columns=X.columns)\n",
    "        synth_df[\"class\"] = synth_labels.cpu().numpy()\n",
    "\n",
    "        print(\"üìä TSTR Accuracy:\")\n",
    "        models = {\n",
    "            \"LogReg\": LogisticRegression(max_iter=300),\n",
    "            \"MLP\": MLPClassifier(max_iter=300),\n",
    "            \"RF\": RandomForestClassifier(),\n",
    "            \"XGBT\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "        }\n",
    "        for name, model in models.items():\n",
    "            model.fit(synth_df.drop(columns=[\"class\"]), synth_df[\"class\"])\n",
    "            acc = accuracy_score(y_test, model.predict(X_test))\n",
    "            results[f\"{name}_acc\"].append(acc)\n",
    "            print(f\"{name}: {acc:.4f}\")\n",
    "\n",
    "        jsd, wd = evaluate_jsd_wd(X_train, synth_df.drop(columns=[\"class\"]))\n",
    "        results[\"jsd\"].append(jsd)\n",
    "        results[\"wd\"].append(wd)\n",
    "        print(f\"üî¨ JSD: {jsd:.4f} | WD: {wd:.4f}\")\n",
    "\n",
    "# ===== Summary =====\n",
    "print(\"\\\\nüìä AVERAGE TSTR Accuracy:\")\n",
    "for name in [\"LogReg\", \"MLP\", \"RF\", \"XGBT\"]:\n",
    "    avg_score = np.mean(results[f\"{name}_acc\"])\n",
    "    print(f\"{name}: {avg_score:.4f}\")\n",
    "\n",
    "print(f\"\\\\nüî¨ Average JSD: {np.mean(results['jsd']):.4f}\")\n",
    "print(f\"üî¨ Average WD: {np.mean(results['wd']):.4f}\")\n",
    "\n",
    "# ===== Final Synthetic Dataset Generation =====\n",
    "print(\"\\\\nüíæ Generating final synthetic dataset (50% size of original)\")\n",
    "synth_size = len(X) // 2\n",
    "z = torch.randn(synth_size, 32).to(device)\n",
    "real_dist = y.value_counts(normalize=True).sort_index().values\n",
    "synth_labels = torch.tensor(np.random.choice(num_classes, size=synth_size, p=real_dist), dtype=torch.long).to(device)\n",
    "gen_data = generator(z, synth_labels).detach().cpu().numpy()\n",
    "synth_df_final = pd.DataFrame(gen_data, columns=X.columns)\n",
    "synth_df_final[\"class\"] = synth_labels.cpu().numpy()\n",
    "\n",
    "# Postprocess\n",
    "for col in X.columns:\n",
    "    synth_df_final[col] = synth_df_final[col].round().astype(int)\n",
    "    synth_df_final[col] = synth_df_final[col].clip(lower=0, upper=df[col].max())\n",
    "synth_df_final[\"class\"] = synth_df_final[\"class\"].clip(lower=0, upper=df[\"class\"].max())\n",
    "\n",
    "synth_df_final.to_csv(\"synthetic_dermatology_half_verified V2.csv\", index=False)\n",
    "print(\"‚úÖ Saved to synthetic_dermatology_half_verified V2.csv\")\n",
    "print(f\"Original dataset size: {len(X)}\")\n",
    "print(f\"Synthetic dataset size: {len(synth_df_final)}\")\n",
    "print(f\"Percentage of original: {round(100 * len(synth_df_final) / len(X), 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45563038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
