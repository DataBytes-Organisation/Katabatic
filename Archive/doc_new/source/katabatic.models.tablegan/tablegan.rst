TableGAN Class
==============

This class implements a Generative Adversarial Network (GAN) for tabular data, specifically designed to handle structured data with a classifier that enforces feature-label relationships.

.. class:: TableGAN

   :param input_dim: Integer, the dimension of the input features.
   :param label_dim: Integer, the dimension of the output labels.
   :param z_dim: Integer, the dimension of the noise vector used for generating synthetic data (default: 100).
   :param delta_mean: Float, the threshold for the mean feature differences during generator training (default: 0.1).
   :param delta_sd: Float, the threshold for the standard deviation differences during generator training (default: 0.1).

   **Example**::

      import tensorflow as tf
      from tensorflow.keras import layers
      import numpy as np

      # Create TableGAN model instance
      gan = TableGAN(input_dim=32, label_dim=10)

      # Train on data
      gan.fit(x_train, y_train, epochs=100)

      # Generate synthetic samples
      generated_data, generated_labels = gan.sample(n_samples=1000)

   **Methods**

   .. method:: _build_generator(self)

      Constructs the generator model, which produces synthetic data from random noise.

      :return: A Keras Sequential model representing the generator.
   
   .. method:: _build_discriminator(self)

      Constructs the discriminator model, which evaluates the authenticity of the data and extracts features.

      :return: A Keras Model that outputs the real/fake classification and extracted features.

   .. method:: _build_classifier(self)

      Constructs the classifier model, which predicts labels for the generated data.

      :return: A Keras Sequential model that classifies the input data.

   .. method:: wasserstein_loss(self, y_true, y_pred)

      Implements the Wasserstein loss function for training the discriminator.

      :param y_true: Tensor, the true labels (real/fake).
      :param y_pred: Tensor, the predicted labels.
      :return: Tensor, the computed Wasserstein loss.

   .. method:: gradient_penalty(self, real, fake)

      Computes the gradient penalty term for enforcing the Lipschitz constraint in Wasserstein GANs.

      :param real: Tensor, real data samples.
      :param fake: Tensor, fake data samples generated by the generator.
      :return: Tensor, the computed gradient penalty.

   .. method:: train_step(self, real_data, real_labels)

      Performs a single training step for the generator, discriminator, and classifier, using real and synthetic data.

      :param real_data: Tensor, the real data samples.
      :param real_labels: Tensor, the true labels for the real data samples.
      :return: Tuple of three values representing the discriminator, generator, and classifier losses, respectively.

   .. method:: fit(self, x, y, batch_size=64, epochs=100, verbose=1)

      Trains the GAN model on the provided data.

      :param x: Tensor, input data for training.
      :param y: Tensor, labels for the training data.
      :param batch_size: Integer, the size of each training batch (default: 64).
      :param epochs: Integer, the number of epochs to train the model (default: 100).
      :param verbose: Integer, the verbosity mode for logging during training (default: 1).
      :return: The fitted TableGAN model.

   .. method:: sample(self, n_samples)

      Generates synthetic data and corresponding labels using the trained generator and classifier.

      :param n_samples: Integer, the number of synthetic data samples to generate.
      :return: Tuple of numpy arrays, containing the generated data and labels.
