{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 16:43:16,165 - katabatic.models.TableGAN - INFO - TableGAN module initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   55 0 81 0 -6 11 25 88 64 4\n",
      "3   55 2 82 0 54 -6 26 28 2 1\n",
      "4   41 0 84 3 38 -4 43 45 2 1\n",
      "5  37 0 100 0 36 -8 63 64 2 1\n",
      "6    46 0 83 0 46 0 37 36 0 1\n",
      "7  44 0 79 0 42 -17 35 37 2 1\n",
      "8   44 -1 78 0 44 0 34 34 0 1\n",
      "9  55 0 81 0 54 -10 25 26 2 1\n"
     ]
    }
   ],
   "source": [
    "from katabatic.models.TableGAN import TableGANAdapter, TableGAN, preprocess_data, postprocess_data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the adapter with a specific privacy setting\n",
    "tablegan_adapter = TableGANAdapter(type='continuous', privacy_setting='high')\n",
    "data_path = 'data/shuttle/shuttle.tst'\n",
    "df = pd.read_csv(data_path)\n",
    "print(df[3:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.copy().drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "x_train, x_test, y_train, y_test=train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---FIT TableGAN Model with high privacy setting\n",
      "---Initialise TableGAN Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: [D loss: -0.9438] [G loss: 0.6501] [C loss: 0.6939]\n",
      "Epoch 20/100: [D loss: -1.2742] [G loss: 1.1586] [C loss: 0.4941]\n",
      "Epoch 30/100: [D loss: -1.1440] [G loss: 1.1257] [C loss: 0.3956]\n",
      "Epoch 40/100: [D loss: -1.2232] [G loss: 1.3256] [C loss: 0.3590]\n",
      "Epoch 50/100: [D loss: -1.1127] [G loss: 1.3535] [C loss: 0.3251]\n",
      "Epoch 60/100: [D loss: -1.0771] [G loss: 1.3517] [C loss: 0.3015]\n",
      "Epoch 70/100: [D loss: -1.1604] [G loss: 1.3237] [C loss: 0.2645]\n",
      "Epoch 80/100: [D loss: -1.1383] [G loss: 1.3875] [C loss: 0.2270]\n",
      "Epoch 90/100: [D loss: -1.0705] [G loss: 1.3176] [C loss: 0.1878]\n",
      "Epoch 100/100: [D loss: -1.1155] [G loss: 1.3207] [C loss: 0.1527]\n"
     ]
    }
   ],
   "source": [
    "tablegan_adapter.fit(x_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Generate from TableGAN Model\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "synthetic_data = tablegan_adapter.generate(size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "x_sync_train = synthetic_df.drop(synthetic_df.columns[-1],axis=1).values\n",
    "y_sync_train = synthetic_df.iloc[ :, -1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:35:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:36:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluated Item        LR        RF       MLP      XGBT\n",
      "0           TSTR  0.679191  0.684971  0.679191  0.089595\n",
      "1           TRTR  0.658960  0.965318  0.936416  0.979769\n"
     ]
    }
   ],
   "source": [
    "# TSTR (train synthetic test real)\n",
    "tstr_score_lr  = LogisticRegression().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "tstr_score_rf  = RandomForestClassifier().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "tstr_score_mlp = MLPClassifier().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_sync_train = le.fit_transform(y_sync_train)\n",
    "\n",
    "xgbt_classifier = XGBClassifier(eval_metric='logloss', use_label_encoder=True )\n",
    "tstr_score_xgbt = xgbt_classifier.fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "\n",
    "\n",
    "# TRTR (train real test real)\n",
    "trtr_score_lr  = LogisticRegression().fit(x_train, y_train).score(x_test, y_test)\n",
    "trtr_score_rf  = RandomForestClassifier().fit(x_train, y_train).score(x_test, y_test)\n",
    "trtr_score_mlp = MLPClassifier().fit(x_train, y_train).score(x_test, y_test)\n",
    "xgbt_classifier = XGBClassifier(eval_metric='logloss', use_label_encoder=True)\n",
    "trtr_score_xgbt = xgbt_classifier.fit(x_train, y_train).score(x_test, y_test)\n",
    "df_evaluate = pd.DataFrame([\n",
    "    ['TSTR', tstr_score_lr, tstr_score_rf, tstr_score_mlp, tstr_score_xgbt],\n",
    "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp, trtr_score_xgbt]\n",
    "], columns=['Evaluated Item', 'LR', 'RF', 'MLP', 'XGBT'])\n",
    "print(df_evaluate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
