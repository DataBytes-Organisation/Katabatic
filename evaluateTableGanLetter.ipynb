{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-13 10:26:42,402 - katabatic.models.TableGAN - INFO - TableGAN module initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>, (16000, 16)\n",
      "<class 'numpy.ndarray'>, (16000,)\n",
      "<class 'numpy.ndarray'>, (4000, 16)\n",
      "<class 'numpy.ndarray'>, (4000,)\n"
     ]
    }
   ],
   "source": [
    "from katabatic.models.TableGAN import TableGANAdapter, TableGAN, preprocess_data, postprocess_data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the adapter with a specific privacy setting\n",
    "tablegan_adapter = TableGANAdapter(type='continuous', privacy_setting='high')\n",
    "data_path = 'data/letter/letter-recognition.data'\n",
    "df = pd.read_csv(data_path, header = None)\n",
    "labelencoder=LabelEncoder()\n",
    "df= df.apply(lambda col: labelencoder.fit_transform(col) if col.dtype =='object' else col)\n",
    "x = df.drop(0, axis = 1).values\n",
    "y = df[0].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, random_state=42, shuffle=True, stratify=y)\n",
    "print(f\"{type(x_train)}, {x_train.shape}\")\n",
    "print(f\"{type(y_train)}, {y_train.shape}\")\n",
    "print(f\"{type(x_test)}, {x_test.shape}\")\n",
    "print(f\"{type(y_test)}, {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---FIT TableGAN Model with high privacy setting\n",
      "---Initialise TableGAN Model\n",
      "Epoch 10/100: [D loss: -0.4345] [G loss: 1.9206] [C loss: 0.9790]\n",
      "Epoch 20/100: [D loss: -0.3769] [G loss: 2.0223] [C loss: 0.7003]\n",
      "Epoch 30/100: [D loss: -0.3881] [G loss: 1.5136] [C loss: 0.5387]\n",
      "Epoch 40/100: [D loss: -0.4160] [G loss: 1.2035] [C loss: 0.4098]\n",
      "Epoch 50/100: [D loss: -0.4586] [G loss: 1.1152] [C loss: 0.3109]\n",
      "Epoch 60/100: [D loss: -0.5038] [G loss: 1.1858] [C loss: 0.2431]\n",
      "Epoch 70/100: [D loss: -0.5389] [G loss: 0.9937] [C loss: 0.1948]\n",
      "Epoch 80/100: [D loss: -0.5740] [G loss: 0.8050] [C loss: 0.1595]\n",
      "Epoch 90/100: [D loss: -0.6054] [G loss: 0.7671] [C loss: 0.1327]\n",
      "Epoch 100/100: [D loss: -0.6294] [G loss: 0.7079] [C loss: 0.1106]\n"
     ]
    }
   ],
   "source": [
    "tablegan_adapter.fit(x_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Generate from TableGAN Model\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "synthetic_data = tablegan_adapter.generate(size=1000)\n",
    "#synthetic_data = tablegan_adapter.generate(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>, (1000, 16)\n",
      "<class 'numpy.ndarray'>, (1000,)\n"
     ]
    }
   ],
   "source": [
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "x_sync_train = synthetic_df.drop(0, axis = 1).values\n",
    "y_sync_train = synthetic_df[0].values\n",
    "#x_sync_train = synthetic_df.drop(synthetic_df.columns[-1],axis=1).values\n",
    "#y_sync_train = synthetic_df.iloc[ :, -1:].values\n",
    "print(f\"{type(x_sync_train)}, {x_sync_train.shape}\")\n",
    "print(f\"{type(y_sync_train)}, {y_sync_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:58:44] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluated Item       LR       RF     MLP    XGBT\n",
      "0           TSTR  0.00000  0.00125  0.0000  0.0395\n",
      "1           TRTR  0.76275  0.96900  0.9295  0.9635\n"
     ]
    }
   ],
   "source": [
    "# TSTR (train synthetic test real)\n",
    "y_sync_train = LabelEncoder().fit_transform(y_sync_train)\n",
    "tstr_score_lr  = LogisticRegression().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "tstr_score_rf  = RandomForestClassifier().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "tstr_score_mlp = MLPClassifier().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "xgbt_classifier = XGBClassifier(eval_metric='logloss')\n",
    "tstr_score_xgbt = xgbt_classifier.fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "\n",
    "# TRTR (train real test real)\n",
    "trtr_score_lr  = LogisticRegression().fit(x_train, y_train).score(x_test, y_test)\n",
    "trtr_score_rf  = RandomForestClassifier().fit(x_train, y_train).score(x_test, y_test)\n",
    "trtr_score_mlp = MLPClassifier().fit(x_train, y_train).score(x_test, y_test)\n",
    "xgbt_classifier = XGBClassifier(eval_metric='logloss', use_label_encoder=True)\n",
    "trtr_score_xgbt = xgbt_classifier.fit(x_train, y_train).score(x_test, y_test)\n",
    "df_evaluate = pd.DataFrame([\n",
    "    ['TSTR', tstr_score_lr, tstr_score_rf, tstr_score_mlp, tstr_score_xgbt],\n",
    "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp, trtr_score_xgbt]\n",
    "], columns=['Evaluated Item', 'LR', 'RF', 'MLP', 'XGBT'])\n",
    "print(df_evaluate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
