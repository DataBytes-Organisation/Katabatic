{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n",
      "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
      "0   1   25           1      49     91107       4    1.6          1         0   \n",
      "1   2   45          19      34     90089       3    1.5          1         0   \n",
      "2   3   39          15      11     94720       1    1.0          1         0   \n",
      "3   4   35           9     100     94112       1    2.7          2         0   \n",
      "4   5   35           8      45     91330       4    1.0          2         0   \n",
      "5   6   37          13      29     92121       4    0.4          2       155   \n",
      "6   7   53          27      72     91711       2    1.5          2         0   \n",
      "7   8   50          24      22     93943       1    0.3          3         0   \n",
      "8   9   35          10      81     90089       3    0.6          2       104   \n",
      "9  10   34           9     180     93023       1    8.9          3         0   \n",
      "\n",
      "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
      "0              0                   1           0       0           0  \n",
      "1              0                   1           0       0           0  \n",
      "2              0                   0           0       0           0  \n",
      "3              0                   0           0       0           0  \n",
      "4              0                   0           0       0           1  \n",
      "5              0                   0           0       1           0  \n",
      "6              0                   0           0       1           0  \n",
      "7              0                   0           0       0           1  \n",
      "8              0                   0           0       1           0  \n",
      "9              1                   0           0       0           0  \n"
     ]
    }
   ],
   "source": [
    "from katabatic.models.TableGAN import TableGANAdapter, TableGAN, preprocess_data, postprocess_data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the adapter with a specific privacy setting\n",
    "tablegan_adapter = TableGANAdapter(type='continuous', privacy_setting='high')\n",
    "data_path = 'data/loan/Bank_Personal_Loan.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df['CCAvg']=df['CCAvg'].str.replace(\"/\",\".\")\n",
    "df[\"CCAvg\"] = df[\"CCAvg\"].astype(str).astype(float)\n",
    "negative_count = (df['Experience'] < 0).sum()\n",
    "print(negative_count)\n",
    "df[\"Experience\"] =abs(df[\"Experience\"])\n",
    "df.info()\n",
    "print(df[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is (5000, 13)\n",
      "\n",
      "y shape is (5000, 1)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(\"Personal Loan\", axis = 1)\n",
    "y = df[\"Personal Loan\"].values.reshape(-1,1)\n",
    "print(\"X shape is\", x.shape)\n",
    "print()\n",
    "print(\"y shape is\", y.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, train_size=0.8, random_state=90049, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---FIT TableGAN Model with high privacy setting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Initialise TableGAN Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: [D loss: -1.5253] [G loss: 0.6486] [C loss: 0.0942]\n",
      "Epoch 20/100: [D loss: -0.8207] [G loss: 0.3043] [C loss: 0.0674]\n",
      "Epoch 30/100: [D loss: -0.5415] [G loss: 0.3467] [C loss: 0.0591]\n",
      "Epoch 40/100: [D loss: -0.5820] [G loss: 0.0892] [C loss: 0.0531]\n",
      "Epoch 50/100: [D loss: -0.4907] [G loss: 0.6886] [C loss: 0.0492]\n",
      "Epoch 60/100: [D loss: -0.4447] [G loss: 0.3717] [C loss: 0.0479]\n",
      "Epoch 70/100: [D loss: -0.4322] [G loss: 0.4619] [C loss: 0.0440]\n",
      "Epoch 80/100: [D loss: -0.4153] [G loss: 0.3388] [C loss: 0.0422]\n",
      "Epoch 90/100: [D loss: -0.4284] [G loss: 0.4799] [C loss: 0.0413]\n",
      "Epoch 100/100: [D loss: -0.4297] [G loss: 0.5591] [C loss: 0.0383]\n"
     ]
    }
   ],
   "source": [
    "tablegan_adapter.fit(x_train, y_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Generate from TableGAN Model\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "synthetic_data = tablegan_adapter.generate(size=4000)\n",
    "#synthetic_data = tablegan_adapter.generate(size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>, (4000, 13)\n",
      "<class 'numpy.ndarray'>, (4000, 1)\n"
     ]
    }
   ],
   "source": [
    "synthetic_df = pd.DataFrame(synthetic_data)\n",
    "x_sync_train = synthetic_df.drop(synthetic_df.columns[-1],axis=1).values\n",
    "y_sync_train = synthetic_df.iloc[ :, -1:].values\n",
    "print(f\"{type(x_sync_train)}, {x_sync_train.shape}\")\n",
    "print(f\"{type(y_sync_train)}, {y_sync_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:2732: UserWarning: X has feature names, but MLPClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\Anaconda3\\envs\\py39\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:25:38] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluated Item     LR     RF    MLP   XGBT\n",
      "0           TSTR  0.905  0.921  0.904  0.970\n",
      "1           TRTR  0.906  0.991  0.904  0.991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimport numpy as np\\n# evaluate\\n#ohe = OneHotEncoder(handle_unknown='ignore')\\nohe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\\nlbe = LabelEncoder()\\n\\n# TRTR\\nx_train_ohe = ohe.fit_transform(x_train)\\nx_test_ohe = ohe.transform(x_test)\\ny_train_lbe = lbe.fit_transform(y_train)\\ny_test_lbe = lbe.transform(y_test)\\ntrtr_score_lr  = LogisticRegression().fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\\ntrtr_score_rf  = RandomForestClassifier().fit(x_train, y_train_lbe).score(x_test, y_test_lbe)\\ntrtr_score_mlp = MLPClassifier().fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\\nxgbt_classifier = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\\ntrtr_score_xgbt = xgbt_classifier.fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\\n\\n# TSTR\\nx_train_ohe = ohe.fit_transform(x_sync_train)\\nx_test_ohe = ohe.fit_transform(x_test)\\ny_train_lbe = lbe.fit_transform(y_sync_train)\\ny_test_lbe = lbe.fit_transform(y_test)\\ntstr_score_lr  = LogisticRegression().fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\\ntstr_score_rf  = RandomForestClassifier().fit(x_train, y_train_lbe).score(x_test, y_test_lbe)\\ntstr_score_mlp = MLPClassifier().fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\\nxgbt_classifier = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\\ntstr_score_xgbt = xgbt_classifier.fit(x_train_ohe, y_train_lbe).score(x_test_ohe, y_test_lbe)\\n\\ndf_evaluate = pd.DataFrame([\\n    ['TSTR', tstr_score_lr, tstr_score_rf, tstr_score_mlp, tstr_score_xgbt],\\n    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp, trtr_score_xgbt]\\n], columns=['Evaluated Item', 'LR', 'RF', 'MLP', 'XGBT'])\\nprint(df_evaluate)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TSTR (train synthetic test real)\n",
    "tstr_score_lr  = LogisticRegression().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "tstr_score_rf  = RandomForestClassifier().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "tstr_score_mlp = MLPClassifier().fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "y_sync_train = LabelEncoder().fit_transform(y_sync_train)\n",
    "xgbt_classifier = XGBClassifier(eval_metric='logloss')\n",
    "tstr_score_xgbt = xgbt_classifier.fit(x_sync_train, y_sync_train).score(x_test, y_test)\n",
    "\n",
    "# TRTR (train real test real)\n",
    "trtr_score_lr  = LogisticRegression().fit(x_train, y_train).score(x_test, y_test)\n",
    "trtr_score_rf  = RandomForestClassifier().fit(x_train, y_train).score(x_test, y_test)\n",
    "trtr_score_mlp = MLPClassifier().fit(x_train, y_train).score(x_test, y_test)\n",
    "xgbt_classifier = XGBClassifier(eval_metric='logloss', use_label_encoder=True)\n",
    "trtr_score_xgbt = xgbt_classifier.fit(x_train, y_train).score(x_test, y_test)\n",
    "df_evaluate = pd.DataFrame([\n",
    "    ['TSTR', tstr_score_lr, tstr_score_rf, tstr_score_mlp, tstr_score_xgbt],\n",
    "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp, trtr_score_xgbt]\n",
    "], columns=['Evaluated Item', 'LR', 'RF', 'MLP', 'XGBT'])\n",
    "print(df_evaluate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
