{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ctgan_adapter import CtganAdapter\n",
    "from ctgan_benchmark import evaluate_ctgan, print_evaluation_results\n",
    "from ctgan_utils import preprocess_data, get_tstr_results\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load configuration\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(\"# Load configuration\")\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1. Load and prepare the dataset\n",
      "Columns in dataset: ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
      "Dataset shape: (19020, 11)\n",
      "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
      "\n",
      "    fAlpha     fDist class  \n",
      "0  40.0920   81.8828     g  \n",
      "1   6.3609  205.2610     g  \n",
      "2  76.9600  256.7880     g  \n",
      "3  10.4490  116.7370     g  \n",
      "4   4.6480  356.4620     g  \n"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare the dataset\n",
    "print(\"# 1. Load and prepare the dataset\")\n",
    "data_raw = pd.read_csv(\"magic.csv\")\n",
    "print(f\"Columns in dataset: {data_raw.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {data_raw.shape}\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 08:53:00,016 - INFO - Converted class to category type (has 2 unique values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 2. Preprocess data and detect categorical columns\n",
      "Detected categorical columns: ['class']\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocess data and detect categorical columns\n",
    "print(\"\\n# 2. Preprocess data and detect categorical columns\")\n",
    "data, categorical_columns = preprocess_data(data_raw)\n",
    "print(f\"Detected categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3. Define the target column for this dataset\n",
      "Target column: class\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the target column for this dataset\n",
    "print(\"\\n# 3. Define the target column for this dataset\")\n",
    "target_column = \"class\"\n",
    "print(f\"Target column: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 4. Split the data into features and target\n",
      "Features shape: (19020, 10)\n",
      "Target shape: (19020,)\n",
      "Target distribution:\n",
      "class\n",
      "g    12332\n",
      "h     6688\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Split the data into features and target\n",
    "print(\"\\n# 4. Split the data into features and target\")\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 5. Initialize and train CTGAN\n",
      "Training CTGAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\mixture\\_base.py:265: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn('Initialization %d did not converge. '\n",
      "Training Epochs:   0%|          | 1/300 [00:18<1:33:14, 18.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss D: 2.7329, Loss G: 0.8742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|█         | 31/300 [08:36<1:14:13, 16.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss D: -0.8772, Loss G: 1.4377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 61/300 [18:19<1:20:40, 20.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss D: -2.8761, Loss G: 1.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|███       | 91/300 [28:59<1:09:58, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Loss D: -3.0163, Loss G: 1.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|████      | 121/300 [38:59<1:01:48, 20.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, Loss D: -2.7886, Loss G: 1.4049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|█████     | 151/300 [49:58<41:17, 16.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, Loss D: -2.6046, Loss G: 1.5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|██████    | 181/300 [1:00:38<45:05, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180, Loss D: -2.4813, Loss G: 1.6029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|███████   | 211/300 [1:12:14<36:22, 24.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210, Loss D: -2.3016, Loss G: 1.7680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|████████  | 241/300 [1:23:39<21:52, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240, Loss D: -2.2559, Loss G: 1.7652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|█████████ | 271/300 [1:34:10<11:09, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270, Loss D: -2.1590, Loss G: 1.8030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [1:44:48<00:00, 20.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize and train CTGAN\n",
    "print(\"\\n# 5. Initialize and train CTGAN\")\n",
    "ctgan = CtganAdapter(**config[\"ctgan_params\"])\n",
    "print(\"Training CTGAN model...\")\n",
    "ctgan.fit(X, y)\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 6. Generate synthetic data\n",
      "Generating 1000 synthetic samples...\n",
      "Generated 1000 synthetic samples\n",
      "Synthetic data head:\n",
      "      fLength     fWidth     fSize     fConc    fConc1       fAsym  \\\n",
      "0   22.828516   9.245157  2.204933  0.651088  0.321686   28.587789   \n",
      "1  164.201571  29.299912  2.828017  0.204912  0.083796  130.753018   \n",
      "2   32.792143   9.612016  2.536615  0.484315  0.363209   96.370634   \n",
      "3   20.490402   8.896585  2.252200  0.579687  0.428748    7.704064   \n",
      "4   17.735438  15.773135  2.938515  0.407805  0.225042   26.758642   \n",
      "\n",
      "      fM3Long   fM3Trans     fAlpha       fDist class  \n",
      "0   16.608428 -12.710108  48.747535  179.957367     g  \n",
      "1  141.899047 -10.561327  32.054131  130.454906     h  \n",
      "2  -16.474628 -14.305284  58.264342   57.352998     h  \n",
      "3  -12.910390   5.160824  51.561391  166.110352     g  \n",
      "4   24.706263   3.727664   0.169784  182.270104     g  \n"
     ]
    }
   ],
   "source": [
    "# 6. Generate synthetic data\n",
    "print(\"\\n# 6. Generate synthetic data\")\n",
    "n_samples = 1000  \n",
    "print(f\"Generating {n_samples} synthetic samples...\")\n",
    "synthetic_data = ctgan.generate(n_samples)\n",
    "print(f\"Generated {len(synthetic_data)} synthetic samples\")\n",
    "print(\"Synthetic data head:\")\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 7. Evaluate quality using TSTR and other metrics\n",
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 10:49:29,238 - INFO - Encoded categorical target with mapping: {'g': 0, 'h': 1}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:49:48] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-03-31 10:49:48,579 - INFO - Encoded categorical targets with mapping: {'g': 0, 'h': 1}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [10:49:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-03-31 10:49:53,292 - INFO - CTGAN Evaluation Results:\n",
      "2025-03-31 10:49:53,293 - INFO - \n",
      "Likelihood Fitness Metrics:\n",
      "2025-03-31 10:49:53,295 - INFO -   - Lsyn (Synthetic Data Log-Likelihood): -27.5534\n",
      "2025-03-31 10:49:53,295 - INFO -   - Ltest (Real Data Log-Likelihood under Synthetic Model): -31.6121\n",
      "2025-03-31 10:49:53,295 - INFO - \n",
      "Statistical Similarity Metrics:\n",
      "2025-03-31 10:49:53,295 - INFO -   - Wasserstein Distance Mean (Numerical): 3.9625\n",
      "2025-03-31 10:49:53,297 - INFO - \n",
      "Machine Learning Efficacy Metrics on Real Data:\n",
      "2025-03-31 10:49:53,297 - INFO -   LogisticRegression:\n",
      "2025-03-31 10:49:53,297 - INFO -     - Accuracy: 0.7931\n",
      "2025-03-31 10:49:53,299 - INFO -     - F1: 0.7867\n",
      "2025-03-31 10:49:53,299 - INFO -   RandomForest:\n",
      "2025-03-31 10:49:53,299 - INFO -     - Accuracy: 0.8809\n",
      "2025-03-31 10:49:53,301 - INFO -     - F1: 0.8789\n",
      "2025-03-31 10:49:53,301 - INFO -   MLP:\n",
      "2025-03-31 10:49:53,301 - INFO -     - Accuracy: 0.8778\n",
      "2025-03-31 10:49:53,302 - INFO -     - F1: 0.8750\n",
      "2025-03-31 10:49:53,303 - INFO -   XGBoost:\n",
      "2025-03-31 10:49:53,304 - INFO -     - Accuracy: 0.8772\n",
      "2025-03-31 10:49:53,304 - INFO -     - F1: 0.8755\n",
      "2025-03-31 10:49:53,305 - INFO - \n",
      "Machine Learning Utility using TSTR Approach:\n",
      "2025-03-31 10:49:53,306 - INFO -   LogisticRegression:\n",
      "2025-03-31 10:49:53,307 - INFO -     - Accuracy: 0.7784\n",
      "2025-03-31 10:49:53,308 - INFO -     - F1: 0.7666\n",
      "2025-03-31 10:49:53,309 - INFO -   RandomForest:\n",
      "2025-03-31 10:49:53,309 - INFO -     - Accuracy: 0.8081\n",
      "2025-03-31 10:49:53,310 - INFO -     - F1: 0.8029\n",
      "2025-03-31 10:49:53,311 - INFO -   MLP:\n",
      "2025-03-31 10:49:53,311 - INFO -     - Accuracy: 0.7955\n",
      "2025-03-31 10:49:53,313 - INFO -     - F1: 0.7953\n",
      "2025-03-31 10:49:53,314 - INFO -   XGBoost:\n",
      "2025-03-31 10:49:53,314 - INFO -     - Accuracy: 0.7853\n",
      "2025-03-31 10:49:53,314 - INFO -     - F1: 0.7840\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate quality using TSTR and other metrics\n",
    "print(\"\\n# 7. Evaluate quality using TSTR and other metrics\")\n",
    "print(\"Running evaluation...\")\n",
    "evaluation_results = evaluate_ctgan(data, synthetic_data, target_column=target_column)\n",
    "print_evaluation_results(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 8. TSTR Performance Results\n",
      "                    Accuracy        F1\n",
      "LogisticRegression  0.778391  0.766582\n",
      "RandomForest        0.808097  0.802876\n",
      "MLP                 0.795531  0.795315\n",
      "XGBoost             0.785331  0.784029\n"
     ]
    }
   ],
   "source": [
    "# 8. Extract and display TSTR results specifically\n",
    "print(\"\\n# 8. TSTR Performance Results\")\n",
    "tstr_results = get_tstr_results(evaluation_results)\n",
    "if tstr_results is not None:\n",
    "    print(tstr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 9. Save synthetic data\n",
      "Synthetic data saved to magic_synthetic.csv\n",
      "\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9. Save the synthetic data\n",
    "print(\"\\n# 9. Save synthetic data\")\n",
    "output_path = \"magic_synthetic.csv\"\n",
    "synthetic_data.to_csv(output_path, index=False)\n",
    "print(f\"Synthetic data saved to {output_path}\")\n",
    "\n",
    "print(\"\\nTest completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit378",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
