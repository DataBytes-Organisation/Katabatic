{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ctgan_adapter import CtganAdapter\n",
    "from ctgan_benchmark import evaluate_ctgan, print_evaluation_results\n",
    "from ctgan_utils import preprocess_data, get_tstr_results\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load configuration\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(\"# Load configuration\")\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1. Load and prepare the dataset\n",
      "Columns in dataset: ['letter', 'xbox ', 'ybox ', 'width ', 'height', 'onpix ', 'xbar ', 'ybar ', 'x2bar', 'y2bar ', 'xybar ', 'x2ybar', 'xy2bar', 'xedge ', 'xedgey', 'yedge ', 'yedgex']\n",
      "Dataset shape: (20000, 17)\n",
      "  letter  xbox   ybox   width   height  onpix   xbar   ybar   x2bar  y2bar   \\\n",
      "0      T      2      8       3       5       1      8     13      0       6   \n",
      "1      I      5     12       3       7       2     10      5      5       4   \n",
      "2      D      4     11       6       8       6     10      6      2       6   \n",
      "3      N      7     11       6       6       3      5      9      4       6   \n",
      "4      G      2      1       3       1       1      8      6      6       6   \n",
      "\n",
      "   xybar   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex  \n",
      "0       6      10       8       0       8       0       8  \n",
      "1      13       3       9       2       8       4      10  \n",
      "2      10       3       7       3       7       3       9  \n",
      "3       4       4      10       6      10       2       8  \n",
      "4       6       5       9       1       7       5      10  \n"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare the dataset\n",
    "print(\"# 1. Load and prepare the dataset\")\n",
    "data_raw = pd.read_csv(\"letter-recognition.csv\")\n",
    "print(f\"Columns in dataset: {data_raw.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {data_raw.shape}\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 14:51:54,728 - INFO - Converted letter to category type (has 26 unique values)\n",
      "2025-04-02 14:51:54,730 - INFO - Converted xbox  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,733 - INFO - Converted ybox  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,736 - INFO - Converted width  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,737 - INFO - Converted height to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,739 - INFO - Converted onpix  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,740 - INFO - Converted xbar  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,742 - INFO - Converted ybar  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,743 - INFO - Converted x2bar to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,744 - INFO - Converted y2bar  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,744 - INFO - Converted xybar  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,744 - INFO - Converted x2ybar to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,751 - INFO - Converted xy2bar to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,754 - INFO - Converted xedge  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,754 - INFO - Converted xedgey to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,754 - INFO - Converted yedge  to category type (has 16 unique values)\n",
      "2025-04-02 14:51:54,754 - INFO - Converted yedgex to category type (has 16 unique values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 2. Preprocess data and detect categorical columns\n",
      "Detected categorical columns: ['letter', 'xbox ', 'ybox ', 'width ', 'height', 'onpix ', 'xbar ', 'ybar ', 'x2bar', 'y2bar ', 'xybar ', 'x2ybar', 'xy2bar', 'xedge ', 'xedgey', 'yedge ', 'yedgex']\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocess data and detect categorical columns\n",
    "print(\"\\n# 2. Preprocess data and detect categorical columns\")\n",
    "data, categorical_columns = preprocess_data(data_raw)\n",
    "print(f\"Detected categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3. Define the target column for this dataset\n",
      "Target column: letter\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the target column for this dataset\n",
    "print(\"\\n# 3. Define the target column for this dataset\")\n",
    "target_column = \"letter\"\n",
    "print(f\"Target column: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 4. Split the data into features and target\n",
      "Features shape: (20000, 16)\n",
      "Target shape: (20000,)\n",
      "Target distribution:\n",
      "letter\n",
      "U    813\n",
      "D    805\n",
      "P    803\n",
      "T    796\n",
      "M    792\n",
      "A    789\n",
      "X    787\n",
      "Y    786\n",
      "Q    783\n",
      "N    783\n",
      "F    775\n",
      "G    773\n",
      "E    768\n",
      "B    766\n",
      "V    764\n",
      "L    761\n",
      "R    758\n",
      "I    755\n",
      "O    753\n",
      "W    752\n",
      "S    748\n",
      "J    747\n",
      "K    739\n",
      "C    736\n",
      "H    734\n",
      "Z    734\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Split the data into features and target\n",
    "print(\"\\n# 4. Split the data into features and target\")\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 5. Initialize and train CTGAN\n",
      "Training CTGAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   0%|          | 1/300 [01:40<8:18:45, 100.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss D: 14.4444, Loss G: 4.6455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  10%|█         | 31/300 [1:11:01<10:32:43, 141.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss D: -1.5041, Loss G: 0.4148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  20%|██        | 61/300 [2:14:52<7:27:24, 112.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Loss D: -3.6350, Loss G: 0.6079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  30%|███       | 91/300 [2:55:04<4:28:55, 77.20s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Loss D: -4.2757, Loss G: 0.4690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  40%|████      | 121/300 [3:33:16<3:47:31, 76.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120, Loss D: -4.1019, Loss G: 0.4729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  50%|█████     | 151/300 [4:12:08<3:08:19, 75.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150, Loss D: -4.0280, Loss G: 0.4807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  60%|██████    | 181/300 [4:50:22<2:31:05, 76.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180, Loss D: -4.0253, Loss G: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  70%|███████   | 211/300 [5:28:34<1:53:06, 76.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210, Loss D: -4.0554, Loss G: 0.4625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  80%|████████  | 241/300 [6:06:35<1:14:25, 75.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240, Loss D: -4.0454, Loss G: 0.4231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  90%|█████████ | 271/300 [6:49:07<51:17, 106.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270, Loss D: -4.0405, Loss G: 0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [7:44:52<00:00, 92.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize and train CTGAN\n",
    "print(\"\\n# 5. Initialize and train CTGAN\")\n",
    "ctgan = CtganAdapter(**config[\"ctgan_params\"])\n",
    "print(\"Training CTGAN model...\")\n",
    "ctgan.fit(X, y)\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 6. Generate synthetic data\n",
      "Generating 1000 synthetic samples...\n",
      "Generated 1000 synthetic samples\n",
      "Synthetic data head:\n",
      "   xbox   ybox   width   height  onpix   xbar   ybar   x2bar  y2bar   xybar   \\\n",
      "0      2      7       4       2       2      6      7      3       5      11   \n",
      "1      6     11       8       8       8      8      4      5       3       6   \n",
      "2      2      4       3       3       2      6      6      7       3       6   \n",
      "3      3      6       4       4       3      8      7      6       5      11   \n",
      "4      4     10       6       1       7      8      6      2       4       9   \n",
      "\n",
      "   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex letter  \n",
      "0       7       6       2       7       2       6      N  \n",
      "1       9      10       8       6       2       8      M  \n",
      "2      10       7       2       9       1       8      G  \n",
      "3       6       7       3       8       4       8      C  \n",
      "4       7      10       8       6       2       5      M  \n"
     ]
    }
   ],
   "source": [
    "# 6. Generate synthetic data\n",
    "print(\"\\n# 6. Generate synthetic data\")\n",
    "n_samples = 1000  \n",
    "print(f\"Generating {n_samples} synthetic samples...\")\n",
    "synthetic_data = ctgan.generate(n_samples)\n",
    "print(f\"Generated {len(synthetic_data)} synthetic samples\")\n",
    "print(\"Synthetic data head:\")\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 09:51:41,660 - WARNING - No numerical columns found for likelihood fitness evaluation\n",
      "2025-04-03 09:51:41,695 - INFO - Encoded categorical target with mapping: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 7. Evaluate quality using TSTR and other metrics\n",
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:52:56] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-03 09:53:09,657 - INFO - Encoded categorical targets with mapping: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:53:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-03 09:53:25,266 - INFO - CTGAN Evaluation Results:\n",
      "2025-04-03 09:53:25,269 - INFO - \n",
      "Likelihood Fitness: Not applicable for fully categorical data\n",
      "2025-04-03 09:53:25,271 - INFO - \n",
      "Statistical Similarity Metrics:\n",
      "2025-04-03 09:53:25,272 - INFO -   - Jensen-Shannon Divergence Mean (Categorical): 0.1340\n",
      "2025-04-03 09:53:25,275 - INFO - \n",
      "Machine Learning Efficacy Metrics on Real Data:\n",
      "2025-04-03 09:53:25,275 - INFO -   LogisticRegression:\n",
      "2025-04-03 09:53:25,277 - INFO -     - Accuracy: 0.8528\n",
      "2025-04-03 09:53:25,279 - INFO -     - F1: 0.8528\n",
      "2025-04-03 09:53:25,281 - INFO -   RandomForest:\n",
      "2025-04-03 09:53:25,281 - INFO -     - Accuracy: 0.8950\n",
      "2025-04-03 09:53:25,283 - INFO -     - F1: 0.8952\n",
      "2025-04-03 09:53:25,285 - INFO -   MLP:\n",
      "2025-04-03 09:53:25,287 - INFO -     - Accuracy: 0.9145\n",
      "2025-04-03 09:53:25,289 - INFO -     - F1: 0.9145\n",
      "2025-04-03 09:53:25,291 - INFO -   XGBoost:\n",
      "2025-04-03 09:53:25,294 - INFO -     - Accuracy: 0.9123\n",
      "2025-04-03 09:53:25,296 - INFO -     - F1: 0.9121\n",
      "2025-04-03 09:53:25,299 - INFO - \n",
      "Machine Learning Utility using TSTR Approach:\n",
      "2025-04-03 09:53:25,300 - INFO -   LogisticRegression:\n",
      "2025-04-03 09:53:25,302 - INFO -     - Accuracy: 0.3245\n",
      "2025-04-03 09:53:25,304 - INFO -     - F1: 0.2986\n",
      "2025-04-03 09:53:25,306 - INFO -   RandomForest:\n",
      "2025-04-03 09:53:25,307 - INFO -     - Accuracy: 0.2369\n",
      "2025-04-03 09:53:25,309 - INFO -     - F1: 0.2064\n",
      "2025-04-03 09:53:25,311 - INFO -   MLP:\n",
      "2025-04-03 09:53:25,312 - INFO -     - Accuracy: 0.2940\n",
      "2025-04-03 09:53:25,313 - INFO -     - F1: 0.2712\n",
      "2025-04-03 09:53:25,315 - INFO -   XGBoost:\n",
      "2025-04-03 09:53:25,317 - INFO -     - Accuracy: 0.2831\n",
      "2025-04-03 09:53:25,319 - INFO -     - F1: 0.2630\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate quality using TSTR and other metrics\n",
    "print(\"\\n# 7. Evaluate quality using TSTR and other metrics\")\n",
    "print(\"Running evaluation...\")\n",
    "evaluation_results = evaluate_ctgan(data, synthetic_data, target_column=target_column)\n",
    "print_evaluation_results(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 8. TSTR Performance Results\n",
      "                    Accuracy        F1\n",
      "LogisticRegression   0.32445  0.298618\n",
      "RandomForest         0.23690  0.206445\n",
      "MLP                  0.29400  0.271157\n",
      "XGBoost              0.28305  0.262957\n"
     ]
    }
   ],
   "source": [
    "# 8. Extract and display TSTR results specifically\n",
    "print(\"\\n# 8. TSTR Performance Results\")\n",
    "tstr_results = get_tstr_results(evaluation_results)\n",
    "if tstr_results is not None:\n",
    "    print(tstr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 9. Save synthetic data\n",
      "Synthetic data saved to letter_synthetic.csv\n",
      "\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9. Save the synthetic data\n",
    "print(\"\\n# 9. Save synthetic data\")\n",
    "output_path = \"letter_synthetic.csv\"\n",
    "synthetic_data.to_csv(output_path, index=False)\n",
    "print(f\"Synthetic data saved to {output_path}\")\n",
    "\n",
    "print(\"\\nTest completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit378",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
