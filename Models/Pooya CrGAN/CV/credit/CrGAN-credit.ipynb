{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62793,
     "status": "ok",
     "timestamp": 1744425920650,
     "user": {
      "displayName": "Pooya Forghani",
      "userId": "09002604427734085896"
     },
     "user_tz": -600
    },
    "id": "kL9qNecp4Cyh",
    "outputId": "d67b1e83-259d-42eb-e4b9-da4420fe3c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#  %pip install xgboost\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad as torch_grad\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import xgboost as xgb\n",
    "from scipy.stats import entropy\n",
    "import warnings\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd /content/drive/MyDrive/Colab Notebooks/Katabatic/CrGAN/credit/cross/\n",
    "# %cd /content/drive/MyDrive/\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setting random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_credit_card_data(file_path, test_size=0.2, random_state=42, shuffle=True):\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "    # Drop ID column as it's not a feature\n",
    "    if 'ID' in df.columns:\n",
    "        df = df.drop('ID', axis=1)\n",
    "\n",
    "    # Rename target variable for consistency\n",
    "    if 'default.payment.next.month' in df.columns:\n",
    "        df = df.rename(columns={'default.payment.next.month': 'TARGET'})\n",
    "\n",
    "    # Split features and target\n",
    "    X = df.drop('TARGET', axis=1)\n",
    "    y = df['TARGET']\n",
    "\n",
    "    # Define categorical and numerical columns\n",
    "    categorical_cols = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3',\n",
    "                         'PAY_4', 'PAY_5', 'PAY_6']\n",
    "    numerical_cols = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3',\n",
    "                       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', 'PAY_AMT2',\n",
    "                       'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "\n",
    "    # Create preprocessing pipeline\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_cols),\n",
    "            ('num', numerical_transformer, numerical_cols)\n",
    "        ])\n",
    "\n",
    "    # Return the full dataset, preprocessor, and feature info\n",
    "    return X, y, preprocessor, categorical_cols, numerical_cols\n",
    "\n",
    "# Custom dataset class\n",
    "class CreditCardDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "\n",
    "        if labels is not None:\n",
    "            # Convert to numpy array and ensure float32 dtype\n",
    "            self.labels = torch.tensor(labels.values.astype(np.float32)).view(-1, 1)\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labels is not None:\n",
    "            return self.features[idx], self.labels[idx]\n",
    "        else:\n",
    "            return self.features[idx]\n",
    "\n",
    "\n",
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(1024, output_dim),\n",
    "            nn.Tanh()  # Output layer - maps to (-1, 1) range\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "# Critic Network (Discriminator)\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Cramer GAN Implementation\n",
    "class CramerGAN:\n",
    "    def __init__(self, data_dim, latent_dim=100, critic_iterations=5, lambda_gp=10):\n",
    "        self.data_dim = data_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.critic_iterations = critic_iterations\n",
    "        self.lambda_gp = lambda_gp\n",
    "\n",
    "        # Initialize networks\n",
    "        self.generator = Generator(latent_dim, data_dim).to(device)\n",
    "        self.critic = Critic(data_dim).to(device)\n",
    "\n",
    "        # Setup optimizers\n",
    "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=0.0002, betas=(0.5, 0.9))\n",
    "        self.c_optimizer = optim.Adam(self.critic.parameters(), lr=0.0002, betas=(0.5, 0.9))\n",
    "\n",
    "        # Initialize loss tracking\n",
    "        self.g_losses = []\n",
    "        self.c_losses = []\n",
    "\n",
    "    def _critic_train_iteration(self, real_data, batch_size):\n",
    "        # Generate random noise\n",
    "        noise = torch.randn(batch_size, self.latent_dim).to(device)\n",
    "\n",
    "        # Generate fake data\n",
    "        fake_data = self.generator(noise)\n",
    "\n",
    "        # Get critic outputs\n",
    "        critic_real = self.critic(real_data)\n",
    "        critic_fake = self.critic(fake_data)\n",
    "\n",
    "        # Calculate Cramer distance\n",
    "        critic_real2 = self.critic(torch.roll(real_data, shifts=1, dims=0))\n",
    "        critic_fake2 = self.critic(torch.roll(fake_data, shifts=1, dims=0))\n",
    "\n",
    "        # Cramer GAN loss function\n",
    "        c_loss = torch.mean(critic_real - critic_fake) - 0.5 * torch.mean(torch.pow(critic_real - critic_real2, 2)) + 0.5 * torch.mean(torch.pow(critic_fake - critic_fake2, 2))\n",
    "\n",
    "        # Calculate gradient penalty\n",
    "        alpha = torch.rand(batch_size, 1).to(device)\n",
    "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "        interpolates.requires_grad_(True)\n",
    "\n",
    "        critic_interpolates = self.critic(interpolates)\n",
    "        gradients = torch_grad(outputs=critic_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones_like(critic_interpolates).to(device),\n",
    "                              create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        gradient_penalty = self.lambda_gp * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "\n",
    "        # Update critic\n",
    "        self.c_optimizer.zero_grad()\n",
    "        c_loss_total = c_loss + gradient_penalty\n",
    "        c_loss_total.backward()\n",
    "        self.c_optimizer.step()\n",
    "\n",
    "        return c_loss_total.item()\n",
    "\n",
    "    def _generator_train_iteration(self, batch_size):\n",
    "        # Generate random noise\n",
    "        noise = torch.randn(batch_size, self.latent_dim).to(device)\n",
    "\n",
    "        # Generate fake data\n",
    "        fake_data = self.generator(noise)\n",
    "\n",
    "        # Calculate critic outputs\n",
    "        critic_fake = self.critic(fake_data)\n",
    "        critic_fake2 = self.critic(torch.roll(fake_data, shifts=1, dims=0))\n",
    "\n",
    "        # Generator loss is negative of critic loss\n",
    "        g_loss = -torch.mean(critic_fake) + 0.5 * torch.mean(torch.pow(critic_fake - critic_fake2, 2))\n",
    "\n",
    "        # Update generator\n",
    "        self.g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "\n",
    "        return g_loss.item()\n",
    "\n",
    "    def train(self, data_loader, epochs, save_interval=10, verbose=True):\n",
    "        for epoch in range(epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            c_loss_total = 0\n",
    "            g_loss_total = 0\n",
    "            num_batches = 0\n",
    "\n",
    "            for i, (real_data, _) in enumerate(data_loader):\n",
    "                batch_size = real_data.size(0)\n",
    "                real_data = real_data.to(device)\n",
    "\n",
    "                # Train critic\n",
    "                for _ in range(self.critic_iterations):\n",
    "                    c_loss = self._critic_train_iteration(real_data, batch_size)\n",
    "                c_loss_total += c_loss\n",
    "\n",
    "                # Train generator\n",
    "                g_loss = self._generator_train_iteration(batch_size)\n",
    "                g_loss_total += g_loss\n",
    "\n",
    "                num_batches += 1\n",
    "\n",
    "            # Calculate average loss for the epoch\n",
    "            c_loss_avg = c_loss_total / num_batches\n",
    "            g_loss_avg = g_loss_total / num_batches\n",
    "\n",
    "            self.c_losses.append(c_loss_avg)\n",
    "            self.g_losses.append(g_loss_avg)\n",
    "\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "            if verbose and (epoch % save_interval == 0 or epoch == epochs - 1):\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] | Critic Loss: {c_loss_avg:.4f} | Generator Loss: {g_loss_avg:.4f} | Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    def generate_samples(self, num_samples):\n",
    "        self.generator.eval()\n",
    "        noise = torch.randn(num_samples, self.latent_dim).to(device)\n",
    "        with torch.no_grad():\n",
    "            generated_data = self.generator(noise).cpu().numpy()\n",
    "        self.generator.train()\n",
    "        return generated_data\n",
    "\n",
    "# Post-process generated data to make it valid for credit card data\n",
    "def post_process_credit_card_data(synthetic_data, preprocessor, feature_names):\n",
    "    \"\"\"\n",
    "    Post-process generated data to ensure it makes sense for credit card data\n",
    "    \"\"\"\n",
    "    # Get the number of categorical features (one-hot encoded)\n",
    "    cat_feature_names = [name for name in feature_names if any(col in name for col in\n",
    "                         ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_'])]\n",
    "    num_cat_features = len(cat_feature_names)\n",
    "\n",
    "    # Split the synthetic data into categorical and numerical\n",
    "    synthetic_cat = synthetic_data[:, :num_cat_features]\n",
    "    synthetic_num = synthetic_data[:, num_cat_features:]\n",
    "\n",
    "    # Process categorical features\n",
    "    processed_cat = np.zeros_like(synthetic_cat)\n",
    "\n",
    "    # Get categorical column groups (for one-hot encoded features)\n",
    "    cat_groups = {}\n",
    "    current_idx = 0\n",
    "\n",
    "    for col in ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']:\n",
    "        col_features = [f for f in feature_names if f.startswith(f\"{col}_\")]\n",
    "        if col_features:\n",
    "            end_idx = current_idx + len(col_features)\n",
    "            cat_groups[col] = (current_idx, end_idx)\n",
    "            current_idx = end_idx\n",
    "\n",
    "    # Process each categorical group to ensure one-hot encoding is maintained\n",
    "    for col, (start_idx, end_idx) in cat_groups.items():\n",
    "        # For each row, set the highest value to 1 and others to 0\n",
    "        max_indices = np.argmax(synthetic_cat[:, start_idx:end_idx], axis=1)\n",
    "\n",
    "        # Create a zeros array and set the max index to 1 for each row\n",
    "        one_hot = np.zeros((synthetic_cat.shape[0], end_idx - start_idx))\n",
    "        for i, idx in enumerate(max_indices):\n",
    "            one_hot[i, idx] = 1\n",
    "\n",
    "        processed_cat[:, start_idx:end_idx] = one_hot\n",
    "\n",
    "    # Process numerical features\n",
    "    processed_num = synthetic_num.copy()\n",
    "\n",
    "    # Define column constraints for numerical columns\n",
    "    # Each tuple contains (column name, min value, max value)\n",
    "    num_constraints = [\n",
    "        (\"LIMIT_BAL\", 10000, 1000000),  # Credit limit\n",
    "        (\"AGE\", 21, 80),                # Age\n",
    "        # Bill amounts can be negative (credit)\n",
    "        (\"BILL_AMT1\", -100000, 1000000),\n",
    "        (\"BILL_AMT2\", -100000, 1000000),\n",
    "        (\"BILL_AMT3\", -100000, 1000000),\n",
    "        (\"BILL_AMT4\", -100000, 1000000),\n",
    "        (\"BILL_AMT5\", -100000, 1000000),\n",
    "        (\"BILL_AMT6\", -100000, 1000000),\n",
    "        # Payment amounts should be non-negative\n",
    "        (\"PAY_AMT1\", 0, 1000000),\n",
    "        (\"PAY_AMT2\", 0, 1000000),\n",
    "        (\"PAY_AMT3\", 0, 1000000),\n",
    "        (\"PAY_AMT4\", 0, 1000000),\n",
    "        (\"PAY_AMT5\", 0, 1000000),\n",
    "        (\"PAY_AMT6\", 0, 1000000)\n",
    "    ]\n",
    "\n",
    "    # Get the indices of numerical columns\n",
    "    num_col_indices = {}\n",
    "    for i, name in enumerate(feature_names[num_cat_features:]):\n",
    "        num_col_indices[name] = i\n",
    "\n",
    "    # Apply constraints for numerical columns\n",
    "    for col, min_val, max_val in num_constraints:\n",
    "        if col in num_col_indices:\n",
    "            idx = num_col_indices[col]\n",
    "            processed_num[:, idx] = np.clip(processed_num[:, idx], min_val, max_val)\n",
    "\n",
    "            # Round specific columns that should be integers\n",
    "            if col in [\"AGE\"]:\n",
    "                processed_num[:, idx] = np.round(processed_num[:, idx])\n",
    "\n",
    "    # Combine processed categorical and numerical data\n",
    "    processed_data = np.hstack((processed_cat, processed_num))\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "# Evaluation Metrics\n",
    "\n",
    "# 1. Machine Learning Utility (TSTR)\n",
    "def evaluate_tstr(real_data, synthetic_data, real_labels, random_state=42):\n",
    "    \"\"\"\n",
    "    Train classifiers on synthetic data and test on real data (TSTR)\n",
    "    Returns accuracy for each classifier\n",
    "    \"\"\"\n",
    "    # Train-test split for real data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        real_data, real_labels, test_size=0.2, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Synthetic data (all used for training)\n",
    "    X_synth = synthetic_data\n",
    "\n",
    "    # Ensure proper dimensions for labels\n",
    "    if isinstance(y_train, pd.Series):\n",
    "        y_train = y_train.values\n",
    "\n",
    "    # Create synthetic labels based on real distribution\n",
    "    # For credit card default prediction, we need binary labels (0-1)\n",
    "    class_distribution = np.bincount(y_train.astype(int)) / len(y_train)\n",
    "    np.random.seed(random_state)\n",
    "    y_synth = np.random.choice([0, 1], size=len(X_synth), p=class_distribution)\n",
    "\n",
    "    # Define classifiers\n",
    "    classifiers = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, random_state=random_state),\n",
    "        'MLP': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=random_state),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=random_state),\n",
    "        'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=random_state)\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        # Train on synthetic data\n",
    "        clf.fit(X_synth, y_synth)\n",
    "\n",
    "        # Test on real data\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # For binary classification, also calculate AUC-ROC\n",
    "        auc = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "        results[name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'auc_roc': auc\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# 2. Statistical Similarity\n",
    "def jensen_shannon_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Calculate Jensen-Shannon Divergence between distributions p and q\n",
    "    \"\"\"\n",
    "    # Ensure p and q are normalized\n",
    "    p = p / np.sum(p)\n",
    "    q = q / np.sum(q)\n",
    "\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    # Calculate JSD\n",
    "    jsd = 0.5 * (entropy(p, m) + entropy(q, m))\n",
    "\n",
    "    return jsd\n",
    "\n",
    "def wasserstein_distance(p, q):\n",
    "    \"\"\"\n",
    "    Calculate 1D Wasserstein distance (Earth Mover's Distance)\n",
    "    \"\"\"\n",
    "    from scipy.stats import wasserstein_distance\n",
    "\n",
    "    return wasserstein_distance(p, q)\n",
    "\n",
    "def evaluate_statistical_similarity(real_data, synthetic_data, feature_names):\n",
    "    \"\"\"\n",
    "    Calculate statistical similarity metrics between real and synthetic data\n",
    "    \"\"\"\n",
    "    results = {'JSD': {}, 'WD': {}}\n",
    "\n",
    "    # Calculate metrics for each feature\n",
    "    for i in range(real_data.shape[1]):\n",
    "        feature_name = feature_names[i] if i < len(feature_names) else f\"feature_{i}\"\n",
    "\n",
    "        # Get feature values\n",
    "        real_values = real_data[:, i]\n",
    "        synth_values = synthetic_data[:, i]\n",
    "\n",
    "        # Calculate histogram (discrete distribution)\n",
    "        hist_bins = min(50, len(np.unique(real_values)))\n",
    "\n",
    "        hist_real, bin_edges = np.histogram(real_values, bins=hist_bins, density=True)\n",
    "        hist_synth, _ = np.histogram(synth_values, bins=bin_edges, density=True)\n",
    "\n",
    "        # Add a small epsilon to avoid division by zero\n",
    "        epsilon = 1e-10\n",
    "        hist_real = hist_real + epsilon\n",
    "        hist_synth = hist_synth + epsilon\n",
    "\n",
    "        # Calculate JSD\n",
    "        jsd = jensen_shannon_divergence(hist_real, hist_synth)\n",
    "        results['JSD'][feature_name] = jsd\n",
    "\n",
    "        # Calculate Wasserstein Distance\n",
    "        wd = wasserstein_distance(real_values, synth_values)\n",
    "        results['WD'][feature_name] = wd\n",
    "\n",
    "    # Calculate average metrics\n",
    "    results['JSD_avg'] = np.mean(list(results['JSD'].values()))\n",
    "    results['WD_avg'] = np.mean(list(results['WD'].values()))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Function to run a single fold\n",
    "def run_fold(X_train, y_train, X_test, y_test, preprocessor, cat_cols, num_cols, fold_num, run_num):\n",
    "    print(f\"\\nRunning Fold {fold_num} of Run {run_num}\")\n",
    "\n",
    "    # Fit preprocessor and transform data\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Get feature names\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_cols)\n",
    "    all_feature_names = list(cat_feature_names) + list(num_cols)\n",
    "\n",
    "    print(f\"Processed training data shape: {X_train_transformed.shape}\")\n",
    "    print(f\"Processed testing data shape: {X_test_transformed.shape}\")\n",
    "\n",
    "    # Create dataset and dataloader\n",
    "    train_dataset = CreditCardDataset(X_train_transformed, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    data_dim = X_train_transformed.shape[1]\n",
    "    latent_dim = 100\n",
    "\n",
    "    print(f\"Data dimension: {data_dim}\")\n",
    "    print(f\"Latent dimension: {latent_dim}\")\n",
    "\n",
    "    crgan = CramerGAN(data_dim, latent_dim)\n",
    "\n",
    "    # Train the model\n",
    "    epochs = 300\n",
    "\n",
    "    print(f\"Training CramerGAN for {epochs} epochs...\")\n",
    "    crgan.train(train_loader, epochs, save_interval=10, verbose=True)\n",
    "\n",
    "    # Generate synthetic data\n",
    "    num_samples = 1000\n",
    "    print(f\"Generating {num_samples} synthetic samples...\")\n",
    "    synthetic_data_raw = crgan.generate_samples(num_samples)\n",
    "\n",
    "    # Post-process the synthetic data\n",
    "    synthetic_data_processed = post_process_credit_card_data(synthetic_data_raw, preprocessor, all_feature_names)\n",
    "\n",
    "    # Generate synthetic labels using a classifier trained on real data\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train_transformed, y_train)\n",
    "    synthetic_labels = clf.predict(synthetic_data_processed)\n",
    "\n",
    "    # Evaluate statistical similarity\n",
    "    print(\"Evaluating statistical similarity...\")\n",
    "    stat_results = evaluate_statistical_similarity(X_train_transformed, synthetic_data_processed, all_feature_names)\n",
    "\n",
    "    # Evaluate Machine Learning Utility (TSTR)\n",
    "    print(\"Evaluating Machine Learning Utility (TSTR)...\")\n",
    "    tstr_results = evaluate_tstr(X_train_transformed, synthetic_data_processed, y_train)\n",
    "\n",
    "    # Combine results\n",
    "    results = {\n",
    "        'statistical': stat_results,\n",
    "        'tstr': tstr_results\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    print(\"Starting CrGAN Cross-Validation on Credit Card Dataset\")\n",
    "\n",
    "    # File path\n",
    "    file_path = 'UCI_Credit_Card.csv'\n",
    "\n",
    "    # Run cross-validation twice (once with original data, once with shuffled data)\n",
    "    all_results = []\n",
    "\n",
    "    # Run 1: Original data order\n",
    "    print(\"\\n===== Run 1: Original Data Order =====\")\n",
    "    X, y, preprocessor, cat_cols, num_cols = load_credit_card_data(file_path, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    fold_num = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Run this fold\n",
    "        fold_results = run_fold(X_train, y_train, X_test, y_test, preprocessor, cat_cols, num_cols, fold_num, 1)\n",
    "        all_results.append(fold_results)\n",
    "        fold_num += 1\n",
    "\n",
    "    # Run 2: Shuffled data with seed=123\n",
    "    print(\"\\n===== Run 2: Shuffled Data (seed=123) =====\")\n",
    "    X, y, preprocessor, cat_cols, num_cols = load_credit_card_data(file_path, shuffle=True, random_state=123)\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    fold_num = 1\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Run this fold\n",
    "        fold_results = run_fold(X_train, y_train, X_test, y_test, preprocessor, cat_cols, num_cols, fold_num, 2)\n",
    "        all_results.append(fold_results)\n",
    "        fold_num += 1\n",
    "\n",
    "    # Calculate average results\n",
    "    print(\"\\n===== Final Average Results (10 runs) =====\")\n",
    "\n",
    "    # Initialize dictionaries to store aggregate results\n",
    "    agg_statistical = {\n",
    "        'JSD_avg': 0.0,\n",
    "        'WD_avg': 0.0\n",
    "    }\n",
    "\n",
    "    agg_tstr = {\n",
    "        'Logistic Regression': {'accuracy': 0.0, 'f1_score': 0.0, 'auc_roc': 0.0},\n",
    "        'MLP': {'accuracy': 0.0, 'f1_score': 0.0, 'auc_roc': 0.0},\n",
    "        'Random Forest': {'accuracy': 0.0, 'f1_score': 0.0, 'auc_roc': 0.0},\n",
    "        'XGBoost': {'accuracy': 0.0, 'f1_score': 0.0, 'auc_roc': 0.0}\n",
    "    }\n",
    "\n",
    "    # Sum up all results\n",
    "    for result in all_results:\n",
    "        # Statistical results\n",
    "        agg_statistical['JSD_avg'] += result['statistical']['JSD_avg']\n",
    "        agg_statistical['WD_avg'] += result['statistical']['WD_avg']\n",
    "\n",
    "        # TSTR results\n",
    "        for clf_name, metrics in result['tstr'].items():\n",
    "            for metric_name, value in metrics.items():\n",
    "                agg_tstr[clf_name][metric_name] += value\n",
    "\n",
    "    # Calculate averages\n",
    "    num_runs = len(all_results)\n",
    "    agg_statistical['JSD_avg'] /= num_runs\n",
    "    agg_statistical['WD_avg'] /= num_runs\n",
    "\n",
    "    for clf_name in agg_tstr.keys():\n",
    "        for metric_name in agg_tstr[clf_name].keys():\n",
    "            agg_tstr[clf_name][metric_name] /= num_runs\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\nAverage Statistical Similarity Metrics:\")\n",
    "    print(f\"Average Jensen-Shannon Divergence: {agg_statistical['JSD_avg']:.6f}\")\n",
    "    print(f\"Average Wasserstein Distance: {agg_statistical['WD_avg']:.6f}\")\n",
    "\n",
    "    print(\"\\nAverage TSTR Results:\")\n",
    "    for clf_name, metrics in agg_tstr.items():\n",
    "        print(f\"{clf_name}:\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']:.6f}\")\n",
    "        print(f\"  F1 Score: {metrics['f1_score']:.6f}\")\n",
    "        print(f\"  AUC-ROC: {metrics['auc_roc']:.6f}\")\n",
    "\n",
    "    print(\"\\nCross-validation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "saG2Dp0h4RhN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CrGAN Cross-Validation on Credit Card Dataset\n",
      "\n",
      "===== Run 1: Original Data Order =====\n",
      "Dataset shape: (30000, 25)\n",
      "\n",
      "Running Fold 1 of Run 1\n",
      "Processed training data shape: (24000, 91)\n",
      "Processed testing data shape: (6000, 91)\n",
      "Data dimension: 91\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -1138.2170 | Generator Loss: -13.4279 | Time: 26.98s\n",
      "Epoch [11/300] | Critic Loss: -1490200095286.4680 | Generator Loss: 7509217.6150 | Time: 25.65s\n",
      "Epoch [21/300] | Critic Loss: -33722822418257.7031 | Generator Loss: 67179789.7553 | Time: 26.49s\n",
      "Epoch [31/300] | Critic Loss: -7130078429315072.0000 | Generator Loss: 5553004187.2340 | Time: 27.95s\n",
      "Epoch [41/300] | Critic Loss: -8304007664654118.0000 | Generator Loss: 133867073971.7447 | Time: 26.63s\n",
      "Epoch [51/300] | Critic Loss: -72251315613580960.0000 | Generator Loss: 88186062956.9362 | Time: 28.44s\n",
      "Epoch [61/300] | Critic Loss: -77655208374611536.0000 | Generator Loss: 9644158403605.7871 | Time: 27.66s\n",
      "Epoch [71/300] | Critic Loss: -1898269314755781888.0000 | Generator Loss: 8416471210463.3193 | Time: 27.93s\n",
      "Epoch [81/300] | Critic Loss: -29556899855212650496.0000 | Generator Loss: 32469886887108.0859 | Time: 25.50s\n",
      "Epoch [91/300] | Critic Loss: -210576369457775542272.0000 | Generator Loss: 150107297465365.7812 | Time: 37.43s\n",
      "Epoch [101/300] | Critic Loss: -857341989740665765888.0000 | Generator Loss: 491328944990774.4375 | Time: 21.51s\n",
      "Epoch [111/300] | Critic Loss: -2693832860264460976128.0000 | Generator Loss: 1357458810049296.2500 | Time: 21.89s\n",
      "Epoch [121/300] | Critic Loss: -3572208745126144507904.0000 | Generator Loss: 1699888318515940.7500 | Time: 21.93s\n",
      "Epoch [131/300] | Critic Loss: -355545919335190233088.0000 | Generator Loss: 733486989872542.0000 | Time: 24.87s\n",
      "Epoch [141/300] | Critic Loss: 556363497357368229888.0000 | Generator Loss: 722894981012981.1250 | Time: 25.36s\n",
      "Epoch [151/300] | Critic Loss: -87139915625649356800.0000 | Generator Loss: 2018410451959808.0000 | Time: 21.87s\n",
      "Epoch [161/300] | Critic Loss: -990003011036118646784.0000 | Generator Loss: 2634035852587966.5000 | Time: 22.95s\n",
      "Epoch [171/300] | Critic Loss: -1193532851989734227968.0000 | Generator Loss: 2943379342143052.5000 | Time: 35.29s\n",
      "Epoch [181/300] | Critic Loss: -1560374880174056669184.0000 | Generator Loss: 3377901099236330.0000 | Time: 21.42s\n",
      "Epoch [191/300] | Critic Loss: -1430155102580670201856.0000 | Generator Loss: 2772966021418049.5000 | Time: 21.28s\n",
      "Epoch [201/300] | Critic Loss: -1322998049070022918144.0000 | Generator Loss: 2608572355798909.5000 | Time: 22.33s\n",
      "Epoch [211/300] | Critic Loss: -1345672972500806139904.0000 | Generator Loss: 2858399471188970.0000 | Time: 22.16s\n",
      "Epoch [221/300] | Critic Loss: -2115451364641769259008.0000 | Generator Loss: 3267839680878722.5000 | Time: 21.83s\n",
      "Epoch [231/300] | Critic Loss: -8173057294223632498688.0000 | Generator Loss: 14103906014082680.0000 | Time: 22.54s\n",
      "Epoch [241/300] | Critic Loss: -19090189031227061698560.0000 | Generator Loss: 23503293168166432.0000 | Time: 21.91s\n",
      "Epoch [251/300] | Critic Loss: -14260020758446124040192.0000 | Generator Loss: 12799874023499296.0000 | Time: 22.07s\n",
      "Epoch [261/300] | Critic Loss: -4595960766071054532608.0000 | Generator Loss: 10394695716028068.0000 | Time: 21.57s\n",
      "Epoch [271/300] | Critic Loss: 2793828127350390259712.0000 | Generator Loss: 6602170955570677.0000 | Time: 21.93s\n",
      "Epoch [281/300] | Critic Loss: 1378495994116134404096.0000 | Generator Loss: 6543004786870664.0000 | Time: 21.86s\n",
      "Epoch [291/300] | Critic Loss: 49540152862199586816.0000 | Generator Loss: 9252674686563960.0000 | Time: 25.28s\n",
      "Epoch [300/300] | Critic Loss: -929389870646086205440.0000 | Generator Loss: 15388352876692502.0000 | Time: 25.59s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "Running Fold 2 of Run 1\n",
      "Processed training data shape: (24000, 87)\n",
      "Processed testing data shape: (6000, 87)\n",
      "Data dimension: 87\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -8865.3200 | Generator Loss: 11.8264 | Time: 24.92s\n",
      "Epoch [11/300] | Critic Loss: -157175761712062.6250 | Generator Loss: 459011347.1915 | Time: 27.54s\n",
      "Epoch [21/300] | Critic Loss: 969170450444200.8750 | Generator Loss: 1051626037.1064 | Time: 25.60s\n",
      "Epoch [31/300] | Critic Loss: -829350908543324.6250 | Generator Loss: 3990741283.4043 | Time: 25.23s\n",
      "Epoch [41/300] | Critic Loss: -18378352713101924.0000 | Generator Loss: 269124312347.2340 | Time: 27.30s\n",
      "Epoch [51/300] | Critic Loss: -141980247011712160.0000 | Generator Loss: 1610865385297.7021 | Time: 24.95s\n",
      "Epoch [61/300] | Critic Loss: -492053665172969280.0000 | Generator Loss: 7668443769398.4678 | Time: 22.61s\n",
      "Epoch [71/300] | Critic Loss: -931450714017692288.0000 | Generator Loss: 30954217041135.6602 | Time: 25.23s\n",
      "Epoch [81/300] | Critic Loss: -2684998812404982784.0000 | Generator Loss: 114204944841706.2188 | Time: 23.19s\n",
      "Epoch [91/300] | Critic Loss: -9262273483455287296.0000 | Generator Loss: 210748488966666.9062 | Time: 24.85s\n",
      "Epoch [101/300] | Critic Loss: -16493994976892688384.0000 | Generator Loss: 457915600631764.4375 | Time: 28.95s\n",
      "Epoch [111/300] | Critic Loss: -46008982653638533120.0000 | Generator Loss: 1619607778782447.7500 | Time: 25.34s\n",
      "Epoch [121/300] | Critic Loss: -177586266710518890496.0000 | Generator Loss: 5589183196656226.0000 | Time: 33.88s\n",
      "Epoch [131/300] | Critic Loss: -646611701474839363584.0000 | Generator Loss: 21317885741403548.0000 | Time: 29.02s\n",
      "Epoch [141/300] | Critic Loss: -1535040898571263541248.0000 | Generator Loss: 8328744674435943.0000 | Time: 22.80s\n",
      "Epoch [151/300] | Critic Loss: -423724530674385747968.0000 | Generator Loss: 5549628309110784.0000 | Time: 23.07s\n",
      "Epoch [161/300] | Critic Loss: -1171047654670912323584.0000 | Generator Loss: 18279054548469108.0000 | Time: 24.07s\n",
      "Epoch [171/300] | Critic Loss: -2875074271377256087552.0000 | Generator Loss: 67532643259997336.0000 | Time: 24.98s\n",
      "Epoch [181/300] | Critic Loss: -8791723272915299336192.0000 | Generator Loss: 356150525022805504.0000 | Time: 24.12s\n",
      "Epoch [191/300] | Critic Loss: -17530528483638845112320.0000 | Generator Loss: 398322844541319808.0000 | Time: 27.53s\n",
      "Epoch [201/300] | Critic Loss: -24436608929831441137664.0000 | Generator Loss: 187532301928179232.0000 | Time: 26.66s\n",
      "Epoch [211/300] | Critic Loss: -47761499213119237390336.0000 | Generator Loss: 162427923649343744.0000 | Time: 24.51s\n",
      "Epoch [221/300] | Critic Loss: -50402724711655601602560.0000 | Generator Loss: 98842278893090768.0000 | Time: 35.05s\n",
      "Epoch [231/300] | Critic Loss: -46079775149410394046464.0000 | Generator Loss: 97608729583257648.0000 | Time: 30.38s\n",
      "Epoch [241/300] | Critic Loss: -37566076077790206099456.0000 | Generator Loss: 121769197667815504.0000 | Time: 30.28s\n",
      "Epoch [251/300] | Critic Loss: -38813344113829080989696.0000 | Generator Loss: 179414327722067648.0000 | Time: 31.34s\n",
      "Epoch [261/300] | Critic Loss: -50188822462413525745664.0000 | Generator Loss: 256629769506289632.0000 | Time: 31.79s\n",
      "Epoch [271/300] | Critic Loss: -65298629949856491241472.0000 | Generator Loss: 379549525036487808.0000 | Time: 32.84s\n",
      "Epoch [281/300] | Critic Loss: -95723171068731432370176.0000 | Generator Loss: 689803246662219776.0000 | Time: 30.41s\n",
      "Epoch [291/300] | Critic Loss: -134711929717297726357504.0000 | Generator Loss: 1179171790212306432.0000 | Time: 38.26s\n",
      "Epoch [300/300] | Critic Loss: -178549256538095930572800.0000 | Generator Loss: 1623188686086468864.0000 | Time: 45.83s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "Running Fold 3 of Run 1\n",
      "Processed training data shape: (24000, 91)\n",
      "Processed testing data shape: (6000, 91)\n",
      "Data dimension: 91\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -909.3748 | Generator Loss: -14.4658 | Time: 45.17s\n",
      "Epoch [11/300] | Critic Loss: -10118651891450.5527 | Generator Loss: 100039963.5851 | Time: 24.18s\n",
      "Epoch [21/300] | Critic Loss: -856534293430620.6250 | Generator Loss: 1907958368.0000 | Time: 20.69s\n",
      "Epoch [31/300] | Critic Loss: -2945804542974082.5000 | Generator Loss: 5628206737.7021 | Time: 20.56s\n",
      "Epoch [41/300] | Critic Loss: -22059281853760532.0000 | Generator Loss: 207497007801.1915 | Time: 21.47s\n",
      "Epoch [51/300] | Critic Loss: -287943199286077664.0000 | Generator Loss: 527289027910.8085 | Time: 24.83s\n",
      "Epoch [61/300] | Critic Loss: -139375653284161056.0000 | Generator Loss: 514895458042.5532 | Time: 23.61s\n",
      "Epoch [71/300] | Critic Loss: -913974201860137856.0000 | Generator Loss: 8783423770013.9570 | Time: 22.26s\n",
      "Epoch [81/300] | Critic Loss: -2826899882334268928.0000 | Generator Loss: 18457035153582.2969 | Time: 26.47s\n",
      "Epoch [91/300] | Critic Loss: -5081953750393881600.0000 | Generator Loss: 47893714611788.2578 | Time: 23.13s\n",
      "Epoch [101/300] | Critic Loss: -8201908505069725696.0000 | Generator Loss: 120333933360759.8281 | Time: 25.45s\n",
      "Epoch [111/300] | Critic Loss: -17453614360028745728.0000 | Generator Loss: 267439096229103.6562 | Time: 24.56s\n",
      "Epoch [121/300] | Critic Loss: -26336343377553494016.0000 | Generator Loss: 656827852013916.6250 | Time: 23.45s\n",
      "Epoch [131/300] | Critic Loss: -55126098541813243904.0000 | Generator Loss: 1355957611176807.5000 | Time: 21.88s\n",
      "Epoch [141/300] | Critic Loss: -85971803361968603136.0000 | Generator Loss: 3027969763939088.5000 | Time: 24.28s\n",
      "Epoch [151/300] | Critic Loss: -69174118337378795520.0000 | Generator Loss: 5442455963044581.0000 | Time: 24.64s\n",
      "Epoch [161/300] | Critic Loss: -195773134333207445504.0000 | Generator Loss: 7986300766477465.0000 | Time: 22.45s\n",
      "Epoch [171/300] | Critic Loss: -288909806214744113152.0000 | Generator Loss: 20097306915822048.0000 | Time: 24.21s\n",
      "Epoch [181/300] | Critic Loss: -418788777873928683520.0000 | Generator Loss: 36427506252150744.0000 | Time: 23.27s\n",
      "Epoch [191/300] | Critic Loss: -877482346291133546496.0000 | Generator Loss: 23596832398485720.0000 | Time: 22.55s\n",
      "Epoch [201/300] | Critic Loss: -1822881410919328645120.0000 | Generator Loss: 58842944002521744.0000 | Time: 24.78s\n",
      "Epoch [211/300] | Critic Loss: -2681151139937421623296.0000 | Generator Loss: 44950287299925800.0000 | Time: 23.81s\n",
      "Epoch [221/300] | Critic Loss: -4503990709900903710720.0000 | Generator Loss: 35500506115155488.0000 | Time: 21.91s\n",
      "Epoch [231/300] | Critic Loss: -13320918851248296296448.0000 | Generator Loss: 133721763841489200.0000 | Time: 24.67s\n",
      "Epoch [241/300] | Critic Loss: -35138464801739958648832.0000 | Generator Loss: 239205898295560576.0000 | Time: 24.26s\n",
      "Epoch [251/300] | Critic Loss: -34841593299512793759744.0000 | Generator Loss: 29190257896972112.0000 | Time: 21.54s\n",
      "Epoch [261/300] | Critic Loss: -27302067623735945330688.0000 | Generator Loss: 25384815375556784.0000 | Time: 23.25s\n",
      "Epoch [271/300] | Critic Loss: -29386724338327269408768.0000 | Generator Loss: 29382810384811728.0000 | Time: 23.90s\n",
      "Epoch [281/300] | Critic Loss: -29705104685022660526080.0000 | Generator Loss: 38516140001248280.0000 | Time: 21.73s\n",
      "Epoch [291/300] | Critic Loss: -67705263662462639538176.0000 | Generator Loss: 81312690946117712.0000 | Time: 22.56s\n",
      "Epoch [300/300] | Critic Loss: -100231795371788321423360.0000 | Generator Loss: 170746444545361952.0000 | Time: 24.09s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "Running Fold 4 of Run 1\n",
      "Processed training data shape: (24000, 91)\n",
      "Processed testing data shape: (6000, 91)\n",
      "Data dimension: 91\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -15314040.4258 | Generator Loss: 8.2723 | Time: 22.38s\n",
      "Epoch [11/300] | Critic Loss: -565547640352.6809 | Generator Loss: 28675474.4362 | Time: 21.62s\n",
      "Epoch [21/300] | Critic Loss: -29364581324582.1289 | Generator Loss: 1819148800.0000 | Time: 23.00s\n",
      "Epoch [31/300] | Critic Loss: -47512096297395.7422 | Generator Loss: 7819558912.0000 | Time: 25.05s\n",
      "Epoch [41/300] | Critic Loss: -192381182469316.0938 | Generator Loss: 37244664494.2979 | Time: 21.61s\n",
      "Epoch [51/300] | Critic Loss: -374340186303727.6875 | Generator Loss: 122438510330.5532 | Time: 22.56s\n",
      "Epoch [61/300] | Critic Loss: -2044858964087568.2500 | Generator Loss: 875594122958.9788 | Time: 24.90s\n",
      "Epoch [71/300] | Critic Loss: -24929823040431996.0000 | Generator Loss: 4678008079033.1914 | Time: 22.09s\n",
      "Epoch [81/300] | Critic Loss: -46611959315353336.0000 | Generator Loss: 4308930036409.1914 | Time: 23.22s\n",
      "Epoch [91/300] | Critic Loss: -239827571463483296.0000 | Generator Loss: 2149563356268.9363 | Time: 24.18s\n",
      "Epoch [101/300] | Critic Loss: -667336144253353984.0000 | Generator Loss: 4856396397546.2129 | Time: 21.73s\n",
      "Epoch [111/300] | Critic Loss: -958908320778523392.0000 | Generator Loss: 12365231565715.0645 | Time: 23.03s\n",
      "Epoch [121/300] | Critic Loss: -740729973895248128.0000 | Generator Loss: 16800934800275.0645 | Time: 23.35s\n",
      "Epoch [131/300] | Critic Loss: -1938268081271396864.0000 | Generator Loss: 55700817232917.7891 | Time: 21.84s\n",
      "Epoch [141/300] | Critic Loss: -3718184989181646848.0000 | Generator Loss: 146814919374107.2188 | Time: 21.85s\n",
      "Epoch [151/300] | Critic Loss: -8074121977027055616.0000 | Generator Loss: 279471709832910.9688 | Time: 23.29s\n",
      "Epoch [161/300] | Critic Loss: -18492198001371131904.0000 | Generator Loss: 721246140854882.0000 | Time: 22.80s\n",
      "Epoch [171/300] | Critic Loss: -42978795420364668928.0000 | Generator Loss: 1649286867538355.7500 | Time: 21.06s\n",
      "Epoch [181/300] | Critic Loss: -96262766753625456640.0000 | Generator Loss: 2900882581194795.5000 | Time: 23.62s\n",
      "Epoch [191/300] | Critic Loss: -137600637077954019328.0000 | Generator Loss: 4320507798782649.0000 | Time: 22.99s\n",
      "Epoch [201/300] | Critic Loss: -243224106555101708288.0000 | Generator Loss: 7295688047580269.0000 | Time: 21.73s\n",
      "Epoch [211/300] | Critic Loss: -468181902731205672960.0000 | Generator Loss: 12764346362441990.0000 | Time: 22.11s\n",
      "Epoch [221/300] | Critic Loss: -645801286357651292160.0000 | Generator Loss: 41135447075940224.0000 | Time: 23.19s\n",
      "Epoch [231/300] | Critic Loss: 34620877151945142272.0000 | Generator Loss: 11510901384792456.0000 | Time: 20.58s\n",
      "Epoch [241/300] | Critic Loss: 178448755774516101120.0000 | Generator Loss: 39090812325422976.0000 | Time: 22.97s\n",
      "Epoch [251/300] | Critic Loss: -213337761563156640.0000 | Generator Loss: 129604024738512896.0000 | Time: 23.22s\n",
      "Epoch [261/300] | Critic Loss: -34764173788704915456.0000 | Generator Loss: 123802143584877200.0000 | Time: 21.35s\n",
      "Epoch [271/300] | Critic Loss: -99703492258591145984.0000 | Generator Loss: 208212104688128448.0000 | Time: 21.81s\n",
      "Epoch [281/300] | Critic Loss: -269226841448356478976.0000 | Generator Loss: 562266544621932288.0000 | Time: 25.12s\n",
      "Epoch [291/300] | Critic Loss: -735661695437694042112.0000 | Generator Loss: 1506837081531373312.0000 | Time: 21.42s\n",
      "Epoch [300/300] | Critic Loss: -1898939662700708626432.0000 | Generator Loss: 2224992452545040896.0000 | Time: 21.85s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "Running Fold 5 of Run 1\n",
      "Processed training data shape: (24000, 91)\n",
      "Processed testing data shape: (6000, 91)\n",
      "Data dimension: 91\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -20124163.5117 | Generator Loss: 28.8078 | Time: 22.08s\n",
      "Epoch [11/300] | Critic Loss: -1507460826133.7874 | Generator Loss: 2730298.7673 | Time: 22.68s\n",
      "Epoch [21/300] | Critic Loss: -21355183963462.8086 | Generator Loss: 81083560.0426 | Time: 23.03s\n",
      "Epoch [31/300] | Critic Loss: -833180305953552.3750 | Generator Loss: 5832809322.2128 | Time: 21.01s\n",
      "Epoch [41/300] | Critic Loss: -48079014916968184.0000 | Generator Loss: 29099669569.3617 | Time: 23.70s\n",
      "Epoch [51/300] | Critic Loss: -36285703708999680.0000 | Generator Loss: 14404433070472.1699 | Time: 21.99s\n",
      "Epoch [61/300] | Critic Loss: -3021435671934703616.0000 | Generator Loss: 3271942010836.4253 | Time: 21.50s\n",
      "Epoch [71/300] | Critic Loss: -4885367364297062400.0000 | Generator Loss: 1897130696181.1064 | Time: 23.71s\n",
      "Epoch [81/300] | Critic Loss: -5419341127490999296.0000 | Generator Loss: 6921054800961.3613 | Time: 22.91s\n",
      "Epoch [91/300] | Critic Loss: -17993892336897589248.0000 | Generator Loss: 37585292261332.4219 | Time: 20.87s\n",
      "Epoch [101/300] | Critic Loss: -45107775200029908992.0000 | Generator Loss: 121713398226421.1094 | Time: 22.16s\n",
      "Epoch [111/300] | Critic Loss: -85861814675432472576.0000 | Generator Loss: 222930109548238.9688 | Time: 22.83s\n",
      "Epoch [121/300] | Critic Loss: -161015431708490858496.0000 | Generator Loss: 516659968346852.7500 | Time: 21.50s\n",
      "Epoch [131/300] | Critic Loss: -275062597199130886144.0000 | Generator Loss: 979152702989508.1250 | Time: 22.00s\n",
      "Epoch [141/300] | Critic Loss: -354350359986139168768.0000 | Generator Loss: 1829089975914234.5000 | Time: 23.90s\n",
      "Epoch [151/300] | Critic Loss: -512064422036387004416.0000 | Generator Loss: 2876455395189956.0000 | Time: 21.22s\n",
      "Epoch [161/300] | Critic Loss: -635283550143185289216.0000 | Generator Loss: 4905347195812842.0000 | Time: 21.80s\n",
      "Epoch [171/300] | Critic Loss: -653651806117404868608.0000 | Generator Loss: 7510790433055591.0000 | Time: 23.34s\n",
      "Epoch [181/300] | Critic Loss: -1184349073600534282240.0000 | Generator Loss: 13499085675287660.0000 | Time: 21.41s\n",
      "Epoch [191/300] | Critic Loss: -1540568661370676445184.0000 | Generator Loss: 21091892232688400.0000 | Time: 21.12s\n",
      "Epoch [201/300] | Critic Loss: -2116845758737832738816.0000 | Generator Loss: 31443422704951120.0000 | Time: 23.00s\n",
      "Epoch [211/300] | Critic Loss: -2650446193566524375040.0000 | Generator Loss: 46333107375690864.0000 | Time: 22.60s\n",
      "Epoch [221/300] | Critic Loss: -3465075709815371595776.0000 | Generator Loss: 70296887055976488.0000 | Time: 20.50s\n",
      "Epoch [231/300] | Critic Loss: -4953120543146117169152.0000 | Generator Loss: 111505788101883856.0000 | Time: 22.29s\n",
      "Epoch [241/300] | Critic Loss: -6983875099138817261568.0000 | Generator Loss: 148123957164780448.0000 | Time: 22.13s\n",
      "Epoch [251/300] | Critic Loss: -9349284477739924979712.0000 | Generator Loss: 226929684016010688.0000 | Time: 20.61s\n",
      "Epoch [261/300] | Critic Loss: -11163088170939603484672.0000 | Generator Loss: 340883369537970368.0000 | Time: 21.88s\n",
      "Epoch [271/300] | Critic Loss: -14629814989013041283072.0000 | Generator Loss: 469502757717342848.0000 | Time: 24.92s\n",
      "Epoch [281/300] | Critic Loss: -17879528516736922943488.0000 | Generator Loss: 602649118736110720.0000 | Time: 21.42s\n",
      "Epoch [291/300] | Critic Loss: -23268889219687302299648.0000 | Generator Loss: 762265218816119552.0000 | Time: 22.81s\n",
      "Epoch [300/300] | Critic Loss: -29261047701606651396096.0000 | Generator Loss: 920957870040276864.0000 | Time: 22.85s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "===== Run 2: Shuffled Data (seed=123) =====\n",
      "Dataset shape: (30000, 25)\n",
      "\n",
      "Running Fold 1 of Run 2\n",
      "Processed training data shape: (24000, 91)\n",
      "Processed testing data shape: (6000, 91)\n",
      "Data dimension: 91\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -47527393.1862 | Generator Loss: 44.2314 | Time: 23.36s\n",
      "Epoch [11/300] | Critic Loss: -3813808939182.2979 | Generator Loss: 5445343.6024 | Time: 21.58s\n",
      "Epoch [21/300] | Critic Loss: -117027700747155.0625 | Generator Loss: 189141248.5532 | Time: 21.56s\n",
      "Epoch [31/300] | Critic Loss: -762033625829463.1250 | Generator Loss: 35292657963.5745 | Time: 23.10s\n",
      "Epoch [41/300] | Critic Loss: -98312063581209616.0000 | Generator Loss: 43516911398.1277 | Time: 21.61s\n",
      "Epoch [51/300] | Critic Loss: -2410158262081318.0000 | Generator Loss: 14413015430775.8301 | Time: 21.08s\n",
      "Epoch [61/300] | Critic Loss: -207996797931888800.0000 | Generator Loss: 220731371773080.5000 | Time: 23.29s\n",
      "Epoch [71/300] | Critic Loss: -5099084404735606784.0000 | Generator Loss: 4695752798818.0430 | Time: 22.49s\n",
      "Epoch [81/300] | Critic Loss: -20008018816283586560.0000 | Generator Loss: 6648828141742.2979 | Time: 20.74s\n",
      "Epoch [91/300] | Critic Loss: -11969108453500481536.0000 | Generator Loss: 21230037683962.5547 | Time: 22.71s\n",
      "Epoch [101/300] | Critic Loss: -20822531088098484224.0000 | Generator Loss: 55408402517057.3594 | Time: 23.14s\n",
      "Epoch [111/300] | Critic Loss: -12603260580913311744.0000 | Generator Loss: 185225147446555.2188 | Time: 25.42s\n",
      "Epoch [121/300] | Critic Loss: -19630838744836190208.0000 | Generator Loss: 683026641260631.1250 | Time: 22.47s\n",
      "Epoch [131/300] | Critic Loss: -54122108554089201664.0000 | Generator Loss: 1248926514633880.5000 | Time: 24.20s\n",
      "Epoch [141/300] | Critic Loss: -65956526224946642944.0000 | Generator Loss: 1012754161704437.1250 | Time: 21.44s\n",
      "Epoch [151/300] | Critic Loss: -104796849710801829888.0000 | Generator Loss: 895307741804151.8750 | Time: 22.75s\n",
      "Epoch [161/300] | Critic Loss: -152420880196984242176.0000 | Generator Loss: 1097877933160404.3750 | Time: 23.25s\n",
      "Epoch [171/300] | Critic Loss: -273283322753995014144.0000 | Generator Loss: 1101843310441755.2500 | Time: 21.26s\n",
      "Epoch [181/300] | Critic Loss: -404370113644394446848.0000 | Generator Loss: 1182707381023678.7500 | Time: 21.39s\n",
      "Epoch [191/300] | Critic Loss: -562732967655621853184.0000 | Generator Loss: 1605734013326445.0000 | Time: 23.18s\n",
      "Epoch [201/300] | Critic Loss: -716985348257882177536.0000 | Generator Loss: 1234568698474757.5000 | Time: 21.60s\n",
      "Epoch [211/300] | Critic Loss: -884013180354426830848.0000 | Generator Loss: 1628894492751131.2500 | Time: 20.81s\n",
      "Epoch [221/300] | Critic Loss: -1367876506194794774528.0000 | Generator Loss: 4466492183674880.0000 | Time: 23.24s\n",
      "Epoch [231/300] | Critic Loss: -3399918471837090578432.0000 | Generator Loss: 10945065056284934.0000 | Time: 22.27s\n",
      "Epoch [241/300] | Critic Loss: -8109045842059858018304.0000 | Generator Loss: 19399505346916964.0000 | Time: 20.61s\n",
      "Epoch [251/300] | Critic Loss: -15342374905340676276224.0000 | Generator Loss: 30861494598957708.0000 | Time: 22.62s\n",
      "Epoch [261/300] | Critic Loss: -27818509119403256184832.0000 | Generator Loss: 33141819495053268.0000 | Time: 23.16s\n",
      "Epoch [271/300] | Critic Loss: -39854899025799381254144.0000 | Generator Loss: 555189322596020160.0000 | Time: 21.55s\n",
      "Epoch [281/300] | Critic Loss: -58811054643845135335424.0000 | Generator Loss: 50080561676017488.0000 | Time: 22.39s\n",
      "Epoch [291/300] | Critic Loss: -52010658397414571900928.0000 | Generator Loss: 38701114681815648.0000 | Time: 24.97s\n",
      "Epoch [300/300] | Critic Loss: -33473860106002947375104.0000 | Generator Loss: 31922461830907948.0000 | Time: 21.31s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "Running Fold 2 of Run 2\n",
      "Processed training data shape: (24000, 87)\n",
      "Processed testing data shape: (6000, 87)\n",
      "Data dimension: 87\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -21901291.1057 | Generator Loss: 29.2406 | Time: 21.59s\n",
      "Epoch [11/300] | Critic Loss: -665772646922.8937 | Generator Loss: 6623867.3521 | Time: 22.11s\n",
      "Epoch [21/300] | Critic Loss: -54019247771735.1484 | Generator Loss: 101515474.0638 | Time: 23.09s\n",
      "Epoch [31/300] | Critic Loss: -210212869340486.8125 | Generator Loss: 1360873473.3617 | Time: 25.75s\n",
      "Epoch [41/300] | Critic Loss: -897365660819978.8750 | Generator Loss: 5948479613.2766 | Time: 21.80s\n",
      "Epoch [51/300] | Critic Loss: -1982605987542299.2500 | Generator Loss: 21709992698.5532 | Time: 22.83s\n",
      "Epoch [61/300] | Critic Loss: -5037299768341439.0000 | Generator Loss: 70538416738.0426 | Time: 21.19s\n",
      "Epoch [71/300] | Critic Loss: -24463574641209256.0000 | Generator Loss: 213310742222.9787 | Time: 20.78s\n",
      "Epoch [81/300] | Critic Loss: -87495495856233280.0000 | Generator Loss: 586538802677.1063 | Time: 23.53s\n",
      "Epoch [91/300] | Critic Loss: -3721873381353430528.0000 | Generator Loss: 91724436343524.7656 | Time: 22.17s\n",
      "Epoch [101/300] | Critic Loss: -88696526707775651840.0000 | Generator Loss: 425244352873145.1875 | Time: 21.12s\n",
      "Epoch [111/300] | Critic Loss: -198237833659496726528.0000 | Generator Loss: 101282202768492.9375 | Time: 22.63s\n",
      "Epoch [121/300] | Critic Loss: -208665363132756295680.0000 | Generator Loss: 141282746090517.7812 | Time: 23.00s\n",
      "Epoch [131/300] | Critic Loss: -154930655195541274624.0000 | Generator Loss: 453740188312423.5000 | Time: 21.32s\n",
      "Epoch [141/300] | Critic Loss: -367869082463705432064.0000 | Generator Loss: 1055033276470032.3750 | Time: 22.00s\n",
      "Epoch [151/300] | Critic Loss: -554002215755401134080.0000 | Generator Loss: 1559931930932507.2500 | Time: 23.69s\n",
      "Epoch [161/300] | Critic Loss: -947475224805016469504.0000 | Generator Loss: 2597441619646246.0000 | Time: 21.28s\n",
      "Epoch [171/300] | Critic Loss: -1777592852239526133760.0000 | Generator Loss: 5927043007345250.0000 | Time: 21.87s\n",
      "Epoch [181/300] | Critic Loss: -2878482627914928488448.0000 | Generator Loss: 12404921498828102.0000 | Time: 22.91s\n",
      "Epoch [191/300] | Critic Loss: -5588854517631955238912.0000 | Generator Loss: 24785557676220240.0000 | Time: 21.29s\n",
      "Epoch [201/300] | Critic Loss: -8604774025386740678656.0000 | Generator Loss: 29144771628892160.0000 | Time: 23.28s\n",
      "Epoch [211/300] | Critic Loss: -10279867772343118987264.0000 | Generator Loss: 38253693591572912.0000 | Time: 22.97s\n",
      "Epoch [221/300] | Critic Loss: -12453168035896852742144.0000 | Generator Loss: 52085867867916680.0000 | Time: 22.38s\n",
      "Epoch [231/300] | Critic Loss: -17232825911570866372608.0000 | Generator Loss: 85786387914586064.0000 | Time: 20.96s\n",
      "Epoch [241/300] | Critic Loss: -18089683148250776862720.0000 | Generator Loss: 87976588873246240.0000 | Time: 22.35s\n",
      "Epoch [251/300] | Critic Loss: -26252479559662229782528.0000 | Generator Loss: 110176797102540848.0000 | Time: 22.40s\n",
      "Epoch [261/300] | Critic Loss: -33944017892701917675520.0000 | Generator Loss: 159156783849384160.0000 | Time: 20.83s\n",
      "Epoch [271/300] | Critic Loss: -44596930380620665716736.0000 | Generator Loss: 204994611816855520.0000 | Time: 22.68s\n",
      "Epoch [281/300] | Critic Loss: -60026442033496300978176.0000 | Generator Loss: 280084708864607264.0000 | Time: 23.69s\n",
      "Epoch [291/300] | Critic Loss: -74743433248406987866112.0000 | Generator Loss: 451669983688286720.0000 | Time: 21.39s\n",
      "Epoch [300/300] | Critic Loss: -97093866433030238765056.0000 | Generator Loss: 605823721424289792.0000 | Time: 22.13s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "Running Fold 3 of Run 2\n",
      "Processed training data shape: (24000, 91)\n",
      "Processed testing data shape: (6000, 91)\n",
      "Data dimension: 91\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -317.9693 | Generator Loss: -13.4417 | Time: 22.54s\n",
      "Epoch [11/300] | Critic Loss: -11113225965306.5527 | Generator Loss: 56932042.0851 | Time: 23.31s\n",
      "Epoch [21/300] | Critic Loss: -1928455913717411.5000 | Generator Loss: 1495290399.3191 | Time: 21.37s\n",
      "Epoch [31/300] | Critic Loss: -40980349261625648.0000 | Generator Loss: 36196287564.2553 | Time: 21.57s\n",
      "Epoch [41/300] | Critic Loss: -1201278958826779.2500 | Generator Loss: 19315439289.1915 | Time: 23.21s\n",
      "Epoch [51/300] | Critic Loss: -148721867466624064.0000 | Generator Loss: 346413367906.0425 | Time: 21.86s\n",
      "Epoch [61/300] | Critic Loss: -388389372444038976.0000 | Generator Loss: 1005015616228.7660 | Time: 20.96s\n",
      "Epoch [71/300] | Critic Loss: -519998278823787520.0000 | Generator Loss: 3016814816495.6597 | Time: 24.04s\n",
      "Epoch [81/300] | Critic Loss: -1750899126316168448.0000 | Generator Loss: 16048587641616.3398 | Time: 22.69s\n",
      "Epoch [91/300] | Critic Loss: -4388937653811418624.0000 | Generator Loss: 52952094596945.7031 | Time: 20.98s\n",
      "Epoch [101/300] | Critic Loss: -13869888209172869120.0000 | Generator Loss: 171296023023005.9688 | Time: 22.49s\n",
      "Epoch [111/300] | Critic Loss: -28921725521197023232.0000 | Generator Loss: 401459869618960.3125 | Time: 23.22s\n",
      "Epoch [121/300] | Critic Loss: -50521171010817015808.0000 | Generator Loss: 938227927914626.7500 | Time: 21.26s\n",
      "Epoch [131/300] | Critic Loss: -95282273095448330240.0000 | Generator Loss: 1940005408110548.5000 | Time: 22.52s\n",
      "Epoch [141/300] | Critic Loss: -179479425107767885824.0000 | Generator Loss: 3119431595109964.5000 | Time: 23.77s\n",
      "Epoch [151/300] | Critic Loss: -325742273431906287616.0000 | Generator Loss: 5721061787373655.0000 | Time: 22.04s\n",
      "Epoch [161/300] | Critic Loss: -631603172744443068416.0000 | Generator Loss: 9952286875465336.0000 | Time: 22.36s\n",
      "Epoch [171/300] | Critic Loss: -1070697179639240458240.0000 | Generator Loss: 15657784305338062.0000 | Time: 23.30s\n",
      "Epoch [181/300] | Critic Loss: -1993187796170269261824.0000 | Generator Loss: 25147363830764304.0000 | Time: 21.58s\n",
      "Epoch [191/300] | Critic Loss: -8065385402019678781440.0000 | Generator Loss: 130909942305410112.0000 | Time: 21.70s\n",
      "Epoch [201/300] | Critic Loss: -20352361658366767923200.0000 | Generator Loss: 2690737309070940160.0000 | Time: 23.30s\n",
      "Epoch [211/300] | Critic Loss: 2399100214519366942720.0000 | Generator Loss: 412971245288509888.0000 | Time: 21.34s\n",
      "Epoch [221/300] | Critic Loss: -14861962050982767493120.0000 | Generator Loss: 617287695613742848.0000 | Time: 20.86s\n",
      "Epoch [231/300] | Critic Loss: -39356630920081585471488.0000 | Generator Loss: 576321463498398848.0000 | Time: 24.24s\n",
      "Epoch [241/300] | Critic Loss: -71441526714076044984320.0000 | Generator Loss: 629068219219109120.0000 | Time: 22.13s\n",
      "Epoch [251/300] | Critic Loss: -104767021335899495464960.0000 | Generator Loss: 906333702869305088.0000 | Time: 20.63s\n",
      "Epoch [261/300] | Critic Loss: -135485654649126241959936.0000 | Generator Loss: 1483400457878324992.0000 | Time: 22.24s\n",
      "Epoch [271/300] | Critic Loss: -157458073503784000028672.0000 | Generator Loss: 1856417646712477440.0000 | Time: 23.13s\n",
      "Epoch [281/300] | Critic Loss: -198239693316757202665472.0000 | Generator Loss: 3069261708937278976.0000 | Time: 21.04s\n",
      "Epoch [291/300] | Critic Loss: -227768344572847762440192.0000 | Generator Loss: 4384652529483873792.0000 | Time: 22.52s\n",
      "Epoch [300/300] | Critic Loss: -229848391086650335166464.0000 | Generator Loss: 5691959027761252352.0000 | Time: 27.39s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "Running Fold 4 of Run 2\n",
      "Processed training data shape: (24000, 91)\n",
      "Processed testing data shape: (6000, 91)\n",
      "Data dimension: 91\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -21822017.3306 | Generator Loss: 11.4229 | Time: 29.53s\n",
      "Epoch [11/300] | Critic Loss: -610149178869.1063 | Generator Loss: 5114622.6835 | Time: 29.86s\n",
      "Epoch [21/300] | Critic Loss: -24850321135398.1289 | Generator Loss: 789389582.6383 | Time: 28.15s\n",
      "Epoch [31/300] | Critic Loss: -66201357614406.8047 | Generator Loss: 6882987544.5106 | Time: 29.43s\n",
      "Epoch [41/300] | Critic Loss: -476109878301456.3125 | Generator Loss: 42698882156.9362 | Time: 28.14s\n",
      "Epoch [51/300] | Critic Loss: -2070200731822646.5000 | Generator Loss: 143917649920.0000 | Time: 28.35s\n",
      "Epoch [61/300] | Critic Loss: -5553752622849177.0000 | Generator Loss: 635447662897.0212 | Time: 27.74s\n",
      "Epoch [71/300] | Critic Loss: -16478160899706270.0000 | Generator Loss: 2009444453092.7659 | Time: 22.86s\n",
      "Epoch [81/300] | Critic Loss: -29898490407930248.0000 | Generator Loss: 3891902006293.7871 | Time: 22.14s\n",
      "Epoch [91/300] | Critic Loss: -64678534458281376.0000 | Generator Loss: 5809829744029.9570 | Time: 22.77s\n",
      "Epoch [101/300] | Critic Loss: -84596366339188960.0000 | Generator Loss: 16800067661388.2559 | Time: 22.86s\n",
      "Epoch [111/300] | Critic Loss: -151735202083096960.0000 | Generator Loss: 17774731792471.1484 | Time: 23.04s\n",
      "Epoch [121/300] | Critic Loss: -325964751837175296.0000 | Generator Loss: 52531406552739.4062 | Time: 22.33s\n",
      "Epoch [131/300] | Critic Loss: -1062063045428407552.0000 | Generator Loss: 84526176146889.5312 | Time: 22.31s\n",
      "Epoch [141/300] | Critic Loss: -793645014933168000.0000 | Generator Loss: 97141278381513.5312 | Time: 20.98s\n",
      "Epoch [151/300] | Critic Loss: -2270834436167517952.0000 | Generator Loss: 220764117061370.5625 | Time: 20.21s\n",
      "Epoch [161/300] | Critic Loss: -2515686259642803712.0000 | Generator Loss: 323159227172210.3750 | Time: 22.83s\n",
      "Epoch [171/300] | Critic Loss: -4497967472632671232.0000 | Generator Loss: 520243194916079.6875 | Time: 19.90s\n",
      "Epoch [181/300] | Critic Loss: -8158736333065220096.0000 | Generator Loss: 812745459465542.7500 | Time: 20.90s\n",
      "Epoch [191/300] | Critic Loss: -12558147127554510848.0000 | Generator Loss: 1218180961617615.0000 | Time: 20.58s\n",
      "Epoch [201/300] | Critic Loss: -20959237673250930688.0000 | Generator Loss: 1960043650493331.0000 | Time: 21.91s\n",
      "Epoch [211/300] | Critic Loss: -23030306549783040000.0000 | Generator Loss: 2611019361299347.0000 | Time: 21.46s\n",
      "Epoch [221/300] | Critic Loss: -42273747485008773120.0000 | Generator Loss: 3923027667295733.0000 | Time: 24.80s\n",
      "Epoch [231/300] | Critic Loss: -53824880242653052928.0000 | Generator Loss: 5669947185968760.0000 | Time: 31.54s\n",
      "Epoch [241/300] | Critic Loss: -81184332945444388864.0000 | Generator Loss: 8381486932800447.0000 | Time: 29.82s\n",
      "Epoch [251/300] | Critic Loss: -106864473185769766912.0000 | Generator Loss: 10373373522228856.0000 | Time: 21.82s\n",
      "Epoch [261/300] | Critic Loss: -109213305695997640704.0000 | Generator Loss: 13181832984181042.0000 | Time: 24.94s\n",
      "Epoch [271/300] | Critic Loss: -178197329608413446144.0000 | Generator Loss: 23227842499918828.0000 | Time: 22.91s\n",
      "Epoch [281/300] | Critic Loss: -313828555333010784256.0000 | Generator Loss: 37426176976748544.0000 | Time: 22.05s\n",
      "Epoch [291/300] | Critic Loss: -308563935329544896512.0000 | Generator Loss: 46069695809189144.0000 | Time: 20.20s\n",
      "Epoch [300/300] | Critic Loss: -274390771826393513984.0000 | Generator Loss: 53732070633382064.0000 | Time: 20.66s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "Running Fold 5 of Run 2\n",
      "Processed training data shape: (24000, 91)\n",
      "Processed testing data shape: (6000, 91)\n",
      "Data dimension: 91\n",
      "Latent dimension: 100\n",
      "Training CramerGAN for 300 epochs...\n",
      "Epoch [1/300] | Critic Loss: -25366969.9479 | Generator Loss: 31.5127 | Time: 22.51s\n",
      "Epoch [11/300] | Critic Loss: -1153357115304.8511 | Generator Loss: 6344970.9395 | Time: 22.35s\n",
      "Epoch [21/300] | Critic Loss: -34540586761542.8086 | Generator Loss: 169160397.1489 | Time: 21.41s\n",
      "Epoch [31/300] | Critic Loss: -402125987473277.2500 | Generator Loss: 4789502485.7872 | Time: 26.19s\n",
      "Epoch [41/300] | Critic Loss: -2217602775760547.5000 | Generator Loss: 121049814952.8511 | Time: 22.07s\n",
      "Epoch [51/300] | Critic Loss: -54855750384816216.0000 | Generator Loss: 851906903192.5106 | Time: 27.83s\n",
      "Epoch [61/300] | Critic Loss: -408531301828344832.0000 | Generator Loss: 5368750406285.6172 | Time: 23.29s\n",
      "Epoch [71/300] | Critic Loss: -227313765715731648.0000 | Generator Loss: 54612451633369.8750 | Time: 23.24s\n",
      "Epoch [81/300] | Critic Loss: -359142831022485760.0000 | Generator Loss: 120239054344627.7500 | Time: 30.74s\n",
      "Epoch [91/300] | Critic Loss: -1343224664249380352.0000 | Generator Loss: 39146576658083.4062 | Time: 25.31s\n",
      "Epoch [101/300] | Critic Loss: -6471970743303386112.0000 | Generator Loss: 98301385297658.5469 | Time: 21.39s\n",
      "Epoch [111/300] | Critic Loss: -13675177192217339904.0000 | Generator Loss: 263333396365660.5938 | Time: 26.38s\n",
      "Epoch [121/300] | Critic Loss: -28483973026661343232.0000 | Generator Loss: 665718539084996.1250 | Time: 26.73s\n",
      "Epoch [131/300] | Critic Loss: -54594307718593069056.0000 | Generator Loss: 1801570762922114.7500 | Time: 24.61s\n",
      "Epoch [141/300] | Critic Loss: -122334409584588013568.0000 | Generator Loss: 3800091263455667.5000 | Time: 21.42s\n",
      "Epoch [151/300] | Critic Loss: -232653257285156569088.0000 | Generator Loss: 6060942617912167.0000 | Time: 21.29s\n",
      "Epoch [161/300] | Critic Loss: -432546299304974680064.0000 | Generator Loss: 11448905562274794.0000 | Time: 22.05s\n",
      "Epoch [171/300] | Critic Loss: -806685748919814455296.0000 | Generator Loss: 19873808403298260.0000 | Time: 21.49s\n",
      "Epoch [181/300] | Critic Loss: -1088317442812583346176.0000 | Generator Loss: 32485094025286068.0000 | Time: 21.50s\n",
      "Epoch [191/300] | Critic Loss: -1551765009798674513920.0000 | Generator Loss: 51516071416787552.0000 | Time: 21.36s\n",
      "Epoch [201/300] | Critic Loss: -2068076005881304842240.0000 | Generator Loss: 77757558998774016.0000 | Time: 23.75s\n",
      "Epoch [211/300] | Critic Loss: -2457752778389304377344.0000 | Generator Loss: 126976196608624688.0000 | Time: 26.22s\n",
      "Epoch [221/300] | Critic Loss: -3361514783601593942016.0000 | Generator Loss: 210824405460345344.0000 | Time: 23.45s\n",
      "Epoch [231/300] | Critic Loss: -3506048860342259286016.0000 | Generator Loss: 344517446365358976.0000 | Time: 25.66s\n",
      "Epoch [241/300] | Critic Loss: -4883954397812035158016.0000 | Generator Loss: 576317074864262912.0000 | Time: 23.06s\n",
      "Epoch [251/300] | Critic Loss: -1126511114782477910016.0000 | Generator Loss: 818933503473288576.0000 | Time: 25.01s\n",
      "Epoch [261/300] | Critic Loss: -1819352553147477786624.0000 | Generator Loss: 1151754163200241280.0000 | Time: 21.44s\n",
      "Epoch [271/300] | Critic Loss: -2258771044545147961344.0000 | Generator Loss: 1568325777590360320.0000 | Time: 21.97s\n",
      "Epoch [281/300] | Critic Loss: -2813939304827341242368.0000 | Generator Loss: 1879882998396563712.0000 | Time: 22.86s\n",
      "Epoch [291/300] | Critic Loss: -2726910967080225865728.0000 | Generator Loss: 2371248288874136064.0000 | Time: 21.57s\n",
      "Epoch [300/300] | Critic Loss: -2610425644193264697344.0000 | Generator Loss: 2476281189197983232.0000 | Time: 44.62s\n",
      "Generating 1000 synthetic samples...\n",
      "Evaluating statistical similarity...\n",
      "Evaluating Machine Learning Utility (TSTR)...\n",
      "\n",
      "===== Final Average Results (10 runs) =====\n",
      "\n",
      "Average Statistical Similarity Metrics:\n",
      "Average Jensen-Shannon Divergence: 0.131549\n",
      "Average Wasserstein Distance: 0.268122\n",
      "\n",
      "Average TSTR Results:\n",
      "Logistic Regression:\n",
      "  Accuracy: 0.577042\n",
      "  F1 Score: 0.585694\n",
      "  AUC-ROC: 0.482025\n",
      "MLP:\n",
      "  Accuracy: 0.704396\n",
      "  F1 Score: 0.650112\n",
      "  AUC-ROC: 0.498570\n",
      "Random Forest:\n",
      "  Accuracy: 0.767979\n",
      "  F1 Score: 0.680481\n",
      "  AUC-ROC: 0.449804\n",
      "XGBoost:\n",
      "  Accuracy: 0.648333\n",
      "  F1 Score: 0.599704\n",
      "  AUC-ROC: 0.485392\n",
      "\n",
      "Cross-validation complete!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
