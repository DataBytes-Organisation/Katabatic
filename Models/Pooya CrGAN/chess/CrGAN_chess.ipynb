{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1726c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "✅ Preprocessed data saved to: preprocessed_chess.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"chess-official.csv\")\n",
    "\n",
    "# Encode the target column\n",
    "le = LabelEncoder()\n",
    "df['class'] = le.fit_transform(df['class'])\n",
    "\n",
    "# Separate features and target\n",
    "NUMERIC_COLS = df.columns[df.columns != 'class'].tolist()\n",
    "TARGET_COL = 'class'\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "df[NUMERIC_COLS] = scaler.fit_transform(df[NUMERIC_COLS])\n",
    "\n",
    "# Save preprocessed dataset\n",
    "out_path = \"preprocessed_chess.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"✅ Preprocessed data saved to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01975c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "— Rep 1/3 Fold 1/2 —\n",
      "Epoch 1/100 - D_loss=1.3021  G_loss=0.7138\n",
      "Epoch 20/100 - D_loss=0.6076  G_loss=1.1980\n",
      "Epoch 40/100 - D_loss=0.0911  G_loss=3.4959\n",
      "Epoch 60/100 - D_loss=0.0298  G_loss=4.7595\n",
      "Epoch 80/100 - D_loss=0.0009  G_loss=7.4344\n",
      "Epoch 100/100 - D_loss=0.2912  G_loss=11.2808\n",
      "\n",
      "— Rep 1/3 Fold 2/2 —\n",
      "Epoch 1/100 - D_loss=1.3279  G_loss=0.7011\n",
      "Epoch 20/100 - D_loss=0.8696  G_loss=1.0404\n",
      "Epoch 40/100 - D_loss=0.1176  G_loss=3.3301\n",
      "Epoch 60/100 - D_loss=0.0476  G_loss=5.2470\n",
      "Epoch 80/100 - D_loss=0.1814  G_loss=5.9640\n",
      "Epoch 100/100 - D_loss=0.1248  G_loss=12.7826\n",
      "\n",
      "— Rep 2/3 Fold 1/2 —\n",
      "Epoch 1/100 - D_loss=1.3345  G_loss=0.7323\n",
      "Epoch 20/100 - D_loss=0.4959  G_loss=1.3732\n",
      "Epoch 40/100 - D_loss=0.2457  G_loss=2.6262\n",
      "Epoch 60/100 - D_loss=0.0283  G_loss=4.3815\n",
      "Epoch 80/100 - D_loss=0.6308  G_loss=6.3929\n",
      "Epoch 100/100 - D_loss=0.0359  G_loss=5.2464\n",
      "\n",
      "— Rep 2/3 Fold 2/2 —\n",
      "Epoch 1/100 - D_loss=1.3213  G_loss=0.7076\n",
      "Epoch 20/100 - D_loss=0.8108  G_loss=1.1800\n",
      "Epoch 40/100 - D_loss=0.1376  G_loss=2.9832\n",
      "Epoch 60/100 - D_loss=0.1009  G_loss=4.9225\n",
      "Epoch 80/100 - D_loss=0.0361  G_loss=7.2459\n",
      "Epoch 100/100 - D_loss=0.0019  G_loss=6.8983\n",
      "\n",
      "— Rep 3/3 Fold 1/2 —\n",
      "Epoch 1/100 - D_loss=1.3156  G_loss=0.7171\n",
      "Epoch 20/100 - D_loss=0.9916  G_loss=1.0036\n",
      "Epoch 40/100 - D_loss=0.1583  G_loss=2.7494\n",
      "Epoch 60/100 - D_loss=0.1447  G_loss=3.7060\n",
      "Epoch 80/100 - D_loss=0.0762  G_loss=5.3802\n",
      "Epoch 100/100 - D_loss=0.0010  G_loss=7.3828\n",
      "\n",
      "— Rep 3/3 Fold 2/2 —\n",
      "Epoch 1/100 - D_loss=1.3322  G_loss=0.6690\n",
      "Epoch 20/100 - D_loss=0.6454  G_loss=1.2257\n",
      "Epoch 40/100 - D_loss=0.1782  G_loss=2.4675\n",
      "Epoch 60/100 - D_loss=0.1793  G_loss=4.6167\n",
      "Epoch 80/100 - D_loss=0.2939  G_loss=7.4827\n",
      "Epoch 100/100 - D_loss=0.0647  G_loss=8.0462\n",
      "\n",
      "=== CV Results (mean ± std) ===\n",
      " • LR TSTR = 56.51% ± 21.62%\n",
      " • MLP TSTR = 65.22% ± 10.65%\n",
      " • RF TSTR = 50.53% ± 24.46%\n",
      " • XGB TSTR = 55.56% ± 17.95%\n",
      " • JSD = 0.5311 ± 0.0483\n",
      " • WD  = 1.0992 ± 0.0230\n"
     ]
    }
   ],
   "source": [
    "# --- GAN Training & Evaluation ---\n",
    "\n",
    "# Hyperparameters\n",
    "PREPROCESSED_PATH = \"preprocessed_chess.csv\"\n",
    "LATENT_DIM        = 100\n",
    "BATCH_SIZE        = 64\n",
    "EPOCHS            = 100\n",
    "REPEATS           = 3\n",
    "FOLDS             = 2\n",
    "SYN_RATIO         = 0.5\n",
    "TARGET_COL        = \"class\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(PREPROCESSED_PATH)\n",
    "X_full = df.drop(columns=[TARGET_COL]).values.astype(np.float32)\n",
    "y_full = df[TARGET_COL].values.astype(int)\n",
    "NUMERIC_COLS = df.columns[df.columns != TARGET_COL].tolist()\n",
    "num_idx = [df.columns.get_loc(c) for c in NUMERIC_COLS]\n",
    "\n",
    "# Define models\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.ReLU(),\n",
    "            nn.Linear(256, out_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512), nn.ReLU(),\n",
    "            nn.Linear(512, 256), nn.ReLU(),\n",
    "            nn.Linear(256, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def train_cramer_gan(G, D, loader, epochs):\n",
    "    G, D = G.to(device), D.to(device)\n",
    "    optg = optim.Adam(G.parameters(), lr=2e-4)\n",
    "    optd = optim.Adam(D.parameters(), lr=2e-4)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    for ep in range(1, epochs + 1):\n",
    "        for real_batch, _ in loader:\n",
    "            real_batch = real_batch.to(device)\n",
    "            bsz = real_batch.size(0)\n",
    "\n",
    "            # Discriminator step\n",
    "            optd.zero_grad()\n",
    "            z = torch.randn(bsz, LATENT_DIM, device=device)\n",
    "            fake = G(z).detach()\n",
    "            d_real = D(real_batch)\n",
    "            d_fake = D(fake)\n",
    "            lossd = loss_fn(d_real, torch.ones_like(d_real)) + \\\n",
    "                    loss_fn(d_fake, torch.zeros_like(d_fake))\n",
    "            lossd.backward()\n",
    "            optd.step()\n",
    "\n",
    "            # Generator step\n",
    "            optg.zero_grad()\n",
    "            z = torch.randn(bsz, LATENT_DIM, device=device)\n",
    "            fake2 = G(z)\n",
    "            dg = D(fake2)\n",
    "            lossg = loss_fn(dg, torch.ones_like(dg))\n",
    "            lossg.backward()\n",
    "            optg.step()\n",
    "\n",
    "        if ep % 20 == 0 or ep == 1 or ep == epochs:\n",
    "            print(f\"Epoch {ep}/{epochs} - D_loss={lossd.item():.4f}  G_loss={lossg.item():.4f}\")\n",
    "    return G, D\n",
    "\n",
    "def generate_synthetic(G, n_samples):\n",
    "    G = G.to(device).eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(n_samples, LATENT_DIM, device=device)\n",
    "        return G(z).cpu().numpy()\n",
    "\n",
    "def compute_tstr_all(X_real, y_real, X_syn, y_syn):\n",
    "    results = {}\n",
    "    for name, clf in [\n",
    "        (\"LR\", LogisticRegression(max_iter=5000)),\n",
    "        (\"MLP\", MLPClassifier(hidden_layer_sizes=(128,64), max_iter=1000)),\n",
    "        (\"RF\", RandomForestClassifier(n_estimators=200)),\n",
    "        (\"XGB\", XGBClassifier(eval_metric=\"logloss\"))\n",
    "    ]:\n",
    "        clf.fit(X_syn, y_syn)\n",
    "        results[name] = clf.score(X_real, y_real) * 100.0\n",
    "    return results\n",
    "\n",
    "def compute_jsd_wd(X_real, X_syn, num_idx):\n",
    "    jsd_list, wd_list = [], []\n",
    "    for i in num_idx:\n",
    "        p_real, _ = np.histogram(X_real[:, i], bins=50, density=True)\n",
    "        p_syn, _ = np.histogram(X_syn[:, i], bins=50, density=True)\n",
    "        jsd_list.append(jensenshannon(p_real, p_syn))\n",
    "        wd_list.append(wasserstein_distance(X_real[:, i], X_syn[:, i]))\n",
    "    return np.mean(jsd_list), np.mean(wd_list)\n",
    "\n",
    "# Cross-validation Training\n",
    "tstr_scores = {m: [] for m in [\"LR\", \"MLP\", \"RF\", \"XGB\"]}\n",
    "jsd_scores, wd_scores = [], []\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "for rep in range(REPEATS):\n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_full), 1):\n",
    "        print(f\"\\n— Rep {rep + 1}/{REPEATS} Fold {fold}/{FOLDS} —\")\n",
    "        X_tr, X_te = X_full[train_idx], X_full[test_idx]\n",
    "        y_tr, y_te = y_full[train_idx], y_full[test_idx]\n",
    "\n",
    "        loader = DataLoader(\n",
    "            TensorDataset(torch.from_numpy(X_tr), torch.from_numpy(y_tr)),\n",
    "            batch_size=BATCH_SIZE, shuffle=True\n",
    "        )\n",
    "\n",
    "        G = Generator(LATENT_DIM, X_tr.shape[1])\n",
    "        D = Discriminator(X_tr.shape[1])\n",
    "        G, D = train_cramer_gan(G, D, loader, EPOCHS)\n",
    "\n",
    "        X_syn = generate_synthetic(G, int(SYN_RATIO * len(X_tr)))\n",
    "        y_syn = np.random.choice(y_tr, size=X_syn.shape[0], replace=True)\n",
    "\n",
    "        tstr = compute_tstr_all(X_te, y_te, X_syn, y_syn)\n",
    "        for m, score in tstr.items():\n",
    "            tstr_scores[m].append(score)\n",
    "\n",
    "        js, wd = compute_jsd_wd(X_te, X_syn, num_idx)\n",
    "        jsd_scores.append(js)\n",
    "        wd_scores.append(wd)\n",
    "\n",
    "# Report Results\n",
    "print(\"\\n=== CV Results (mean ± std) ===\")\n",
    "for m in tstr_scores:\n",
    "    scores = np.array(tstr_scores[m])\n",
    "    print(f\" • {m} TSTR = {scores.mean():.2f}% ± {scores.std():.2f}%\")\n",
    "print(f\" • JSD = {np.mean(jsd_scores):.4f} ± {np.std(jsd_scores):.4f}\")\n",
    "print(f\" • WD  = {np.mean(wd_scores):.4f} ± {np.std(wd_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dcec758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - D_loss=1.2406  G_loss=0.6604\n",
      "Epoch 20/100 - D_loss=0.9899  G_loss=1.8146\n",
      "Epoch 40/100 - D_loss=0.4565  G_loss=5.3574\n",
      "Epoch 60/100 - D_loss=0.0303  G_loss=6.0340\n",
      "Epoch 80/100 - D_loss=0.3548  G_loss=10.2845\n",
      "Epoch 100/100 - D_loss=0.0724  G_loss=6.3636\n",
      "\n",
      "✅ Final synthetic dataset saved to: synthetic_chess_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Final model on all data\n",
    "full_loader = DataLoader(\n",
    "    TensorDataset(torch.from_numpy(X_full), torch.from_numpy(y_full)),\n",
    "    batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "Gf = Generator(LATENT_DIM, X_full.shape[1])\n",
    "Df = Discriminator(X_full.shape[1])\n",
    "Gf, Df = train_cramer_gan(Gf, Df, full_loader, EPOCHS)\n",
    "\n",
    "# Generate final synthetic data\n",
    "n_final = int(SYN_RATIO * len(X_full))\n",
    "Xf_syn = generate_synthetic(Gf, n_final)\n",
    "yf_syn = np.random.choice(y_full, size=n_final, replace=True)\n",
    "\n",
    "# Save to CSV\n",
    "syn_df = pd.DataFrame(Xf_syn, columns=NUMERIC_COLS)\n",
    "syn_df[TARGET_COL] = yf_syn\n",
    "out_path = \"synthetic_chess_final.csv\"\n",
    "syn_df.to_csv(out_path, index=False)\n",
    "print(f\"\\n✅ Final synthetic dataset saved to: {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
