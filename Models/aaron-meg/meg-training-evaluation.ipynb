{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "-----------"
      ],
      "metadata": {
        "id": "AQDCp8v6M00p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Library Imports"
      ],
      "metadata": {
        "id": "GuGRxNWiM5PZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import entropy, wasserstein_distance\n",
        "from xgboost import XGBClassifier\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "metadata": {
        "id": "6weUZZmPM0Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class and Function Definitions"
      ],
      "metadata": {
        "id": "RfkigwHtNExu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FusionNetwork(nn.Module):\n",
        "    def __init__(self, num_generators, feature_dim):\n",
        "        super(FusionNetwork, self).__init__()\n",
        "        self.weights = nn.Parameter(torch.ones(num_generators, feature_dim) / num_generators)\n",
        "\n",
        "    def forward(self, outputs):\n",
        "        stacked = torch.stack(outputs, dim=0)\n",
        "        gamma = torch.softmax(self.weights, dim=0)\n",
        "        fused = torch.einsum('gd,gbd->bd', gamma, stacked)\n",
        "        return fused, gamma\n",
        "\n",
        "# Masked Generator\n",
        "class MaskedGenerator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(MaskedGenerator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        return self.net(x * mask)\n",
        "\n",
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, feature_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(feature_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# MEG Model\n",
        "class MEG(nn.Module):\n",
        "    def __init__(self, input_dim, num_generators=None, alpha=0.1, beta=1.0):\n",
        "        super(MEG, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.num_generators = input_dim if num_generators is None else num_generators\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.generators = nn.ModuleList([MaskedGenerator(input_dim) for _ in range(self.num_generators)])\n",
        "        self.fusion = FusionNetwork(self.num_generators, input_dim)\n",
        "        self.discriminator = Discriminator(input_dim)\n",
        "        self.opt_gen = optim.Adam(list(self.generators.parameters()) + list(self.fusion.parameters()), lr=0.001)\n",
        "        self.opt_disc = optim.Adam(self.discriminator.parameters(), lr=0.001)\n",
        "        self.bce = nn.BCELoss()\n",
        "        self.mse = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        masks = [(torch.rand_like(x) < 0.8).float() for _ in range(self.num_generators)]\n",
        "        outputs = [g(x, m) for g, m in zip(self.generators, masks)]\n",
        "        fused, gamma = self.fusion(outputs)\n",
        "        return outputs, fused, gamma\n",
        "\n",
        "    def train_meg(self, data, epochs=50, batch_size=64):\n",
        "        for epoch in range(epochs):\n",
        "            perm = torch.randperm(data.size(0))\n",
        "            for i in range(0, data.size(0), batch_size):\n",
        "                idx = perm[i:i + batch_size]\n",
        "                real_batch = data[idx]\n",
        "                bs = real_batch.size(0)\n",
        "                real_labels = torch.ones(bs, 1).to(real_batch.device)\n",
        "                fake_labels = torch.zeros(bs, 1).to(real_batch.device)\n",
        "\n",
        "                self.opt_disc.zero_grad()\n",
        "                loss_real = self.bce(self.discriminator(real_batch), real_labels)\n",
        "                _, fused, _ = self.forward(real_batch)\n",
        "                loss_fake = self.bce(self.discriminator(fused.detach()), fake_labels)\n",
        "                loss_D = loss_real + loss_fake\n",
        "                loss_D.backward()\n",
        "                self.opt_disc.step()\n",
        "\n",
        "                self.opt_gen.zero_grad()\n",
        "                outputs, fused, gamma = self.forward(real_batch)\n",
        "                loss_proxy = self.mse(fused, real_batch)\n",
        "                loss_group = sum(torch.mean(w * (out - real_batch).pow(2)) for out, w in zip(outputs, gamma))\n",
        "                loss_adv = self.bce(self.discriminator(fused), real_labels)\n",
        "                loss_G = loss_proxy + self.alpha * loss_group + self.beta * loss_adv\n",
        "                loss_G.backward()\n",
        "                self.opt_gen.step()\n",
        "\n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch}: Loss_D={loss_D.item():.4f}, Loss_proxy={loss_proxy.item():.4f}, \"\n",
        "                      f\"Loss_group={loss_group.item():.4f}, Loss_adv={loss_adv.item():.4f}\")\n",
        "\n",
        "    def generate(self, x):\n",
        "        _, fused, _ = self.forward(x)\n",
        "        return fused\n",
        "\n",
        "# Evaluation Functions\n",
        "def jensen_shannon_divergence(real, synthetic):\n",
        "    real_hist, _ = np.histogram(real, bins=50, density=True)\n",
        "    syn_hist, _ = np.histogram(synthetic, bins=50, density=True)\n",
        "    real_hist = real_hist + 1e-10\n",
        "    syn_hist = syn_hist + 1e-10\n",
        "    m = 0.5 * (real_hist + syn_hist)\n",
        "    return 0.5 * (entropy(real_hist, m) + entropy(syn_hist, m))\n",
        "\n",
        "def evaluate_dataset(dataset_name, X, y, le, results_file='results.csv'):\n",
        "    dataset_size = len(X)\n",
        "    epochs = 50 if dataset_size >= 30000 else 100\n",
        "    print(f\"\\nEvaluating {dataset_name} ({dataset_size} samples, {epochs} epochs):\")\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "\n",
        "    # Use StratifiedKFold to ensure class distribution is preserved\n",
        "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "    all_classes = np.unique(y)\n",
        "    num_classes = len(all_classes)\n",
        "\n",
        "    print(f\"Number of classes: {num_classes}, Labels: {all_classes}\")\n",
        "\n",
        "    classifiers = {\n",
        "        \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        \"MLP\": MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n",
        "    }\n",
        "\n",
        "    # Add XGBoost wrapped in OneVsRestClassifier for more stable multiclass handling\n",
        "    if num_classes > 2:\n",
        "        classifiers[\"XGBoost\"] = OneVsRestClassifier(XGBClassifier(eval_metric='logloss'))\n",
        "    else:\n",
        "        classifiers[\"XGBoost\"] = XGBClassifier(objective='binary:logistic', eval_metric='logloss')\n",
        "\n",
        "    tstr_scores = {name: [] for name in classifiers.keys()}\n",
        "    jsd_scores = []\n",
        "    wd_scores = []\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_scaled, y)):\n",
        "        X_train, X_test = X_tensor[train_idx].to(device), X_tensor[test_idx].to(device)\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        # Ensure all classes are present in training data\n",
        "        train_classes = np.unique(y_train)\n",
        "        print(f\"Fold {fold} - Classes in training data: {train_classes}\")\n",
        "\n",
        "        # Check for missing classes in training\n",
        "        missing_classes = set(all_classes) - set(train_classes)\n",
        "        if missing_classes:\n",
        "            print(f\"Warning: Missing classes in training fold {fold}: {missing_classes}\")\n",
        "            # Add at least one sample from each missing class\n",
        "            for cls in missing_classes:\n",
        "                cls_indices = np.where(y == cls)[0]\n",
        "                if len(cls_indices) > 0:\n",
        "                    # Add sample to training\n",
        "                    idx = cls_indices[0]\n",
        "                    train_idx = np.append(train_idx, idx)\n",
        "                    # Remove from test if present\n",
        "                    if idx in test_idx:\n",
        "                        test_idx = test_idx[test_idx != idx]\n",
        "\n",
        "            # Update splits\n",
        "            X_train = X_tensor[train_idx].to(device)\n",
        "            X_test = X_tensor[test_idx].to(device)\n",
        "            y_train = y[train_idx]\n",
        "            y_test = y[test_idx]\n",
        "\n",
        "            print(f\"After adjustment - Classes in training: {np.unique(y_train)}\")\n",
        "\n",
        "        meg = MEG(input_dim=X_train.shape[1], num_generators=X.shape[1] - 1, alpha=0.1, beta=1.0)\n",
        "        meg.to(device)\n",
        "        meg.train_meg(X_train, epochs=epochs, batch_size=64)\n",
        "\n",
        "        # Generate synthetic data with stratification\n",
        "        synthetic_data = []\n",
        "        synthetic_labels = []\n",
        "\n",
        "        # Process each class to ensure representation\n",
        "        for cls in all_classes:\n",
        "            cls_indices = np.where(y_train == cls)[0]\n",
        "            if len(cls_indices) > 0:\n",
        "                # Select up to half the samples for this class, minimum 1\n",
        "                cls_sample_size = max(1, int(len(cls_indices) * 0.5))\n",
        "                cls_sample_indices = cls_indices[:cls_sample_size]\n",
        "\n",
        "                # Generate data for this class\n",
        "                cls_synthetic = meg.generate(X_train[cls_sample_indices]).detach().cpu().numpy()\n",
        "                cls_labels = np.full(cls_sample_size, cls)\n",
        "\n",
        "                synthetic_data.append(cls_synthetic)\n",
        "                synthetic_labels.append(cls_labels)\n",
        "\n",
        "        # Combine all synthetic data\n",
        "        X_syn = np.vstack(synthetic_data)\n",
        "        y_syn = np.concatenate(synthetic_labels)\n",
        "\n",
        "        print(f\"Fold {fold} - Classes in synthetic data: {np.unique(y_syn)}\")\n",
        "\n",
        "        for clf_name, clf in classifiers.items():\n",
        "            try:\n",
        "                clf.fit(X_syn, y_syn)\n",
        "                y_pred = clf.predict(X_test.cpu().numpy())\n",
        "                score = accuracy_score(y_test, y_pred)\n",
        "                tstr_scores[clf_name].append(score)\n",
        "                print(f\"Fold {fold} - {clf_name} accuracy: {score:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {clf_name} on fold {fold}: {e}\")\n",
        "                # Try to recover with OneVsRestClassifier if needed\n",
        "                if clf_name == \"XGBoost\" and \"Invalid classes\" in str(e):\n",
        "                    try:\n",
        "                        print(\"Trying with OneVsRestClassifier...\")\n",
        "                        recovery_clf = OneVsRestClassifier(XGBClassifier(eval_metric='logloss'))\n",
        "                        recovery_clf.fit(X_syn, y_syn)\n",
        "                        y_pred = recovery_clf.predict(X_test.cpu().numpy())\n",
        "                        score = accuracy_score(y_test, y_pred)\n",
        "                        tstr_scores[clf_name].append(score)\n",
        "                        print(f\"Recovery successful! Accuracy: {score:.4f}\")\n",
        "                    except Exception as e2:\n",
        "                        print(f\"Recovery failed: {e2}\")\n",
        "                        tstr_scores[clf_name].append(0)\n",
        "                else:\n",
        "                    tstr_scores[clf_name].append(0)\n",
        "\n",
        "        real_flat = X_test.cpu().numpy().flatten()\n",
        "        syn_flat = X_syn.flatten()\n",
        "        jsd_scores.append(jensen_shannon_divergence(real_flat, syn_flat))\n",
        "        wd_scores.append(wasserstein_distance(real_flat, syn_flat))\n",
        "\n",
        "    result = {'Dataset': dataset_name}\n",
        "    for clf_name in classifiers.keys():\n",
        "        result[f'TSTR ({clf_name}) Mean'] = np.mean(tstr_scores[clf_name])\n",
        "        result[f'TSTR ({clf_name}) Std'] = np.std(tstr_scores[clf_name])\n",
        "    result['JSD Mean'] = np.mean(jsd_scores)\n",
        "    result['JSD Std'] = np.std(jsd_scores)\n",
        "    result['WD Mean'] = np.mean(wd_scores)\n",
        "    result['WD Std'] = np.std(wd_scores)\n",
        "\n",
        "    if os.path.exists(results_file):\n",
        "        df = pd.read_csv(results_file)\n",
        "        df = pd.concat([df, pd.DataFrame([result])], ignore_index=True)\n",
        "    else:\n",
        "        df = pd.DataFrame([result])\n",
        "\n",
        "    df.to_csv(results_file, index=False)\n",
        "    print(f\"\\nResults for {dataset_name}:\")\n",
        "    print(df)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "RDNK2F2jM9UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading Function"
      ],
      "metadata": {
        "id": "z1vMueOwNLyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_arff(file_path):\n",
        "    data, meta = arff.loadarff(file_path)\n",
        "    df = pd.DataFrame(data)\n",
        "    for col in df.columns:\n",
        "        if df[col].dtype == object:\n",
        "            if isinstance(df[col].iloc[0], bytes):\n",
        "                df[col] = df[col].str.decode('utf-8')\n",
        "            else:\n",
        "                df[col] = df[col]\n",
        "    class_col = meta.names()[-1]\n",
        "    df_features = pd.get_dummies(df.drop(columns=[class_col]), drop_first=True)\n",
        "    le = LabelEncoder()\n",
        "    df[class_col] = le.fit_transform(df[class_col])\n",
        "    df = pd.concat([df_features, df[class_col]], axis=1)\n",
        "    X = df.drop(columns=[class_col]).values\n",
        "    y = df[class_col].values\n",
        "    print(f\"Dataset: {file_path}, Unique labels: {np.unique(y)}\")\n",
        "    return X, y, le"
      ],
      "metadata": {
        "id": "09zwF_ZLNOXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate `car`"
      ],
      "metadata": {
        "id": "JyZ2x0KzNpA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, le = load_arff(\"car 1.arff\")\n",
        "evaluate_dataset(\"car\", X, y, le, results_file='results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZNRJ1g7NsBl",
        "outputId": "b4785b39-a48e-4bc6-ae40-91044e229114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: car 1.arff, Unique labels: [0 1 2 3]\n",
            "\n",
            "Evaluating car (1728 samples, 100 epochs):\n",
            "Number of classes: 4, Labels: [0 1 2 3]\n",
            "Fold 0 - Classes in training data: [0 1 2 3]\n",
            "Epoch 0: Loss_D=1.2544, Loss_proxy=0.7852, Loss_group=0.8310, Loss_adv=0.5729\n",
            "Epoch 10: Loss_D=1.4314, Loss_proxy=0.1066, Loss_group=0.4012, Loss_adv=0.6586\n",
            "Epoch 20: Loss_D=1.3972, Loss_proxy=0.0291, Loss_group=0.3339, Loss_adv=0.6924\n",
            "Epoch 30: Loss_D=1.3933, Loss_proxy=0.0233, Loss_group=0.3053, Loss_adv=0.7002\n",
            "Epoch 40: Loss_D=1.3901, Loss_proxy=0.0215, Loss_group=0.2824, Loss_adv=0.6960\n",
            "Epoch 50: Loss_D=1.3883, Loss_proxy=0.0196, Loss_group=0.2659, Loss_adv=0.6987\n",
            "Epoch 60: Loss_D=1.3871, Loss_proxy=0.0211, Loss_group=0.2679, Loss_adv=0.6946\n",
            "Epoch 70: Loss_D=1.3859, Loss_proxy=0.0189, Loss_group=0.2581, Loss_adv=0.6942\n",
            "Epoch 80: Loss_D=1.3857, Loss_proxy=0.0179, Loss_group=0.2601, Loss_adv=0.6960\n",
            "Epoch 90: Loss_D=1.3848, Loss_proxy=0.0201, Loss_group=0.2559, Loss_adv=0.6942\n",
            "Fold 0 - Classes in synthetic data: [0 1 2 3]\n",
            "Fold 0 - Logistic Regression accuracy: 0.7465\n",
            "Fold 0 - Random Forest accuracy: 0.7153\n",
            "Fold 0 - MLP accuracy: 0.7778\n",
            "Fold 0 - XGBoost accuracy: 0.8148\n",
            "Fold 1 - Classes in training data: [0 1 2 3]\n",
            "Epoch 0: Loss_D=1.3067, Loss_proxy=0.8416, Loss_group=0.8922, Loss_adv=0.6056\n",
            "Epoch 10: Loss_D=1.4293, Loss_proxy=0.0896, Loss_group=0.3914, Loss_adv=0.6990\n",
            "Epoch 20: Loss_D=1.4195, Loss_proxy=0.0477, Loss_group=0.3475, Loss_adv=0.6985\n",
            "Epoch 30: Loss_D=1.3931, Loss_proxy=0.0239, Loss_group=0.3167, Loss_adv=0.7057\n",
            "Epoch 40: Loss_D=1.3870, Loss_proxy=0.0177, Loss_group=0.2695, Loss_adv=0.6966\n",
            "Epoch 50: Loss_D=1.3876, Loss_proxy=0.0167, Loss_group=0.2792, Loss_adv=0.6988\n",
            "Epoch 60: Loss_D=1.3865, Loss_proxy=0.0184, Loss_group=0.2558, Loss_adv=0.6988\n",
            "Epoch 70: Loss_D=1.3857, Loss_proxy=0.0179, Loss_group=0.2613, Loss_adv=0.6907\n",
            "Epoch 80: Loss_D=1.3844, Loss_proxy=0.0193, Loss_group=0.2617, Loss_adv=0.6994\n",
            "Epoch 90: Loss_D=1.3838, Loss_proxy=0.0195, Loss_group=0.2647, Loss_adv=0.6964\n",
            "Fold 1 - Classes in synthetic data: [0 1 2 3]\n",
            "Fold 1 - Logistic Regression accuracy: 0.6852\n",
            "Fold 1 - Random Forest accuracy: 0.7257\n",
            "Fold 1 - MLP accuracy: 0.7373\n",
            "Fold 1 - XGBoost accuracy: 0.7593\n",
            "\n",
            "Results for car:\n",
            "    Dataset  TSTR (Logistic Regression) Mean  TSTR (Logistic Regression) Std  \\\n",
            "0  credit-a                         0.821256                        0.016368   \n",
            "1       car                         0.715278                        0.016204   \n",
            "2       car                         0.715856                        0.030671   \n",
            "\n",
            "   TSTR (Random Forest) Mean  TSTR (Random Forest) Std  TSTR (MLP) Mean  \\\n",
            "0                   0.847343                  0.017445         0.809662   \n",
            "1                   0.713542                  0.000579         0.758102   \n",
            "2                   0.720486                  0.005208         0.757523   \n",
            "\n",
            "   TSTR (MLP) Std  TSTR (XGBoost) Mean  TSTR (XGBoost) Std  JSD Mean  \\\n",
            "0        0.017920             0.857971            0.014874  0.106695   \n",
            "1        0.031250             0.793981            0.000000  0.583143   \n",
            "2        0.020255             0.787037            0.027778  0.588338   \n",
            "\n",
            "    JSD Std   WD Mean    WD Std  \n",
            "0  0.070606  0.052980  0.006941  \n",
            "1  0.018523  0.095162  0.000923  \n",
            "2  0.002535  0.095527  0.001674  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dataset': 'car',\n",
              " 'TSTR (Logistic Regression) Mean': np.float64(0.7158564814814815),\n",
              " 'TSTR (Logistic Regression) Std': np.float64(0.03067129629629628),\n",
              " 'TSTR (Random Forest) Mean': np.float64(0.7204861111111112),\n",
              " 'TSTR (Random Forest) Std': np.float64(0.005208333333333315),\n",
              " 'TSTR (MLP) Mean': np.float64(0.7575231481481481),\n",
              " 'TSTR (MLP) Std': np.float64(0.02025462962962965),\n",
              " 'TSTR (XGBoost) Mean': np.float64(0.787037037037037),\n",
              " 'TSTR (XGBoost) Std': np.float64(0.027777777777777735),\n",
              " 'JSD Mean': np.float64(0.588338184818088),\n",
              " 'JSD Std': np.float64(0.002534643678293369),\n",
              " 'WD Mean': np.float64(0.09552714280363273),\n",
              " 'WD Std': np.float64(0.0016740063675890413)}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate `credit-a`"
      ],
      "metadata": {
        "id": "7_NaQt0qNULB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, le = load_arff(\"credit-a.arff\")\n",
        "evaluate_dataset(\"credit-a\", X, y, le, results_file='results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9a2E47tNRNK",
        "outputId": "ffadbc46-9e0d-4629-bd15-6fa7b09bee4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: credit-a.arff, Unique labels: [0 1]\n",
            "\n",
            "Evaluating credit-a (690 samples, 100 epochs):\n",
            "Number of classes: 2, Labels: [0 1]\n",
            "Fold 0 - Classes in training data: [0 1]\n",
            "Epoch 0: Loss_D=1.3879, Loss_proxy=1.3686, Loss_group=1.4337, Loss_adv=0.6248\n",
            "Epoch 10: Loss_D=1.5172, Loss_proxy=0.7499, Loss_group=0.8641, Loss_adv=0.4126\n",
            "Epoch 20: Loss_D=1.4145, Loss_proxy=0.3221, Loss_group=0.4651, Loss_adv=0.6278\n",
            "Epoch 30: Loss_D=1.4771, Loss_proxy=0.2556, Loss_group=0.4655, Loss_adv=0.6068\n",
            "Epoch 40: Loss_D=1.4238, Loss_proxy=0.0961, Loss_group=0.3550, Loss_adv=0.6619\n",
            "Epoch 50: Loss_D=1.4049, Loss_proxy=0.0386, Loss_group=0.3194, Loss_adv=0.6834\n",
            "Epoch 60: Loss_D=1.3960, Loss_proxy=0.0265, Loss_group=0.2752, Loss_adv=0.6975\n",
            "Epoch 70: Loss_D=1.3949, Loss_proxy=0.0159, Loss_group=0.2926, Loss_adv=0.7005\n",
            "Epoch 80: Loss_D=1.3903, Loss_proxy=0.0349, Loss_group=0.4014, Loss_adv=0.6934\n",
            "Epoch 90: Loss_D=1.3920, Loss_proxy=0.0157, Loss_group=0.3741, Loss_adv=0.6998\n",
            "Fold 0 - Classes in synthetic data: [0 1]\n",
            "Fold 0 - Logistic Regression accuracy: 0.8609\n",
            "Fold 0 - Random Forest accuracy: 0.8667\n",
            "Fold 0 - MLP accuracy: 0.8232\n",
            "Fold 0 - XGBoost accuracy: 0.8551\n",
            "Fold 1 - Classes in training data: [0 1]\n",
            "Epoch 0: Loss_D=1.3034, Loss_proxy=0.8207, Loss_group=0.8604, Loss_adv=0.6284\n",
            "Epoch 10: Loss_D=1.4726, Loss_proxy=0.7132, Loss_group=0.8127, Loss_adv=0.4396\n",
            "Epoch 20: Loss_D=1.5271, Loss_proxy=0.5098, Loss_group=0.6769, Loss_adv=0.6407\n",
            "Epoch 30: Loss_D=1.4552, Loss_proxy=0.5613, Loss_group=1.0616, Loss_adv=0.6387\n",
            "Epoch 40: Loss_D=1.4077, Loss_proxy=0.0907, Loss_group=0.3121, Loss_adv=0.6726\n",
            "Epoch 50: Loss_D=1.3994, Loss_proxy=0.0648, Loss_group=0.4946, Loss_adv=0.6765\n",
            "Epoch 60: Loss_D=1.3948, Loss_proxy=0.0564, Loss_group=0.3445, Loss_adv=0.7042\n",
            "Epoch 70: Loss_D=1.3950, Loss_proxy=0.0390, Loss_group=0.4805, Loss_adv=0.6979\n",
            "Epoch 80: Loss_D=1.3921, Loss_proxy=0.0176, Loss_group=0.3126, Loss_adv=0.7012\n",
            "Epoch 90: Loss_D=1.3914, Loss_proxy=0.0133, Loss_group=0.2877, Loss_adv=0.7070\n",
            "Fold 1 - Classes in synthetic data: [0 1]\n",
            "Fold 1 - Logistic Regression accuracy: 0.8319\n",
            "Fold 1 - Random Forest accuracy: 0.8522\n",
            "Fold 1 - MLP accuracy: 0.8435\n",
            "Fold 1 - XGBoost accuracy: 0.8609\n",
            "\n",
            "Results for credit-a:\n",
            "    Dataset  TSTR (Logistic Regression) Mean  TSTR (Logistic Regression) Std  \\\n",
            "0  credit-a                         0.821256                        0.016368   \n",
            "1       car                         0.715278                        0.016204   \n",
            "2       car                         0.715856                        0.030671   \n",
            "3  credit-a                         0.846377                        0.014493   \n",
            "\n",
            "   TSTR (Random Forest) Mean  TSTR (Random Forest) Std  TSTR (MLP) Mean  \\\n",
            "0                   0.847343                  0.017445         0.809662   \n",
            "1                   0.713542                  0.000579         0.758102   \n",
            "2                   0.720486                  0.005208         0.757523   \n",
            "3                   0.859420                  0.007246         0.833333   \n",
            "\n",
            "   TSTR (MLP) Std  TSTR (XGBoost) Mean  TSTR (XGBoost) Std  JSD Mean  \\\n",
            "0        0.017920             0.857971            0.014874  0.106695   \n",
            "1        0.031250             0.793981            0.000000  0.583143   \n",
            "2        0.020255             0.787037            0.027778  0.588338   \n",
            "3        0.010145             0.857971            0.002899  0.159476   \n",
            "\n",
            "    JSD Std   WD Mean    WD Std  \n",
            "0  0.070606  0.052980  0.006941  \n",
            "1  0.018523  0.095162  0.000923  \n",
            "2  0.002535  0.095527  0.001674  \n",
            "3  0.084962  0.041119  0.003898  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dataset': 'credit-a',\n",
              " 'TSTR (Logistic Regression) Mean': np.float64(0.846376811594203),\n",
              " 'TSTR (Logistic Regression) Std': np.float64(0.014492753623188415),\n",
              " 'TSTR (Random Forest) Mean': np.float64(0.8594202898550725),\n",
              " 'TSTR (Random Forest) Std': np.float64(0.007246376811594235),\n",
              " 'TSTR (MLP) Mean': np.float64(0.8333333333333333),\n",
              " 'TSTR (MLP) Std': np.float64(0.010144927536231918),\n",
              " 'TSTR (XGBoost) Mean': np.float64(0.8579710144927537),\n",
              " 'TSTR (XGBoost) Std': np.float64(0.002898550724637683),\n",
              " 'JSD Mean': np.float64(0.15947554664262437),\n",
              " 'JSD Std': np.float64(0.08496183163354602),\n",
              " 'WD Mean': np.float64(0.04111857703108171),\n",
              " 'WD Std': np.float64(0.0038980460302406802)}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate `nursery`"
      ],
      "metadata": {
        "id": "O6xFZ1NaNZlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, le = load_arff(\"nursery 1.arff\")\n",
        "evaluate_dataset(\"nursery\", X, y, le, results_file='results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvOt1QUANdK_",
        "outputId": "b583d425-02bd-4b01-cddb-7795315558ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: nursery 1.arff, Unique labels: [0 1 2 3 4]\n",
            "\n",
            "Evaluating nursery (12960 samples, 100 epochs):\n",
            "Number of classes: 5, Labels: [0 1 2 3 4]\n",
            "Fold 0 - Classes in training data: [0 1 2 3 4]\n",
            "Epoch 0: Loss_D=1.4300, Loss_proxy=0.1868, Loss_group=0.4628, Loss_adv=0.5548\n",
            "Epoch 10: Loss_D=1.3860, Loss_proxy=0.0133, Loss_group=0.2578, Loss_adv=0.6894\n",
            "Epoch 20: Loss_D=1.3856, Loss_proxy=0.0125, Loss_group=0.2440, Loss_adv=0.6927\n",
            "Epoch 30: Loss_D=1.3876, Loss_proxy=0.0194, Loss_group=0.2613, Loss_adv=0.6842\n",
            "Epoch 40: Loss_D=1.3850, Loss_proxy=0.0158, Loss_group=0.2593, Loss_adv=0.6947\n",
            "Epoch 50: Loss_D=1.3900, Loss_proxy=0.0178, Loss_group=0.2505, Loss_adv=0.6805\n",
            "Epoch 60: Loss_D=1.3875, Loss_proxy=0.0155, Loss_group=0.2331, Loss_adv=0.7029\n",
            "Epoch 70: Loss_D=1.3805, Loss_proxy=0.0226, Loss_group=0.2443, Loss_adv=0.7072\n",
            "Epoch 80: Loss_D=1.3923, Loss_proxy=0.0283, Loss_group=0.2278, Loss_adv=0.7034\n",
            "Epoch 90: Loss_D=1.3723, Loss_proxy=0.0436, Loss_group=0.2507, Loss_adv=0.7390\n",
            "Fold 0 - Classes in synthetic data: [0 1 2 3 4]\n",
            "Fold 0 - Logistic Regression accuracy: 0.8136\n",
            "Fold 0 - Random Forest accuracy: 0.8020\n",
            "Fold 0 - MLP accuracy: 0.8309\n",
            "Fold 0 - XGBoost accuracy: 0.8341\n",
            "Fold 1 - Classes in training data: [0 1 2 3 4]\n",
            "Epoch 0: Loss_D=1.4385, Loss_proxy=0.1828, Loss_group=0.4257, Loss_adv=0.5199\n",
            "Epoch 10: Loss_D=1.3874, Loss_proxy=0.0154, Loss_group=0.2657, Loss_adv=0.6959\n",
            "Epoch 20: Loss_D=1.3862, Loss_proxy=0.0145, Loss_group=0.2556, Loss_adv=0.6994\n",
            "Epoch 30: Loss_D=1.3668, Loss_proxy=0.0324, Loss_group=0.2724, Loss_adv=0.6987\n",
            "Epoch 40: Loss_D=1.3295, Loss_proxy=0.0345, Loss_group=0.2605, Loss_adv=0.7175\n",
            "Epoch 50: Loss_D=1.3228, Loss_proxy=0.0339, Loss_group=0.2644, Loss_adv=0.6943\n",
            "Epoch 60: Loss_D=1.2893, Loss_proxy=0.0496, Loss_group=0.2659, Loss_adv=0.7823\n",
            "Epoch 70: Loss_D=1.4029, Loss_proxy=0.0604, Loss_group=0.2613, Loss_adv=0.8120\n",
            "Epoch 80: Loss_D=1.3693, Loss_proxy=0.0388, Loss_group=0.2485, Loss_adv=0.7371\n",
            "Epoch 90: Loss_D=1.2318, Loss_proxy=0.0259, Loss_group=0.2667, Loss_adv=0.9511\n",
            "Fold 1 - Classes in synthetic data: [0 1 2 3 4]\n",
            "Fold 1 - Logistic Regression accuracy: 0.8591\n",
            "Fold 1 - Random Forest accuracy: 0.7923\n",
            "Fold 1 - MLP accuracy: 0.8586\n",
            "Fold 1 - XGBoost accuracy: 0.8431\n",
            "\n",
            "Results for nursery:\n",
            "    Dataset  TSTR (Logistic Regression) Mean  TSTR (Logistic Regression) Std  \\\n",
            "0  credit-a                         0.821256                        0.016368   \n",
            "1       car                         0.715278                        0.016204   \n",
            "2       car                         0.715856                        0.030671   \n",
            "3  credit-a                         0.846377                        0.014493   \n",
            "4   nursery                         0.836343                        0.022762   \n",
            "\n",
            "   TSTR (Random Forest) Mean  TSTR (Random Forest) Std  TSTR (MLP) Mean  \\\n",
            "0                   0.847343                  0.017445         0.809662   \n",
            "1                   0.713542                  0.000579         0.758102   \n",
            "2                   0.720486                  0.005208         0.757523   \n",
            "3                   0.859420                  0.007246         0.833333   \n",
            "4                   0.797145                  0.004861         0.844753   \n",
            "\n",
            "   TSTR (MLP) Std  TSTR (XGBoost) Mean  TSTR (XGBoost) Std  JSD Mean  \\\n",
            "0        0.017920             0.857971            0.014874  0.106695   \n",
            "1        0.031250             0.793981            0.000000  0.583143   \n",
            "2        0.020255             0.787037            0.027778  0.588338   \n",
            "3        0.010145             0.857971            0.002899  0.159476   \n",
            "4        0.013889             0.838580            0.004475  0.445901   \n",
            "\n",
            "    JSD Std   WD Mean    WD Std  \n",
            "0  0.070606  0.052980  0.006941  \n",
            "1  0.018523  0.095162  0.000923  \n",
            "2  0.002535  0.095527  0.001674  \n",
            "3  0.084962  0.041119  0.003898  \n",
            "4  0.049923  0.090403  0.004790  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dataset': 'nursery',\n",
              " 'TSTR (Logistic Regression) Mean': np.float64(0.8363425925925926),\n",
              " 'TSTR (Logistic Regression) Std': np.float64(0.022762345679012363),\n",
              " 'TSTR (Random Forest) Mean': np.float64(0.797145061728395),\n",
              " 'TSTR (Random Forest) Std': np.float64(0.004861111111111094),\n",
              " 'TSTR (MLP) Mean': np.float64(0.844753086419753),\n",
              " 'TSTR (MLP) Std': np.float64(0.013888888888888895),\n",
              " 'TSTR (XGBoost) Mean': np.float64(0.8385802469135802),\n",
              " 'TSTR (XGBoost) Std': np.float64(0.004475308641975317),\n",
              " 'JSD Mean': np.float64(0.4459010282261264),\n",
              " 'JSD Std': np.float64(0.049922879461593295),\n",
              " 'WD Mean': np.float64(0.09040291698026154),\n",
              " 'WD Std': np.float64(0.004789764712924832)}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate `dermatology`"
      ],
      "metadata": {
        "id": "6LHFYW7lNg9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, le = load_arff(\"dermatology.arff\")\n",
        "evaluate_dataset(\"dermatology\", X, y, le, results_file='results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr_0FfWoNj98",
        "outputId": "85b29986-8c47-49a7-d65b-6b6e3e65d6b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: dermatology.arff, Unique labels: [0 1 2 3 4 5]\n",
            "\n",
            "Evaluating dermatology (366 samples, 100 epochs):\n",
            "Number of classes: 6, Labels: [0 1 2 3 4 5]\n",
            "Fold 0 - Classes in training data: [0 1 2 3 4 5]\n",
            "Epoch 0: Loss_D=1.3851, Loss_proxy=1.0920, Loss_group=1.1432, Loss_adv=0.6397\n",
            "Epoch 10: Loss_D=1.1408, Loss_proxy=0.7907, Loss_group=0.8532, Loss_adv=0.6223\n",
            "Epoch 20: Loss_D=1.6137, Loss_proxy=0.8593, Loss_group=0.9689, Loss_adv=0.4544\n",
            "Epoch 30: Loss_D=1.2681, Loss_proxy=0.8410, Loss_group=0.9551, Loss_adv=0.8181\n",
            "Epoch 40: Loss_D=1.3820, Loss_proxy=0.9104, Loss_group=1.0215, Loss_adv=1.2596\n",
            "Epoch 50: Loss_D=1.5078, Loss_proxy=0.8426, Loss_group=0.9311, Loss_adv=0.7729\n",
            "Epoch 60: Loss_D=1.0608, Loss_proxy=0.7543, Loss_group=0.8301, Loss_adv=1.1883\n",
            "Epoch 70: Loss_D=1.3068, Loss_proxy=0.6959, Loss_group=0.7863, Loss_adv=0.7464\n",
            "Epoch 80: Loss_D=1.3490, Loss_proxy=0.6294, Loss_group=0.7474, Loss_adv=0.5692\n",
            "Epoch 90: Loss_D=1.6135, Loss_proxy=0.6380, Loss_group=0.8240, Loss_adv=0.5046\n",
            "Fold 0 - Classes in synthetic data: [0 1 2 3 4 5]\n",
            "Fold 0 - Logistic Regression accuracy: 0.8798\n",
            "Fold 0 - Random Forest accuracy: 0.7432\n",
            "Fold 0 - MLP accuracy: 0.8087\n",
            "Fold 0 - XGBoost accuracy: 0.3934\n",
            "Fold 1 - Classes in training data: [0 1 2 3 4 5]\n",
            "Epoch 0: Loss_D=1.4010, Loss_proxy=0.9549, Loss_group=1.0003, Loss_adv=0.6749\n",
            "Epoch 10: Loss_D=1.1893, Loss_proxy=0.8666, Loss_group=0.9342, Loss_adv=0.5590\n",
            "Epoch 20: Loss_D=1.7629, Loss_proxy=0.7704, Loss_group=0.8711, Loss_adv=0.3463\n",
            "Epoch 30: Loss_D=1.2813, Loss_proxy=0.7469, Loss_group=0.8533, Loss_adv=0.8392\n",
            "Epoch 40: Loss_D=1.2039, Loss_proxy=0.8088, Loss_group=0.8951, Loss_adv=1.3651\n",
            "Epoch 50: Loss_D=1.4438, Loss_proxy=0.8190, Loss_group=0.8911, Loss_adv=1.0127\n",
            "Epoch 60: Loss_D=1.2226, Loss_proxy=0.8519, Loss_group=0.9232, Loss_adv=0.8850\n",
            "Epoch 70: Loss_D=1.1434, Loss_proxy=0.7526, Loss_group=0.8406, Loss_adv=1.1094\n",
            "Epoch 80: Loss_D=1.4424, Loss_proxy=0.6913, Loss_group=0.7836, Loss_adv=0.4967\n",
            "Epoch 90: Loss_D=1.2555, Loss_proxy=0.6534, Loss_group=0.7870, Loss_adv=0.5807\n",
            "Fold 1 - Classes in synthetic data: [0 1 2 3 4 5]\n",
            "Fold 1 - Logistic Regression accuracy: 0.8852\n",
            "Fold 1 - Random Forest accuracy: 0.7322\n",
            "Fold 1 - MLP accuracy: 0.8525\n",
            "Fold 1 - XGBoost accuracy: 0.3497\n",
            "\n",
            "Results for dermatology:\n",
            "       Dataset  TSTR (Logistic Regression) Mean  \\\n",
            "0     credit-a                         0.821256   \n",
            "1          car                         0.715278   \n",
            "2          car                         0.715856   \n",
            "3     credit-a                         0.846377   \n",
            "4      nursery                         0.836343   \n",
            "5  dermatology                         0.882514   \n",
            "\n",
            "   TSTR (Logistic Regression) Std  TSTR (Random Forest) Mean  \\\n",
            "0                        0.016368                   0.847343   \n",
            "1                        0.016204                   0.713542   \n",
            "2                        0.030671                   0.720486   \n",
            "3                        0.014493                   0.859420   \n",
            "4                        0.022762                   0.797145   \n",
            "5                        0.002732                   0.737705   \n",
            "\n",
            "   TSTR (Random Forest) Std  TSTR (MLP) Mean  TSTR (MLP) Std  \\\n",
            "0                  0.017445         0.809662        0.017920   \n",
            "1                  0.000579         0.758102        0.031250   \n",
            "2                  0.005208         0.757523        0.020255   \n",
            "3                  0.007246         0.833333        0.010145   \n",
            "4                  0.004861         0.844753        0.013889   \n",
            "5                  0.005464         0.830601        0.021858   \n",
            "\n",
            "   TSTR (XGBoost) Mean  TSTR (XGBoost) Std  JSD Mean   JSD Std   WD Mean  \\\n",
            "0             0.857971            0.014874  0.106695  0.070606  0.052980   \n",
            "1             0.793981            0.000000  0.583143  0.018523  0.095162   \n",
            "2             0.787037            0.027778  0.588338  0.002535  0.095527   \n",
            "3             0.857971            0.002899  0.159476  0.084962  0.041119   \n",
            "4             0.838580            0.004475  0.445901  0.049923  0.090403   \n",
            "5             0.371585            0.021858  0.453897  0.225141  0.341872   \n",
            "\n",
            "     WD Std  \n",
            "0  0.006941  \n",
            "1  0.000923  \n",
            "2  0.001674  \n",
            "3  0.003898  \n",
            "4  0.004790  \n",
            "5  0.001922  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dataset': 'dermatology',\n",
              " 'TSTR (Logistic Regression) Mean': np.float64(0.8825136612021858),\n",
              " 'TSTR (Logistic Regression) Std': np.float64(0.002732240437158473),\n",
              " 'TSTR (Random Forest) Mean': np.float64(0.7377049180327869),\n",
              " 'TSTR (Random Forest) Std': np.float64(0.005464480874316946),\n",
              " 'TSTR (MLP) Mean': np.float64(0.8306010928961749),\n",
              " 'TSTR (MLP) Std': np.float64(0.02185792349726773),\n",
              " 'TSTR (XGBoost) Mean': np.float64(0.3715846994535519),\n",
              " 'TSTR (XGBoost) Std': np.float64(0.021857923497267756),\n",
              " 'JSD Mean': np.float64(0.45389741250670385),\n",
              " 'JSD Std': np.float64(0.22514073877973023),\n",
              " 'WD Mean': np.float64(0.34187178680631675),\n",
              " 'WD Std': np.float64(0.0019223334785075097)}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, le = load_arff(\"connect-4.arff\")\n",
        "evaluate_dataset(\"connec-4\", X, y, le, results_file='results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiIyfve4QVaw",
        "outputId": "f3cb6935-4811-473d-b844-122bc0cdf7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: connect-4.arff, Unique labels: [0 1 2]\n",
            "\n",
            "Evaluating connec-4 (67557 samples, 50 epochs):\n",
            "Number of classes: 3, Labels: [0 1 2]\n",
            "Fold 0 - Classes in training data: [0 1 2]\n",
            "Epoch 0: Loss_D=0.9930, Loss_proxy=0.7022, Loss_group=0.8269, Loss_adv=1.1782\n",
            "Epoch 10: Loss_D=1.3894, Loss_proxy=0.0125, Loss_group=0.3688, Loss_adv=0.6972\n",
            "Epoch 20: Loss_D=1.3928, Loss_proxy=0.0277, Loss_group=0.2750, Loss_adv=0.7037\n",
            "Epoch 30: Loss_D=1.3739, Loss_proxy=0.0244, Loss_group=0.2480, Loss_adv=0.7071\n",
            "Epoch 40: Loss_D=1.3388, Loss_proxy=0.0232, Loss_group=0.2904, Loss_adv=0.7098\n",
            "Fold 0 - Classes in synthetic data: [0 1 2]\n",
            "Fold 0 - Logistic Regression accuracy: 0.7528\n",
            "Fold 0 - Random Forest accuracy: 0.7204\n",
            "Fold 0 - MLP accuracy: 0.7920\n",
            "Fold 0 - XGBoost accuracy: 0.7612\n",
            "Fold 1 - Classes in training data: [0 1 2]\n",
            "Epoch 0: Loss_D=1.0439, Loss_proxy=0.9815, Loss_group=1.1542, Loss_adv=1.7139\n",
            "Epoch 10: Loss_D=1.3911, Loss_proxy=0.0129, Loss_group=0.4073, Loss_adv=0.6825\n",
            "Epoch 20: Loss_D=1.3785, Loss_proxy=0.0172, Loss_group=0.2511, Loss_adv=0.7134\n",
            "Epoch 30: Loss_D=1.3635, Loss_proxy=0.0226, Loss_group=0.2698, Loss_adv=0.7045\n",
            "Epoch 40: Loss_D=1.3605, Loss_proxy=0.0244, Loss_group=0.3368, Loss_adv=0.6982\n",
            "Fold 1 - Classes in synthetic data: [0 1 2]\n",
            "Fold 1 - Logistic Regression accuracy: 0.7567\n",
            "Fold 1 - Random Forest accuracy: 0.7137\n",
            "Fold 1 - MLP accuracy: 0.7940\n",
            "Fold 1 - XGBoost accuracy: 0.7751\n",
            "\n",
            "Results for connec-4:\n",
            "    Dataset  TSTR (Logistic Regression) Mean  TSTR (Logistic Regression) Std  \\\n",
            "0  connec-4                          0.75477                        0.001935   \n",
            "\n",
            "   TSTR (Random Forest) Mean  TSTR (Random Forest) Std  TSTR (MLP) Mean  \\\n",
            "0                   0.717024                  0.003364          0.79299   \n",
            "\n",
            "   TSTR (MLP) Std  TSTR (XGBoost) Mean  TSTR (XGBoost) Std  JSD Mean  \\\n",
            "0        0.001018             0.768137            0.006924  0.648031   \n",
            "\n",
            "    JSD Std   WD Mean    WD Std  \n",
            "0  0.008814  0.039352  0.004224  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dataset': 'connec-4',\n",
              " 'TSTR (Logistic Regression) Mean': np.float64(0.7547700746846856),\n",
              " 'TSTR (Logistic Regression) Std': np.float64(0.0019354733051302198),\n",
              " 'TSTR (Random Forest) Mean': np.float64(0.7170240927762597),\n",
              " 'TSTR (Random Forest) Std': np.float64(0.0033643142221712607),\n",
              " 'TSTR (MLP) Mean': np.float64(0.7929896386502584),\n",
              " 'TSTR (MLP) Std': np.float64(0.0010182955080694778),\n",
              " 'TSTR (XGBoost) Mean': np.float64(0.7681366390463067),\n",
              " 'TSTR (XGBoost) Std': np.float64(0.006924051343888071),\n",
              " 'JSD Mean': np.float64(0.6480312959552712),\n",
              " 'JSD Std': np.float64(0.008813960876347116),\n",
              " 'WD Mean': np.float64(0.03935235932818211),\n",
              " 'WD Std': np.float64(0.004223978276841997)}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.read_csv('results.csv')\n",
        "result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "Rw32F2E1fiBm",
        "outputId": "6b89bc62-65a0-4966-99ce-2da53b434ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Dataset  TSTR (Logistic Regression) Mean  \\\n",
              "0          car                         0.715856   \n",
              "1     credit-a                         0.846377   \n",
              "2      nursery                         0.836343   \n",
              "3  dermatology                         0.882514   \n",
              "\n",
              "   TSTR (Logistic Regression) Std  TSTR (Random Forest) Mean  \\\n",
              "0                        0.030671                   0.720486   \n",
              "1                        0.014493                   0.859420   \n",
              "2                        0.022762                   0.797145   \n",
              "3                        0.002732                   0.737705   \n",
              "\n",
              "   TSTR (Random Forest) Std  TSTR (MLP) Mean  TSTR (MLP) Std  \\\n",
              "0                  0.005208         0.757523        0.020255   \n",
              "1                  0.007246         0.833333        0.010145   \n",
              "2                  0.004861         0.844753        0.013889   \n",
              "3                  0.005464         0.830601        0.021858   \n",
              "\n",
              "   TSTR (XGBoost) Mean  TSTR (XGBoost) Std  JSD Mean   JSD Std   WD Mean  \\\n",
              "0             0.787037            0.027778  0.588338  0.002535  0.095527   \n",
              "1             0.857971            0.002899  0.159476  0.084962  0.041119   \n",
              "2             0.838580            0.004475  0.445901  0.049923  0.090403   \n",
              "3             0.371585            0.021858  0.453897  0.225141  0.341872   \n",
              "\n",
              "     WD Std  \n",
              "0  0.001674  \n",
              "1  0.003898  \n",
              "2  0.004790  \n",
              "3  0.001922  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f34ab54-5297-40ff-aa06-e8e8b760b189\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>TSTR (Logistic Regression) Mean</th>\n",
              "      <th>TSTR (Logistic Regression) Std</th>\n",
              "      <th>TSTR (Random Forest) Mean</th>\n",
              "      <th>TSTR (Random Forest) Std</th>\n",
              "      <th>TSTR (MLP) Mean</th>\n",
              "      <th>TSTR (MLP) Std</th>\n",
              "      <th>TSTR (XGBoost) Mean</th>\n",
              "      <th>TSTR (XGBoost) Std</th>\n",
              "      <th>JSD Mean</th>\n",
              "      <th>JSD Std</th>\n",
              "      <th>WD Mean</th>\n",
              "      <th>WD Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>car</td>\n",
              "      <td>0.715856</td>\n",
              "      <td>0.030671</td>\n",
              "      <td>0.720486</td>\n",
              "      <td>0.005208</td>\n",
              "      <td>0.757523</td>\n",
              "      <td>0.020255</td>\n",
              "      <td>0.787037</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>0.588338</td>\n",
              "      <td>0.002535</td>\n",
              "      <td>0.095527</td>\n",
              "      <td>0.001674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>credit-a</td>\n",
              "      <td>0.846377</td>\n",
              "      <td>0.014493</td>\n",
              "      <td>0.859420</td>\n",
              "      <td>0.007246</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.010145</td>\n",
              "      <td>0.857971</td>\n",
              "      <td>0.002899</td>\n",
              "      <td>0.159476</td>\n",
              "      <td>0.084962</td>\n",
              "      <td>0.041119</td>\n",
              "      <td>0.003898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nursery</td>\n",
              "      <td>0.836343</td>\n",
              "      <td>0.022762</td>\n",
              "      <td>0.797145</td>\n",
              "      <td>0.004861</td>\n",
              "      <td>0.844753</td>\n",
              "      <td>0.013889</td>\n",
              "      <td>0.838580</td>\n",
              "      <td>0.004475</td>\n",
              "      <td>0.445901</td>\n",
              "      <td>0.049923</td>\n",
              "      <td>0.090403</td>\n",
              "      <td>0.004790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dermatology</td>\n",
              "      <td>0.882514</td>\n",
              "      <td>0.002732</td>\n",
              "      <td>0.737705</td>\n",
              "      <td>0.005464</td>\n",
              "      <td>0.830601</td>\n",
              "      <td>0.021858</td>\n",
              "      <td>0.371585</td>\n",
              "      <td>0.021858</td>\n",
              "      <td>0.453897</td>\n",
              "      <td>0.225141</td>\n",
              "      <td>0.341872</td>\n",
              "      <td>0.001922</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f34ab54-5297-40ff-aa06-e8e8b760b189')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f34ab54-5297-40ff-aa06-e8e8b760b189 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f34ab54-5297-40ff-aa06-e8e8b760b189');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0a3b1042-395d-49ee-8bea-d1548cc5daaa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a3b1042-395d-49ee-8bea-d1548cc5daaa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0a3b1042-395d-49ee-8bea-d1548cc5daaa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8d7e5e21-a8c7-423e-9221-b8860c0cf476\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8d7e5e21-a8c7-423e-9221-b8860c0cf476 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"credit-a\",\n          \"dermatology\",\n          \"car\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSTR (Logistic Regression) Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07237944006126436,\n        \"min\": 0.7158564814814815,\n        \"max\": 0.8825136612021858,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.846376811594203,\n          0.8825136612021858,\n          0.7158564814814815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSTR (Logistic Regression) Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011947065624246057,\n        \"min\": 0.0027322404371584,\n        \"max\": 0.0306712962962962,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0144927536231884,\n          0.0027322404371584,\n          0.0306712962962962\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSTR (Random Forest) Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06304876056370284,\n        \"min\": 0.7204861111111112,\n        \"max\": 0.8594202898550725,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8594202898550725,\n          0.7377049180327869,\n          0.7204861111111112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSTR (Random Forest) Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0010633475724481636,\n        \"min\": 0.004861111111111,\n        \"max\": 0.0072463768115942,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0072463768115942,\n          0.0054644808743169,\n          0.0052083333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSTR (MLP) Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03982753144949728,\n        \"min\": 0.7575231481481481,\n        \"max\": 0.844753086419753,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8333333333333333,\n          0.8306010928961749,\n          0.7575231481481481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSTR (MLP) Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005477349696740151,\n        \"min\": 0.0101449275362319,\n        \"max\": 0.0218579234972677,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0101449275362319,\n          0.0218579234972677,\n          0.0202546296296296\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSTR (XGBoost) Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23009444928801565,\n        \"min\": 0.3715846994535519,\n        \"max\": 0.8579710144927537,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.8579710144927537,\n          0.3715846994535519,\n          0.787037037037037\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TSTR (XGBoost) Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012453663992168667,\n        \"min\": 0.0028985507246376,\n        \"max\": 0.0277777777777777,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0028985507246376,\n          0.0218579234972677,\n          0.0277777777777777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"JSD Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1805255201306482,\n        \"min\": 0.1594755466426243,\n        \"max\": 0.588338184818088,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.1594755466426243,\n          0.4538974125067038,\n          0.588338184818088\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"JSD Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09581775765448852,\n        \"min\": 0.0025346436782933,\n        \"max\": 0.2251407387797302,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.084961831633546,\n          0.2251407387797302,\n          0.0025346436782933\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WD Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13533608326263494,\n        \"min\": 0.0411185770310817,\n        \"max\": 0.3418717868063167,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0411185770310817,\n          0.3418717868063167,\n          0.0955271428036327\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"WD Std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0015175839631310336,\n        \"min\": 0.001674006367589,\n        \"max\": 0.0047897647129248,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.0038980460302406,\n          0.0019223334785075,\n          0.001674006367589\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, le = load_arff(\"letter-recog.arff\")\n",
        "evaluate_dataset(\"letter-recog\", X, y, le, results_file='results.csv')"
      ],
      "metadata": {
        "id": "A5gopvQLm-hd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edcfea40-3a03-46a9-bb91-270b57d806e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: letter-recog.arff, Unique labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "\n",
            "Evaluating letter-recog (20000 samples, 100 epochs):\n",
            "Number of classes: 26, Labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "Fold 0 - Classes in training data: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "Epoch 0: Loss_D=1.2469, Loss_proxy=0.9986, Loss_group=1.0308, Loss_adv=1.6929\n",
            "Epoch 10: Loss_D=0.5682, Loss_proxy=1.1818, Loss_group=1.5140, Loss_adv=1.6047\n",
            "Epoch 20: Loss_D=0.7818, Loss_proxy=1.0434, Loss_group=1.7180, Loss_adv=2.0063\n",
            "Epoch 30: Loss_D=1.7524, Loss_proxy=0.7084, Loss_group=1.7159, Loss_adv=0.9100\n",
            "Epoch 40: Loss_D=1.5354, Loss_proxy=0.3552, Loss_group=1.5524, Loss_adv=0.7565\n",
            "Epoch 50: Loss_D=1.4587, Loss_proxy=0.1354, Loss_group=1.3607, Loss_adv=0.7962\n",
            "Epoch 60: Loss_D=1.3966, Loss_proxy=0.0648, Loss_group=0.9453, Loss_adv=0.6279\n",
            "Epoch 70: Loss_D=1.4234, Loss_proxy=0.0347, Loss_group=0.7350, Loss_adv=0.6869\n",
            "Epoch 80: Loss_D=1.3930, Loss_proxy=0.0207, Loss_group=0.5889, Loss_adv=0.6915\n",
            "Epoch 90: Loss_D=1.3853, Loss_proxy=0.0118, Loss_group=0.3461, Loss_adv=0.6948\n",
            "Fold 0 - Classes in synthetic data: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "Fold 0 - Logistic Regression accuracy: 0.7736\n",
            "Fold 0 - Random Forest accuracy: 0.2408\n",
            "Fold 0 - MLP accuracy: 0.8201\n",
            "Fold 0 - XGBoost accuracy: 0.4843\n",
            "Fold 1 - Classes in training data: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "Epoch 0: Loss_D=1.1012, Loss_proxy=0.9299, Loss_group=0.9550, Loss_adv=1.5794\n",
            "Epoch 10: Loss_D=0.8355, Loss_proxy=1.0611, Loss_group=1.4760, Loss_adv=1.3588\n",
            "Epoch 20: Loss_D=1.1899, Loss_proxy=1.0232, Loss_group=1.6483, Loss_adv=1.2147\n",
            "Epoch 30: Loss_D=1.3857, Loss_proxy=0.6468, Loss_group=1.3214, Loss_adv=0.8996\n",
            "Epoch 40: Loss_D=1.5608, Loss_proxy=0.3884, Loss_group=1.4302, Loss_adv=0.8578\n",
            "Epoch 50: Loss_D=1.4006, Loss_proxy=0.2139, Loss_group=1.4587, Loss_adv=0.7951\n",
            "Epoch 60: Loss_D=1.3799, Loss_proxy=0.0871, Loss_group=1.1454, Loss_adv=0.7384\n",
            "Epoch 70: Loss_D=1.3971, Loss_proxy=0.0331, Loss_group=0.7888, Loss_adv=0.6909\n",
            "Epoch 80: Loss_D=1.3863, Loss_proxy=0.0170, Loss_group=0.5049, Loss_adv=0.6934\n",
            "Epoch 90: Loss_D=1.3893, Loss_proxy=0.0238, Loss_group=0.4859, Loss_adv=0.7045\n",
            "Fold 1 - Classes in synthetic data: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25]\n",
            "Fold 1 - Logistic Regression accuracy: 0.7955\n",
            "Fold 1 - Random Forest accuracy: 0.5636\n",
            "Fold 1 - MLP accuracy: 0.8256\n",
            "Fold 1 - XGBoost accuracy: 0.5448\n",
            "\n",
            "Results for letter-recog:\n",
            "        Dataset  TSTR (Logistic Regression) Mean  \\\n",
            "0      connec-4                          0.75477   \n",
            "1  letter-recog                          0.78455   \n",
            "\n",
            "   TSTR (Logistic Regression) Std  TSTR (Random Forest) Mean  \\\n",
            "0                        0.001935                   0.717024   \n",
            "1                        0.010950                   0.402200   \n",
            "\n",
            "   TSTR (Random Forest) Std  TSTR (MLP) Mean  TSTR (MLP) Std  \\\n",
            "0                  0.003364          0.79299        0.001018   \n",
            "1                  0.161400          0.82285        0.002750   \n",
            "\n",
            "   TSTR (XGBoost) Mean  TSTR (XGBoost) Std  JSD Mean   JSD Std   WD Mean  \\\n",
            "0             0.768137            0.006924  0.648031  0.008814  0.039352   \n",
            "1             0.514550            0.030250  0.349827  0.026873  0.058265   \n",
            "\n",
            "     WD Std  \n",
            "0  0.004224  \n",
            "1  0.020643  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Dataset': 'letter-recog',\n",
              " 'TSTR (Logistic Regression) Mean': np.float64(0.78455),\n",
              " 'TSTR (Logistic Regression) Std': np.float64(0.010950000000000015),\n",
              " 'TSTR (Random Forest) Mean': np.float64(0.4022),\n",
              " 'TSTR (Random Forest) Std': np.float64(0.1614),\n",
              " 'TSTR (MLP) Mean': np.float64(0.8228500000000001),\n",
              " 'TSTR (MLP) Std': np.float64(0.0027499999999999747),\n",
              " 'TSTR (XGBoost) Mean': np.float64(0.51455),\n",
              " 'TSTR (XGBoost) Std': np.float64(0.03024999999999997),\n",
              " 'JSD Mean': np.float64(0.34982686315641776),\n",
              " 'JSD Std': np.float64(0.026873259564807572),\n",
              " 'WD Mean': np.float64(0.05826452323382959),\n",
              " 'WD Std': np.float64(0.02064292451781974)}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, le = load_arff(\"adult 1.arff\")\n",
        "evaluate_dataset(\"adult 1\", X, y, le, results_file='results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3G7NNI3uC-l",
        "outputId": "d8cf5216-6da4-4d83-e9b5-9708a5f1ce8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: adult 1.arff, Unique labels: [0 1]\n",
            "\n",
            "Evaluating adult 1 (48842 samples, 50 epochs):\n",
            "Number of classes: 2, Labels: [0 1]\n",
            "Fold 0 - Classes in training data: [0 1]\n",
            "Epoch 0: Loss_D=1.2419, Loss_proxy=0.9318, Loss_group=1.0381, Loss_adv=0.7569\n",
            "Epoch 10: Loss_D=1.2680, Loss_proxy=0.7673, Loss_group=1.7374, Loss_adv=0.8964\n",
            "Epoch 20: Loss_D=1.4151, Loss_proxy=0.0500, Loss_group=0.7102, Loss_adv=0.7106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, le = load_arff(\"chess.arff\")\n",
        "evaluate_dataset(\"chess\", X, y, le, results_file='results.csv')"
      ],
      "metadata": {
        "id": "PxpRETUH6hhQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}