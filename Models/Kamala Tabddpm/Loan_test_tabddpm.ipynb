{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd4103a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Direct imports from the same directory\n",
    "from tabddpm_adapter import TabDDPMAdapter\n",
    "from tabddpm_benchmark import evaluate_tabddpm, print_evaluation_results\n",
    "from tabddpm_utils import preprocess_data, get_tstr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a721eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load configuration\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(\"# Load configuration\")\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914a0b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1. Load and prepare the dataset\n",
      "Columns in dataset: ['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg', 'Education', 'Mortgage', 'Personal Loan', 'Securities Account', 'CD Account', 'Online', 'CreditCard']\n",
      "Dataset shape: (5000, 14)\n",
      "   ID  Age  Experience  Income  ZIP Code  Family CCAvg  Education  Mortgage  \\\n",
      "0   1   25           1      49     91107       4  1/60          1         0   \n",
      "1   2   45          19      34     90089       3  1/50          1         0   \n",
      "2   3   39          15      11     94720       1  1/00          1         0   \n",
      "3   4   35           9     100     94112       1  2/70          2         0   \n",
      "4   5   35           8      45     91330       4  1/00          2         0   \n",
      "\n",
      "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
      "0              0                   1           0       0           0  \n",
      "1              0                   1           0       0           0  \n",
      "2              0                   0           0       0           0  \n",
      "3              0                   0           0       0           0  \n",
      "4              0                   0           0       0           1  \n"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare the dataset\n",
    "print(\"# 1. Load and prepare the dataset\")\n",
    "data_raw = pd.read_csv(\"Bank_Personal_Loan.csv\")\n",
    "print(f\"Columns in dataset: {data_raw.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {data_raw.shape}\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95aa282b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 11:37:31,849 - INFO - Converted Family to category type (has 4 unique values)\n",
      "2025-04-27 11:37:31,849 - INFO - Converted CCAvg to category type (has 108 unique values)\n",
      "2025-04-27 11:37:31,855 - INFO - Converted Education to category type (has 3 unique values)\n",
      "2025-04-27 11:37:31,856 - INFO - Converted Personal Loan to category type (has 2 unique values)\n",
      "2025-04-27 11:37:31,857 - INFO - Converted Securities Account to category type (has 2 unique values)\n",
      "2025-04-27 11:37:31,859 - INFO - Converted CD Account to category type (has 2 unique values)\n",
      "2025-04-27 11:37:31,860 - INFO - Converted Online to category type (has 2 unique values)\n",
      "2025-04-27 11:37:31,861 - INFO - Converted CreditCard to category type (has 2 unique values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 2. Preprocess data and detect categorical columns\n",
      "Detected categorical columns: ['Family', 'CCAvg', 'Education', 'Personal Loan', 'Securities Account', 'CD Account', 'Online', 'CreditCard']\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocess data and detect categorical columns\n",
    "print(\"\\n# 2. Preprocess data and detect categorical columns\")\n",
    "data, categorical_columns = preprocess_data(data_raw)\n",
    "print(f\"Detected categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1dfaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3. Define the target column for this dataset\n",
      "Target column: Personal Loan\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the target column for this dataset\n",
    "print(\"\\n# 3. Define the target column for this dataset\")\n",
    "target_column = \"Personal Loan\"\n",
    "print(f\"Target column: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646be908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 4. Split the data into features and target\n",
      "Features shape: (5000, 13)\n",
      "Target shape: (5000,)\n",
      "Target distribution:\n",
      "Personal Loan\n",
      "0    4520\n",
      "1     480\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Split the data into features and target\n",
    "print(\"\\n# 4. Split the data into features and target\")\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e8a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 5. Initialize and train TabDDPM\n",
      "Training TabDDPM model...\n",
      "Original data shape: (5000, 14), Target column: Personal Loan\n",
      "Added StandardScaler for 6 numerical columns\n",
      "Added OneHotEncoder for 7 categorical columns\n",
      "Target 'Personal Loan' identified as categorical with 2 classes\n",
      "Class mapping: {0: 0, 1: 1}\n",
      "\n",
      "Preprocessing Summary:\n",
      "- Number of numerical features: 6\n",
      "- Number of categorical features: 7\n",
      "- Categorical columns: ['Family', 'CCAvg', 'Education', 'Securities Account', 'CD Account', 'Online', 'CreditCard']\n",
      "- Target column: Personal Loan\n",
      "- Target type: Categorical\n",
      "- Number of target classes: 2\n",
      "X shape: (5000, 13), y shape: (5000,)\n",
      "X_tensor shape: torch.Size([5000, 129]), y_tensor shape: torch.Size([5000])\n",
      "X_tensor shape: torch.Size([5000, 129])\n",
      "y_tensor shape: torch.Size([5000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, Loss: 0.7155: 100%|██████████| 300/300 [05:15<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize and train TabDDPM\n",
    "print(\"\\n# 5. Initialize and train TabDDPM\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tabddpm = TabDDPMAdapter(**config[\"tabddpm_params\"], device=device)\n",
    "print(\"Training TabDDPM model...\")\n",
    "tabddpm.fit(X, y)\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17e6ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 6. Generate synthetic data\n",
      "Generating 1000 synthetic samples...\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Debug - out_dict type: <class 'torch.Tensor'>\n",
      "Added target column 'Personal Loan' with 2 unique values\n",
      "Final columns in synthetic data: ['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg', 'Education', 'Mortgage', 'Securities Account', 'CD Account', 'Online', 'CreditCard', 'Personal Loan']\n",
      "Generated 1000 synthetic samples\n",
      "Synthetic data head:\n",
      "            ID        Age  Experience      Income       ZIP Code  Family  \\\n",
      "0  5499.900000  18.600000   -7.600000  245.600000  105385.400000       2   \n",
      "1  5499.900000  18.600000   -7.600000  245.600000  105385.400000       4   \n",
      "2  4504.194941  31.573985    6.991497  245.600000  103137.771163       4   \n",
      "3  3366.625321  60.249901   35.976439   63.533183   95312.209003       1   \n",
      "4  5499.900000  18.600000   -7.600000  245.600000     572.600000       2   \n",
      "\n",
      "  CCAvg  Education    Mortgage  Securities Account  CD Account  Online  \\\n",
      "0  2/60          3  698.500000                   1           0       1   \n",
      "1  5/10          3  698.500000                   1           1       0   \n",
      "2  3/10          1  698.500000                   1           1       0   \n",
      "3  6/20          2  209.940265                   1           1       1   \n",
      "4  2/33          2  698.500000                   1           0       1   \n",
      "\n",
      "   CreditCard  Personal Loan  \n",
      "0           1              1  \n",
      "1           0              0  \n",
      "2           0              0  \n",
      "3           1              0  \n",
      "4           1              0  \n"
     ]
    }
   ],
   "source": [
    "# 6. Generate synthetic data\n",
    "print(\"\\n# 6. Generate synthetic data\")\n",
    "n_samples = 1000  \n",
    "print(f\"Generating {n_samples} synthetic samples...\")\n",
    "synthetic_data = tabddpm.generate(n_samples)\n",
    "print(f\"Generated {len(synthetic_data)} synthetic samples\")\n",
    "print(\"Synthetic data head:\")\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689f0e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 7. Evaluate quality using TSTR and other metrics\n",
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 11:44:14,720 - INFO - Encoded categorical target with mapping: {0: 0, 1: 1}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:44:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-27 11:44:23,704 - INFO - Encoded categorical targets with mapping: {0: 0, 1: 1}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:44:32] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-27 11:44:32,681 - INFO - TabDDPM Evaluation Results:\n",
      "2025-04-27 11:44:32,683 - INFO - \n",
      "Likelihood Fitness Metrics:\n",
      "2025-04-27 11:44:32,684 - INFO -   - Lsyn (Synthetic Data Log-Likelihood): 22.8104\n",
      "2025-04-27 11:44:32,684 - INFO -   - Ltest (Real Data Log-Likelihood under Synthetic Model): -39.5063\n",
      "2025-04-27 11:44:32,685 - INFO - \n",
      "Statistical Similarity Metrics:\n",
      "2025-04-27 11:44:32,686 - INFO -   - Jensen-Shannon Divergence Mean (Categorical): 0.2030\n",
      "2025-04-27 11:44:32,686 - INFO -   - Wasserstein Distance Mean (Numerical): 3436.5914\n",
      "2025-04-27 11:44:32,687 - INFO - \n",
      "Machine Learning Efficacy Metrics on Real Data:\n",
      "2025-04-27 11:44:32,688 - INFO -   LogisticRegression:\n",
      "2025-04-27 11:44:32,689 - INFO -     - Accuracy: 0.9750\n",
      "2025-04-27 11:44:32,690 - INFO -     - F1: 0.9741\n",
      "2025-04-27 11:44:32,690 - INFO -   RandomForest:\n",
      "2025-04-27 11:44:32,691 - INFO -     - Accuracy: 0.9850\n",
      "2025-04-27 11:44:32,692 - INFO -     - F1: 0.9846\n",
      "2025-04-27 11:44:32,692 - INFO -   MLP:\n",
      "2025-04-27 11:44:32,694 - INFO -     - Accuracy: 0.9940\n",
      "2025-04-27 11:44:32,694 - INFO -     - F1: 0.9939\n",
      "2025-04-27 11:44:32,695 - INFO -   XGBoost:\n",
      "2025-04-27 11:44:32,697 - INFO -     - Accuracy: 0.9900\n",
      "2025-04-27 11:44:32,697 - INFO -     - F1: 0.9899\n",
      "2025-04-27 11:44:32,699 - INFO - \n",
      "Machine Learning Utility using TSTR Approach:\n",
      "2025-04-27 11:44:32,700 - INFO -   LogisticRegression:\n",
      "2025-04-27 11:44:32,701 - INFO -     - Accuracy: 0.7592\n",
      "2025-04-27 11:44:32,702 - INFO -     - F1: 0.7978\n",
      "2025-04-27 11:44:32,703 - INFO -   RandomForest:\n",
      "2025-04-27 11:44:32,704 - INFO -     - Accuracy: 0.7706\n",
      "2025-04-27 11:44:32,706 - INFO -     - F1: 0.8026\n",
      "2025-04-27 11:44:32,706 - INFO -   MLP:\n",
      "2025-04-27 11:44:32,706 - INFO -     - Accuracy: 0.6070\n",
      "2025-04-27 11:44:32,708 - INFO -     - F1: 0.6877\n",
      "2025-04-27 11:44:32,708 - INFO -   XGBoost:\n",
      "2025-04-27 11:44:32,710 - INFO -     - Accuracy: 0.7010\n",
      "2025-04-27 11:44:32,711 - INFO -     - F1: 0.7580\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate quality using TSTR and other metrics\n",
    "print(\"\\n# 7. Evaluate quality using TSTR and other metrics\")\n",
    "print(\"Running evaluation...\")\n",
    "evaluation_results = evaluate_tabddpm(data, synthetic_data, target_column=target_column)\n",
    "print_evaluation_results(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099a3b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 8. TSTR Performance Results\n",
      "                    Accuracy        F1\n",
      "LogisticRegression    0.7592  0.797765\n",
      "RandomForest          0.7706  0.802595\n",
      "MLP                   0.6070  0.687718\n",
      "XGBoost               0.7010  0.758006\n"
     ]
    }
   ],
   "source": [
    "# 8. Extract and display TSTR results specifically\n",
    "print(\"\\n# 8. TSTR Performance Results\")\n",
    "tstr_results = get_tstr_results(evaluation_results)\n",
    "if tstr_results is not None:\n",
    "    print(tstr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "705fec44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 9. Save synthetic data\n",
      "Synthetic data saved to Loan_synthetic.csv\n",
      "\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9. Save the synthetic data\n",
    "print(\"\\n# 9. Save synthetic data\")\n",
    "output_path = \"Loan_synthetic.csv\"\n",
    "synthetic_data.to_csv(output_path, index=False)\n",
    "print(f\"Synthetic data saved to {output_path}\")\n",
    "\n",
    "print(\"\\nTest completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit378",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
