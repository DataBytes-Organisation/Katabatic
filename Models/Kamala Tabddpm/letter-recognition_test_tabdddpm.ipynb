{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eec3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Direct imports from the same directory\n",
    "from tabddpm_adapter import TabDDPMAdapter\n",
    "from tabddpm_benchmark import evaluate_tabddpm, print_evaluation_results\n",
    "from tabddpm_utils import preprocess_data, get_tstr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3aae7628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load configuration\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(\"# Load configuration\")\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5ced15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1. Load and prepare the dataset\n",
      "Columns in dataset: ['letter', 'xbox ', 'ybox ', 'width ', 'height', 'onpix ', 'xbar ', 'ybar ', 'x2bar', 'y2bar ', 'xybar ', 'x2ybar', 'xy2bar', 'xedge ', 'xedgey', 'yedge ', 'yedgex']\n",
      "Dataset shape: (20000, 17)\n",
      "  letter  xbox   ybox   width   height  onpix   xbar   ybar   x2bar  y2bar   \\\n",
      "0      T      2      8       3       5       1      8     13      0       6   \n",
      "1      I      5     12       3       7       2     10      5      5       4   \n",
      "2      D      4     11       6       8       6     10      6      2       6   \n",
      "3      N      7     11       6       6       3      5      9      4       6   \n",
      "4      G      2      1       3       1       1      8      6      6       6   \n",
      "\n",
      "   xybar   x2ybar  xy2bar  xedge   xedgey  yedge   yedgex  \n",
      "0       6      10       8       0       8       0       8  \n",
      "1      13       3       9       2       8       4      10  \n",
      "2      10       3       7       3       7       3       9  \n",
      "3       4       4      10       6      10       2       8  \n",
      "4       6       5       9       1       7       5      10  \n"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare the dataset\n",
    "print(\"# 1. Load and prepare the dataset\")\n",
    "data_raw = pd.read_csv(\"letter-recognition.csv\")\n",
    "print(f\"Columns in dataset: {data_raw.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {data_raw.shape}\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8c23d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 12:47:10,218 - INFO - Converted letter to category type (has 26 unique values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 2. Preprocess data and detect categorical columns\n",
      "Detected categorical columns: ['letter']\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocess data and detect categorical columns\n",
    "print(\"\\n# 2. Preprocess data and detect categorical columns\")\n",
    "data, categorical_columns = preprocess_data(data_raw)\n",
    "print(f\"Detected categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bd505fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3. Define the target column for this dataset\n",
      "Target column: letter\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the target column for this dataset\n",
    "print(\"\\n# 3. Define the target column for this dataset\")\n",
    "target_column = \"letter\"\n",
    "print(f\"Target column: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3124fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 4. Split the data into features and target\n",
      "Features shape: (20000, 16)\n",
      "Target shape: (20000,)\n",
      "Target distribution:\n",
      "letter\n",
      "U    813\n",
      "D    805\n",
      "P    803\n",
      "T    796\n",
      "M    792\n",
      "A    789\n",
      "X    787\n",
      "Y    786\n",
      "Q    783\n",
      "N    783\n",
      "F    775\n",
      "G    773\n",
      "E    768\n",
      "B    766\n",
      "V    764\n",
      "L    761\n",
      "R    758\n",
      "I    755\n",
      "O    753\n",
      "W    752\n",
      "S    748\n",
      "J    747\n",
      "K    739\n",
      "C    736\n",
      "H    734\n",
      "Z    734\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Split the data into features and target\n",
    "print(\"\\n# 4. Split the data into features and target\")\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84961893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 5. Initialize and train TabDDPM\n",
      "Training TabDDPM model...\n",
      "Original data shape: (20000, 17), Target column: letter\n",
      "Added StandardScaler for 16 numerical columns\n",
      "Target 'letter' identified as categorical with 26 classes\n",
      "Class mapping: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "\n",
      "Preprocessing Summary:\n",
      "- Number of numerical features: 16\n",
      "- Number of categorical features: 0\n",
      "- Categorical columns: []\n",
      "- Target column: letter\n",
      "- Target type: Categorical\n",
      "- Number of target classes: 26\n",
      "X shape: (20000, 16), y shape: (20000,)\n",
      "X_tensor shape: torch.Size([20000, 16]), y_tensor shape: torch.Size([20000])\n",
      "X_tensor shape: torch.Size([20000, 16])\n",
      "y_tensor shape: torch.Size([20000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, Loss: 0.3208: 100%|██████████| 300/300 [07:26<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize and train TabDDPM\n",
    "print(\"\\n# 5. Initialize and train TabDDPM\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tabddpm = TabDDPMAdapter(**config[\"tabddpm_params\"], device=device)\n",
    "print(\"Training TabDDPM model...\")\n",
    "tabddpm.fit(X, y)\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe73a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 6. Generate synthetic data\n",
      "Generating 1000 synthetic samples...\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Debug - out_dict type: <class 'torch.Tensor'>\n",
      "Added target column 'letter' with 26 unique values\n",
      "Final columns in synthetic data: ['xbox ', 'ybox ', 'width ', 'height', 'onpix ', 'xbar ', 'ybar ', 'x2bar', 'y2bar ', 'xybar ', 'x2ybar', 'xy2bar', 'xedge ', 'xedgey', 'yedge ', 'yedgex', 'letter']\n",
      "Generated 1000 synthetic samples\n",
      "Synthetic data head:\n",
      "       xbox       ybox      width      height     onpix       xbar      ybar   \\\n",
      "0  10.273256  13.066230   8.174987   6.944760   4.849386   9.092016  3.710027   \n",
      "1   2.869403   3.610033   3.348009   5.667185   0.851724   7.721162  4.400609   \n",
      "2   5.739124   8.398993   8.156721   5.502726   6.389643  11.486719  6.060035   \n",
      "3   1.527788   4.733185   3.262411   3.360594   2.849169   6.039143  6.717039   \n",
      "4  16.500000  16.500000  16.500000  16.500000  16.500000  16.500000  3.769151   \n",
      "\n",
      "       x2bar     y2bar      xybar      x2ybar    xy2bar     xedge      xedgey  \\\n",
      "0   4.539234   3.730077   8.167404   4.252531  4.651276   4.119415   7.253772   \n",
      "1  15.003404   5.156135   7.072544  12.204756  7.168913   3.186474   9.297340   \n",
      "2   2.057648   5.809486  10.457743   1.906513  7.188980   1.664721   7.998496   \n",
      "3   1.587422  11.257764  11.179858   6.153670  7.710362   1.450060   7.718309   \n",
      "4   9.532634  -1.500000  -1.500000   3.070687 -1.500000  16.500000  16.500000   \n",
      "\n",
      "      yedge      yedgex letter  \n",
      "0   6.128731   8.598418      G  \n",
      "1   0.034942   8.027136      T  \n",
      "2   4.669725  10.842600      O  \n",
      "3   5.559671   6.595364      K  \n",
      "4  16.500000  16.500000      H  \n"
     ]
    }
   ],
   "source": [
    "# 6. Generate synthetic data\n",
    "print(\"\\n# 6. Generate synthetic data\")\n",
    "n_samples = 1000  \n",
    "print(f\"Generating {n_samples} synthetic samples...\")\n",
    "synthetic_data = tabddpm.generate(n_samples)\n",
    "print(f\"Generated {len(synthetic_data)} synthetic samples\")\n",
    "print(\"Synthetic data head:\")\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b9889da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 7. Evaluate quality using TSTR and other metrics\n",
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 13:16:55,090 - INFO - Encoded categorical target with mapping: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:18:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-27 13:18:28,746 - INFO - Encoded categorical targets with mapping: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [13:18:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-27 13:18:45,703 - INFO - TabDDPM Evaluation Results:\n",
      "2025-04-27 13:18:45,705 - INFO - \n",
      "Likelihood Fitness Metrics:\n",
      "2025-04-27 13:18:45,705 - INFO -   - Lsyn (Synthetic Data Log-Likelihood): -28.9488\n",
      "2025-04-27 13:18:45,707 - INFO -   - Ltest (Real Data Log-Likelihood under Synthetic Model): -30.4875\n",
      "2025-04-27 13:18:45,707 - INFO - \n",
      "Statistical Similarity Metrics:\n",
      "2025-04-27 13:18:45,709 - INFO -   - Wasserstein Distance Mean (Numerical): 1.5847\n",
      "2025-04-27 13:18:45,711 - INFO - \n",
      "Machine Learning Efficacy Metrics on Real Data:\n",
      "2025-04-27 13:18:45,711 - INFO -   LogisticRegression:\n",
      "2025-04-27 13:18:45,713 - INFO -     - Accuracy: 0.7823\n",
      "2025-04-27 13:18:45,713 - INFO -     - F1: 0.7808\n",
      "2025-04-27 13:18:45,715 - INFO -   RandomForest:\n",
      "2025-04-27 13:18:45,717 - INFO -     - Accuracy: 0.9627\n",
      "2025-04-27 13:18:45,718 - INFO -     - F1: 0.9628\n",
      "2025-04-27 13:18:45,720 - INFO -   MLP:\n",
      "2025-04-27 13:18:45,721 - INFO -     - Accuracy: 0.9527\n",
      "2025-04-27 13:18:45,723 - INFO -     - F1: 0.9528\n",
      "2025-04-27 13:18:45,725 - INFO -   XGBoost:\n",
      "2025-04-27 13:18:45,726 - INFO -     - Accuracy: 0.9623\n",
      "2025-04-27 13:18:45,728 - INFO -     - F1: 0.9622\n",
      "2025-04-27 13:18:45,728 - INFO - \n",
      "Machine Learning Utility using TSTR Approach:\n",
      "2025-04-27 13:18:45,730 - INFO -   LogisticRegression:\n",
      "2025-04-27 13:18:45,732 - INFO -     - Accuracy: 0.0212\n",
      "2025-04-27 13:18:45,732 - INFO -     - F1: 0.0215\n",
      "2025-04-27 13:18:45,735 - INFO -   RandomForest:\n",
      "2025-04-27 13:18:45,736 - INFO -     - Accuracy: 0.0386\n",
      "2025-04-27 13:18:45,737 - INFO -     - F1: 0.0370\n",
      "2025-04-27 13:18:45,738 - INFO -   MLP:\n",
      "2025-04-27 13:18:45,739 - INFO -     - Accuracy: 0.0358\n",
      "2025-04-27 13:18:45,740 - INFO -     - F1: 0.0340\n",
      "2025-04-27 13:18:45,741 - INFO -   XGBoost:\n",
      "2025-04-27 13:18:45,742 - INFO -     - Accuracy: 0.0428\n",
      "2025-04-27 13:18:45,743 - INFO -     - F1: 0.0398\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate quality using TSTR and other metrics\n",
    "print(\"\\n# 7. Evaluate quality using TSTR and other metrics\")\n",
    "print(\"Running evaluation...\")\n",
    "evaluation_results = evaluate_tabddpm(data, synthetic_data, target_column=target_column)\n",
    "print_evaluation_results(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4360c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 8. TSTR Performance Results\n",
      "                    Accuracy        F1\n",
      "LogisticRegression   0.02120  0.021474\n",
      "RandomForest         0.03855  0.036997\n",
      "MLP                  0.03580  0.033996\n",
      "XGBoost              0.04285  0.039795\n"
     ]
    }
   ],
   "source": [
    "# 8. Extract and display TSTR results specifically\n",
    "print(\"\\n# 8. TSTR Performance Results\")\n",
    "tstr_results = get_tstr_results(evaluation_results)\n",
    "if tstr_results is not None:\n",
    "    print(tstr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31aaa66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 9. Save synthetic data\n",
      "Synthetic data saved to letter_synthetic.csv\n",
      "\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9. Save the synthetic data\n",
    "print(\"\\n# 9. Save synthetic data\")\n",
    "output_path = \"letter_synthetic.csv\"\n",
    "synthetic_data.to_csv(output_path, index=False)\n",
    "print(f\"Synthetic data saved to {output_path}\")\n",
    "\n",
    "print(\"\\nTest completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit378",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
