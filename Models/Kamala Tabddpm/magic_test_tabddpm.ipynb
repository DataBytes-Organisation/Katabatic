{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acabba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "# Direct imports from the same directory\n",
    "from tabddpm_adapter import TabDDPMAdapter\n",
    "from tabddpm_benchmark import evaluate_tabddpm, print_evaluation_results\n",
    "from tabddpm_utils import preprocess_data, get_tstr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d74abef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Load configuration\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "print(\"# Load configuration\")\n",
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27efe55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1. Load and prepare the dataset\n",
      "Columns in dataset: ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
      "Dataset shape: (19020, 11)\n",
      "    fLength    fWidth   fSize   fConc  fConc1     fAsym  fM3Long  fM3Trans  \\\n",
      "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110   -8.2027   \n",
      "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238   -9.9574   \n",
      "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580  -45.2160   \n",
      "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633   -7.1513   \n",
      "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525   21.8393   \n",
      "\n",
      "    fAlpha     fDist class  \n",
      "0  40.0920   81.8828     g  \n",
      "1   6.3609  205.2610     g  \n",
      "2  76.9600  256.7880     g  \n",
      "3  10.4490  116.7370     g  \n",
      "4   4.6480  356.4620     g  \n"
     ]
    }
   ],
   "source": [
    "# 1. Load and prepare the dataset\n",
    "print(\"# 1. Load and prepare the dataset\")\n",
    "data_raw = pd.read_csv(\"magic.csv\")\n",
    "print(f\"Columns in dataset: {data_raw.columns.tolist()}\")\n",
    "print(f\"Dataset shape: {data_raw.shape}\")\n",
    "print(data_raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c77a8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 12:14:35,974 - INFO - Converted class to category type (has 2 unique values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 2. Preprocess data and detect categorical columns\n",
      "Detected categorical columns: ['class']\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocess data and detect categorical columns\n",
    "print(\"\\n# 2. Preprocess data and detect categorical columns\")\n",
    "data, categorical_columns = preprocess_data(data_raw)\n",
    "print(f\"Detected categorical columns: {categorical_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30b92dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 3. Define the target column for this dataset\n",
      "Target column: class\n"
     ]
    }
   ],
   "source": [
    "# 3. Define the target column for this dataset\n",
    "print(\"\\n# 3. Define the target column for this dataset\")\n",
    "target_column = \"class\"\n",
    "print(f\"Target column: {target_column}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76860cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 4. Split the data into features and target\n",
      "Features shape: (19020, 10)\n",
      "Target shape: (19020,)\n",
      "Target distribution:\n",
      "class\n",
      "g    12332\n",
      "h     6688\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Split the data into features and target\n",
    "print(\"\\n# 4. Split the data into features and target\")\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "608334fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 5. Initialize and train TabDDPM\n",
      "Training TabDDPM model...\n",
      "Original data shape: (19020, 11), Target column: class\n",
      "Added StandardScaler for 10 numerical columns\n",
      "Target 'class' identified as categorical with 2 classes\n",
      "Class mapping: {'g': 0, 'h': 1}\n",
      "\n",
      "Preprocessing Summary:\n",
      "- Number of numerical features: 10\n",
      "- Number of categorical features: 0\n",
      "- Categorical columns: []\n",
      "- Target column: class\n",
      "- Target type: Categorical\n",
      "- Number of target classes: 2\n",
      "X shape: (19020, 10), y shape: (19020,)\n",
      "X_tensor shape: torch.Size([19020, 10]), y_tensor shape: torch.Size([19020])\n",
      "X_tensor shape: torch.Size([19020, 10])\n",
      "y_tensor shape: torch.Size([19020])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299, Loss: 0.3395: 100%|██████████| 300/300 [09:02<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Initialize and train TabDDPM\n",
    "print(\"\\n# 5. Initialize and train TabDDPM\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tabddpm = TabDDPMAdapter(**config[\"tabddpm_params\"], device=device)\n",
    "print(\"Training TabDDPM model...\")\n",
    "tabddpm.fit(X, y)\n",
    "print(\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b5a6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 6. Generate synthetic data\n",
      "Generating 1000 synthetic samples...\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Sample timestep    0\n",
      "Debug - out_dict type: <class 'torch.Tensor'>\n",
      "Added target column 'class' with 2 unique values\n",
      "Final columns in synthetic data: ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'class']\n",
      "Generated 1000 synthetic samples\n",
      "Synthetic data head:\n",
      "      fLength      fWidth     fSize     fConc    fConc1       fAsym  \\\n",
      "0   23.132451   16.044517  2.416267  0.431629  0.219371   18.395814   \n",
      "1   28.297065   14.584512  2.587033  0.470330  0.252192   -0.097241   \n",
      "2  367.166350  112.722260  1.603100  0.980990  0.742690 -561.231780   \n",
      "3   84.187362   35.502132  3.477488  0.090964  0.047783   16.061834   \n",
      "4   25.330818   13.923141  2.481471  0.574524  0.346881  -19.612429   \n",
      "\n",
      "      fM3Long   fM3Trans     fAlpha       fDist class  \n",
      "0   15.157432  -6.794261  32.805569  122.770295     g  \n",
      "1    6.830813   7.925212  66.752890  123.728033     h  \n",
      "2  295.331100  73.834420  99.000000  -48.145240     g  \n",
      "3   71.851240 -24.395268  53.238708  180.083997     g  \n",
      "4  -25.375448   8.900878  44.261190  240.171278     g  \n"
     ]
    }
   ],
   "source": [
    "# 6. Generate synthetic data\n",
    "print(\"\\n# 6. Generate synthetic data\")\n",
    "n_samples = 1000  \n",
    "print(f\"Generating {n_samples} synthetic samples...\")\n",
    "synthetic_data = tabddpm.generate(n_samples)\n",
    "print(f\"Generated {len(synthetic_data)} synthetic samples\")\n",
    "print(\"Synthetic data head:\")\n",
    "print(synthetic_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7652994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 12:46:13,636 - INFO - Encoded categorical target with mapping: {'g': 0, 'h': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 7. Evaluate quality using TSTR and other metrics\n",
      "Running evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:46:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-27 12:46:28,979 - INFO - Encoded categorical targets with mapping: {'g': 0, 'h': 1}\n",
      "c:\\Users\\kamal\\OneDrive\\Documents\\Vilo\\DEAKIN\\TRIMESTER 1 2025\\SIT378 TEAM PROJECT B\\KatabaticGitRepo\\sit378\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:46:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2025-04-27 12:46:30,831 - INFO - TabDDPM Evaluation Results:\n",
      "2025-04-27 12:46:30,832 - INFO - \n",
      "Likelihood Fitness Metrics:\n",
      "2025-04-27 12:46:30,833 - INFO -   - Lsyn (Synthetic Data Log-Likelihood): -28.4363\n",
      "2025-04-27 12:46:30,833 - INFO -   - Ltest (Real Data Log-Likelihood under Synthetic Model): -32.2831\n",
      "2025-04-27 12:46:30,834 - INFO - \n",
      "Statistical Similarity Metrics:\n",
      "2025-04-27 12:46:30,834 - INFO -   - Wasserstein Distance Mean (Numerical): 88.2596\n",
      "2025-04-27 12:46:30,835 - INFO - \n",
      "Machine Learning Efficacy Metrics on Real Data:\n",
      "2025-04-27 12:46:30,836 - INFO -   LogisticRegression:\n",
      "2025-04-27 12:46:30,836 - INFO -     - Accuracy: 0.7931\n",
      "2025-04-27 12:46:30,837 - INFO -     - F1: 0.7867\n",
      "2025-04-27 12:46:30,837 - INFO -   RandomForest:\n",
      "2025-04-27 12:46:30,839 - INFO -     - Accuracy: 0.8780\n",
      "2025-04-27 12:46:30,839 - INFO -     - F1: 0.8759\n",
      "2025-04-27 12:46:30,839 - INFO -   MLP:\n",
      "2025-04-27 12:46:30,840 - INFO -     - Accuracy: 0.8736\n",
      "2025-04-27 12:46:30,840 - INFO -     - F1: 0.8708\n",
      "2025-04-27 12:46:30,841 - INFO -   XGBoost:\n",
      "2025-04-27 12:46:30,842 - INFO -     - Accuracy: 0.8772\n",
      "2025-04-27 12:46:30,842 - INFO -     - F1: 0.8755\n",
      "2025-04-27 12:46:30,843 - INFO - \n",
      "Machine Learning Utility using TSTR Approach:\n",
      "2025-04-27 12:46:30,844 - INFO -   LogisticRegression:\n",
      "2025-04-27 12:46:30,844 - INFO -     - Accuracy: 0.3973\n",
      "2025-04-27 12:46:30,845 - INFO -     - F1: 0.4046\n",
      "2025-04-27 12:46:30,845 - INFO -   RandomForest:\n",
      "2025-04-27 12:46:30,847 - INFO -     - Accuracy: 0.5297\n",
      "2025-04-27 12:46:30,847 - INFO -     - F1: 0.5402\n",
      "2025-04-27 12:46:30,849 - INFO -   MLP:\n",
      "2025-04-27 12:46:30,849 - INFO -     - Accuracy: 0.5666\n",
      "2025-04-27 12:46:30,850 - INFO -     - F1: 0.5725\n",
      "2025-04-27 12:46:30,850 - INFO -   XGBoost:\n",
      "2025-04-27 12:46:30,851 - INFO -     - Accuracy: 0.4974\n",
      "2025-04-27 12:46:30,851 - INFO -     - F1: 0.5086\n"
     ]
    }
   ],
   "source": [
    "# 7. Evaluate quality using TSTR and other metrics\n",
    "print(\"\\n# 7. Evaluate quality using TSTR and other metrics\")\n",
    "print(\"Running evaluation...\")\n",
    "evaluation_results = evaluate_tabddpm(data, synthetic_data, target_column=target_column)\n",
    "print_evaluation_results(evaluation_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd7ea224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 8. TSTR Performance Results\n",
      "                    Accuracy        F1\n",
      "LogisticRegression  0.397266  0.404562\n",
      "RandomForest        0.529706  0.540244\n",
      "MLP                 0.566614  0.572535\n",
      "XGBoost             0.497371  0.508637\n"
     ]
    }
   ],
   "source": [
    "# 8. Extract and display TSTR results specifically\n",
    "print(\"\\n# 8. TSTR Performance Results\")\n",
    "tstr_results = get_tstr_results(evaluation_results)\n",
    "if tstr_results is not None:\n",
    "    print(tstr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d4604c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# 9. Save synthetic data\n",
      "Synthetic data saved to magic_synthetic.csv\n",
      "\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# 9. Save the synthetic data\n",
    "print(\"\\n# 9. Save synthetic data\")\n",
    "output_path = \"magic_synthetic.csv\"\n",
    "synthetic_data.to_csv(output_path, index=False)\n",
    "print(f\"Synthetic data saved to {output_path}\")\n",
    "\n",
    "print(\"\\nTest completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sit378",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
