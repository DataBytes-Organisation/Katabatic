{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a01eff6",
   "metadata": {},
   "source": [
    "# Improved MedGAN Training with Better Synthetic Data and Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from data_loader import load_shuttle_data\n",
    "from medgan_model import Medgan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483731e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load and preprocess real shuttle data ---\n",
    "df = pd.read_csv(\"datasets/shuttle.csv\", header=None)  # Update path if needed\n",
    "X_real = df.iloc[:, :-1]\n",
    "y_real = df.iloc[:, -1]\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_real)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_real)\n",
    "\n",
    "# Split for classifier testing\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78988380",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load GAN Training Data ---\n",
    "X_train, X_test = load_shuttle_data(\"datasets/shuttle.csv\", test_size=0.2, normalize=True, n_shuffle=10)\n",
    "input_dim = X_train.shape[1]\n",
    "print(\"Data loaded for GAN training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Set Parameters ---\n",
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "\n",
    "print(f\"Parameters set: Epochs={n_epochs}, Batch Size={batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1e002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Train MedGAN ---\n",
    "\n",
    "medgan = Medgan(input_dim=input_dim, ae_loss_type='bce')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    np.random.shuffle(X_train)\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch = X_train[i:i+batch_size]\n",
    "        noise = np.random.normal(size=(batch.shape[0], medgan.random_dim))\n",
    "        ae_loss, d_loss, g_loss = medgan.train_step(batch, noise)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} completed\", end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Generate Synthetic Data (More samples) ---\n",
    "\n",
    "synthetic_data = medgan.generate_data(num_samples=5000)  # Generate 5000 samples\n",
    "synthetic_scaled = scaler.transform(synthetic_data)  # Scale similarly\n",
    "print(f\"Generated Synthetic Data Shape: {synthetic_scaled.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbce89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Classifier Evaluation on Improved Synthetic Data ---\n",
    "\n",
    "# Split synthetic data\n",
    "X_train_syn, X_test_syn, y_train_syn, y_test_syn = train_test_split(synthetic_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"MLP Classifier\": MLPClassifier(max_iter=300, random_state=42),\n",
    "    \"XGB Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=300, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_syn, y_train_syn)\n",
    "    y_pred = model.predict(X_test_real)\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test_real, y_pred),\n",
    "        \"Precision\": precision_score(y_test_real, y_pred, average='macro', zero_division=0),\n",
    "        \"Recall\": recall_score(y_test_real, y_pred, average='macro', zero_division=0),\n",
    "        \"F1 Score\": f1_score(y_test_real, y_pred, average='macro', zero_division=0)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nClassifier Evaluation on Real Data (Using Improved Synthetic Data):\\n\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
