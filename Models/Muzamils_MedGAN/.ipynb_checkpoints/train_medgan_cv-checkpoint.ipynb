{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c8d1f16",
   "metadata": {},
   "source": [
    "# Updated Train MedGAN with 5-Fold Cross Validation and 7 Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb145090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from data_loader import load_shuttle_data  # or load_nursery_data / load_letter_data\n",
    "from medgan_model import Medgan\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load your dataset\n",
    "csv_path = \"path/to/your/data.csv\"  # <-- Change this to your CSV file path\n",
    "X_train, X_test = load_shuttle_data(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f7aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "k_folds = 5\n",
    "n_runs = 7\n",
    "epochs = 50\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6629b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# To collect results across all runs\n",
    "all_ae_losses = []\n",
    "all_d_losses = []\n",
    "all_g_losses = []\n",
    "\n",
    "for run in range(n_runs):\n",
    "    print(f\"Starting Run {run+1}/{n_runs}\")\n",
    "\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=run)\n",
    "\n",
    "    run_ae_losses = []\n",
    "    run_d_losses = []\n",
    "    run_g_losses = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
    "        print(f\"  Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "\n",
    "        model = Medgan(input_dim=X_train.shape[1])\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            random_data = np.random.normal(size=(X_tr.shape[0], model.random_dim))\n",
    "\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                ae_loss, d_loss, g_loss = model.train_step(X_tr, random_data)\n",
    "\n",
    "            ae_vars = model.encoder.trainable_variables + model.decoder.trainable_variables\n",
    "            d_vars = model.discriminator.trainable_variables\n",
    "            g_vars = model.generator.trainable_variables\n",
    "\n",
    "            optimizer.apply_gradients(zip(tape.gradient(ae_loss, ae_vars), ae_vars))\n",
    "            optimizer.apply_gradients(zip(tape.gradient(d_loss, d_vars), d_vars))\n",
    "            optimizer.apply_gradients(zip(tape.gradient(g_loss, g_vars), g_vars))\n",
    "\n",
    "        # Evaluate after fold\n",
    "        random_data_val = np.random.normal(size=(X_val.shape[0], model.random_dim))\n",
    "        ae_loss_val, d_loss_val, g_loss_val = model.train_step(X_val, random_data_val)\n",
    "\n",
    "        run_ae_losses.append(ae_loss_val.numpy())\n",
    "        run_d_losses.append(d_loss_val.numpy())\n",
    "        run_g_losses.append(g_loss_val.numpy())\n",
    "\n",
    "    # After 5 folds\n",
    "    all_ae_losses.append(np.mean(run_ae_losses))\n",
    "    all_d_losses.append(np.mean(run_d_losses))\n",
    "    all_g_losses.append(np.mean(run_g_losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa5763",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final average across 7 runs\n",
    "final_ae_loss = np.mean(all_ae_losses)\n",
    "final_d_loss = np.mean(all_d_losses)\n",
    "final_g_loss = np.mean(all_g_losses)\n",
    "\n",
    "print(\"\\nFinal Results After 7 Runs with 5-Fold CV:\")\n",
    "print(f\"AE Loss: {final_ae_loss:.4f}\")\n",
    "print(f\"Discriminator Loss: {final_d_loss:.4f}\")\n",
    "print(f\"Generator Loss: {final_g_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
