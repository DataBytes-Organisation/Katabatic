{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802d27ba",
   "metadata": {},
   "source": [
    "# Final Clean Version: MedGAN Training with 5-Fold CV, 7 Runs, and Averaged Classifier Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b496bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from data_loader import load_shuttle_data\n",
    "from medgan_model import Medgan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb752604",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load and preprocess real shuttle data ---\n",
    "df = pd.read_csv(\"datasets/shuttle.csv\", header=None)  # <-- Change to your correct path\n",
    "X_real = df.iloc[:, :-1]\n",
    "y_real = df.iloc[:, -1]\n",
    "\n",
    "# Encode target once\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_real)\n",
    "\n",
    "# Normalize features once\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_real)\n",
    "\n",
    "# Train-test split on real data once\n",
    "X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cce98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load data without labels for GAN training ---\n",
    "X_train, X_test = load_shuttle_data(\"datasets/shuttle.csv\", test_size=0.2, normalize=True, n_shuffle=10)\n",
    "input_dim = X_train.shape[1]\n",
    "print(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Set Parameters ---\n",
    "k_folds = 5\n",
    "n_runs = 7\n",
    "n_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 0.0002\n",
    "\n",
    "print(f\"Parameters set: Folds={k_folds}, Runs={n_runs}, Epochs={n_epochs}, Batch Size={batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac395c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Training MedGAN with 5-Fold Cross Validation and 7 Times ---\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# To collect all results\n",
    "all_run_results = []\n",
    "\n",
    "for run in range(n_runs):\n",
    "    print(f\"\\n===== Starting Run {run+1}/{n_runs} =====\")\n",
    "    \n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=run)\n",
    "    \n",
    "    fold_results = defaultdict(list)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        print(f\"  --- Fold {fold+1}/{k_folds} ---\")\n",
    "        \n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        \n",
    "        # Initialize MedGAN model\n",
    "        medgan = Medgan(input_dim=input_dim, ae_loss_type='bce')\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # Train MedGAN\n",
    "        for epoch in range(n_epochs):\n",
    "            np.random.shuffle(X_tr)\n",
    "            for i in range(0, len(X_tr), batch_size):\n",
    "                batch = X_tr[i:i+batch_size]\n",
    "                noise = np.random.normal(size=(batch.shape[0], medgan.random_dim))\n",
    "                ae_loss, d_loss, g_loss = medgan.train_step(batch, noise)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{n_epochs} completed\", end=\"\\r\")\n",
    "        \n",
    "        # Generate synthetic data\n",
    "        synthetic_data = medgan.generate_data(num_samples=len(X_real))\n",
    "        synthetic_scaled = scaler.transform(synthetic_data)\n",
    "        \n",
    "        # Split synthetic data\n",
    "        X_train_syn, X_test_syn, y_train_syn, y_test_syn = train_test_split(synthetic_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Define classifiers\n",
    "        models = {\n",
    "            \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "            \"MLP Classifier\": MLPClassifier(max_iter=300, random_state=42),\n",
    "            \"XGB Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42),\n",
    "            \"Logistic Regression\": LogisticRegression(max_iter=300, random_state=42)\n",
    "        }\n",
    "        \n",
    "        # Evaluate classifiers\n",
    "        results = {}\n",
    "        for name, model in models.items():\n",
    "            model.fit(X_train_syn, y_train_syn)\n",
    "            y_pred = model.predict(X_test_real)\n",
    "            results[name] = {\n",
    "                \"Accuracy\": accuracy_score(y_test_real, y_pred),\n",
    "                \"Precision\": precision_score(y_test_real, y_pred, average='macro', zero_division=0),\n",
    "                \"Recall\": recall_score(y_test_real, y_pred, average='macro', zero_division=0),\n",
    "                \"F1 Score\": f1_score(y_test_real, y_pred, average='macro', zero_division=0)\n",
    "            }\n",
    "        \n",
    "        fold_results[fold] = results\n",
    "    \n",
    "    all_run_results.append(fold_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef251b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Final Averaging across all runs ---\n",
    "\n",
    "aggregate = {}\n",
    "\n",
    "for run in all_run_results:\n",
    "    for fold, model_scores in run.items():\n",
    "        for model, scores in model_scores.items():\n",
    "            if model not in aggregate:\n",
    "                aggregate[model] = {\"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": []}\n",
    "            for metric in scores:\n",
    "                aggregate[model][metric].append(scores[metric])\n",
    "\n",
    "# Average\n",
    "final_scores = {}\n",
    "for model, metrics in aggregate.items():\n",
    "    final_scores[model] = {metric: np.mean(values) for metric, values in metrics.items()}\n",
    "\n",
    "# Display\n",
    "final_df = pd.DataFrame(final_scores).T\n",
    "print(\"\\n===== Final Averaged Classifier Results Over 7 Runs =====\\n\")\n",
    "print(final_df)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
