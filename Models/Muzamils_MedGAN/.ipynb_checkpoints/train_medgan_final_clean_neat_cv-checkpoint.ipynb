{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56523374",
   "metadata": {},
   "source": [
    "# Train MedGAN with 5-Fold Cross Validation and 7 Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbaea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from data_loader import load_shuttle_data\n",
    "from medgan_model import Medgan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a726d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "csv_path = \"path/to/your/shuttle.csv\"  # <-- Replace with your dataset path\n",
    "X_train, X_test = load_shuttle_data(csv_path)\n",
    "print(\"Data loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb6573",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define parameters\n",
    "k_folds = 5\n",
    "n_runs = 7\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(\"Parameters set:\")\n",
    "print(f\"  Folds: {k_folds}\")\n",
    "print(f\"  Runs: {n_runs}\")\n",
    "print(f\"  Epochs per fold: {epochs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize lists to collect losses\n",
    "all_run_ae_losses = []\n",
    "all_run_d_losses = []\n",
    "all_run_g_losses = []\n",
    "\n",
    "# Start 7 runs\n",
    "for run in range(n_runs):\n",
    "    print(f\"\\n===== Starting Run {run+1} of {n_runs} =====\")\n",
    "    \n",
    "    # Prepare 5-Fold cross-validation\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=run)\n",
    "    \n",
    "    fold_ae_losses = []\n",
    "    fold_d_losses = []\n",
    "    fold_g_losses = []\n",
    "    \n",
    "    # Start folds\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
    "        print(f\"  - Fold {fold+1} of {k_folds}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        \n",
    "        # Initialize a fresh MedGAN model\n",
    "        model = Medgan(input_dim=X_train.shape[1])\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        \n",
    "        # Train model\n",
    "        for epoch in range(epochs):\n",
    "            random_data = np.random.normal(size=(X_tr.shape[0], model.random_dim))\n",
    "            \n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                ae_loss, d_loss, g_loss = model.train_step(X_tr, random_data)\n",
    "            \n",
    "            ae_vars = model.encoder.trainable_variables + model.decoder.trainable_variables\n",
    "            d_vars = model.discriminator.trainable_variables\n",
    "            g_vars = model.generator.trainable_variables\n",
    "            \n",
    "            optimizer.apply_gradients(zip(tape.gradient(ae_loss, ae_vars), ae_vars))\n",
    "            optimizer.apply_gradients(zip(tape.gradient(d_loss, d_vars), d_vars))\n",
    "            optimizer.apply_gradients(zip(tape.gradient(g_loss, g_vars), g_vars))\n",
    "        \n",
    "        # Validate model\n",
    "        random_data_val = np.random.normal(size=(X_val.shape[0], model.random_dim))\n",
    "        ae_loss_val, d_loss_val, g_loss_val = model.train_step(X_val, random_data_val)\n",
    "        \n",
    "        fold_ae_losses.append(ae_loss_val.numpy())\n",
    "        fold_d_losses.append(d_loss_val.numpy())\n",
    "        fold_g_losses.append(g_loss_val.numpy())\n",
    "    \n",
    "    # After all folds, average losses for this run\n",
    "    run_ae_loss = np.mean(fold_ae_losses)\n",
    "    run_d_loss = np.mean(fold_d_losses)\n",
    "    run_g_loss = np.mean(fold_g_losses)\n",
    "    \n",
    "    all_run_ae_losses.append(run_ae_loss)\n",
    "    all_run_d_losses.append(run_d_loss)\n",
    "    all_run_g_losses.append(run_g_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616bbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final average losses across all 7 runs\n",
    "final_ae_loss = np.mean(all_run_ae_losses)\n",
    "final_d_loss = np.mean(all_run_d_losses)\n",
    "final_g_loss = np.mean(all_run_g_losses)\n",
    "\n",
    "print(\"\"\"\n",
    "=======================================\n",
    "Final Results after 7 Runs and 5-Fold CV\n",
    "=======================================\"\"\")\n",
    "print(f\"Autoencoder Loss (AE): {final_ae_loss:.4f}\")\n",
    "print(f\"Discriminator Loss (D): {final_d_loss:.4f}\")\n",
    "print(f\"Generator Loss (G): {final_g_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
