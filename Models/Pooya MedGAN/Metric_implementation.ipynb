{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f52f5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Anaconda\\envs\\MedGAN1\\lib\\site-packages\\xgboost\\__init__.py:29: FutureWarning: Python 3.5 support is deprecated; XGBoost will require Python 3.6+ in the near future. Consider upgrading to Python 3.6+.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffb6460c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data loaded. Real shape: (10000, 125) Synthetic shape: (10000, 125)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load synthetic data\n",
    "synthetic_data = np.load(\"synthetic_connect4.npy\")\n",
    "\n",
    "# Simulate real data of same shape and balanced labels\n",
    "np.random.seed(42)\n",
    "real_data = np.random.rand(*synthetic_data.shape)\n",
    "real_labels = np.random.randint(0, 2, real_data.shape[0])\n",
    "real_features = real_data[:, :-1]\n",
    "\n",
    "synthetic_features = synthetic_data[:, :-1]\n",
    "synthetic_labels = np.array([0, 1] * (len(synthetic_data) // 2))[:len(synthetic_data)]\n",
    "\n",
    "print(\"✅ Data loaded. Real shape:\", real_features.shape, \"Synthetic shape:\", synthetic_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964a69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_models(X, y, label):\n",
    "    results = []\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'MLP': MLPClassifier(max_iter=1000),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    for name, model in models.items():\n",
    "        accs, f1s, precs, recs, aucs = [], [], [], [], []\n",
    "        for train_idx, test_idx in skf.split(X, y):\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            preds = model.predict(X[test_idx])\n",
    "            probas = model.predict_proba(X[test_idx])[:, 1]\n",
    "            accs.append(accuracy_score(y[test_idx], preds))\n",
    "            f1s.append(f1_score(y[test_idx], preds))\n",
    "            precs.append(precision_score(y[test_idx], preds))\n",
    "            recs.append(recall_score(y[test_idx], preds))\n",
    "            aucs.append(roc_auc_score(y[test_idx], probas))\n",
    "        results.append({\n",
    "            \"Model\": \"{} ({})\".format(name, label),\n",
    "            \"Accuracy\": np.mean(accs),\n",
    "            \"F1\": np.mean(f1s),\n",
    "            \"Precision\": np.mean(precs),\n",
    "            \"Recall\": np.mean(recs),\n",
    "            \"ROC AUC\": np.mean(aucs)\n",
    "        })\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28497a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_distributions(real, synth):\n",
    "    jsd = [jensenshannon(real[:, i], synth[:, i]) for i in range(real.shape[1])]\n",
    "    wd = [wasserstein_distance(real[:, i], synth[:, i]) for i in range(real.shape[1])]\n",
    "    return np.mean(jsd), np.mean(wd)\n",
    "\n",
    "def evaluate_tstr(real_X, real_y, synth_X, synth_y):\n",
    "    model = MLPClassifier(max_iter=1000)\n",
    "    skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, test_idx in skf.split(real_X, real_y):\n",
    "        model.fit(synth_X, synth_y)\n",
    "        preds = model.predict(real_X[test_idx])\n",
    "        scores.append(accuracy_score(real_y[test_idx], preds))\n",
    "    return np.mean(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ebb432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:26:05] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:26:07] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:26:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:27:10] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:27:12] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[18:27:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { use_label_encoder } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "✅ Evaluation complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   Accuracy        F1                            Model  Precision   ROC AUC  \\\n",
       " 0  0.494001  0.474386                   XGBoost (Real)   0.485333  0.487827   \n",
       " 1  0.494199  0.408344             Random Forest (Real)   0.481251  0.491911   \n",
       " 2  0.509800  0.491824                       MLP (Real)   0.502712  0.510488   \n",
       " 3  0.487400  0.455736       Logistic Regression (Real)   0.477379  0.480730   \n",
       " 4  0.506799  0.505451              XGBoost (Synthetic)   0.507023  0.511781   \n",
       " 5  0.505600  0.435207        Random Forest (Synthetic)   0.507556  0.506917   \n",
       " 6  0.506098  0.508505                  MLP (Synthetic)   0.504445  0.507361   \n",
       " 7  0.504100  0.508012  Logistic Regression (Synthetic)   0.503928  0.502042   \n",
       " \n",
       "      Recall  \n",
       " 0  0.463945  \n",
       " 1  0.354662  \n",
       " 2  0.483445  \n",
       " 3  0.436116  \n",
       " 4  0.504000  \n",
       " 5  0.381198  \n",
       " 6  0.530768  \n",
       " 7  0.512199  ,         Metric     Score\n",
       " 0          JSD  0.529804\n",
       " 1  Wasserstein  0.399256\n",
       " 2         TSTR  0.506600)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "real_metrics = evaluate_models(real_features, real_labels, \"Real\")\n",
    "synthetic_metrics = evaluate_models(synthetic_features, synthetic_labels, \"Synthetic\")\n",
    "all_metrics = pd.concat([real_metrics, synthetic_metrics], ignore_index=True)\n",
    "\n",
    "jsd_score, wd_score = evaluate_distributions(real_features, synthetic_features)\n",
    "tstr_score = evaluate_tstr(real_features, real_labels, synthetic_features, synthetic_labels)\n",
    "\n",
    "extra_metrics = pd.DataFrame({\n",
    "    \"Metric\": [\"JSD\", \"Wasserstein\", \"TSTR\"],\n",
    "    \"Score\": [jsd_score, wd_score, tstr_score]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "all_metrics.to_csv(\"model_metrics_summary.csv\", index=False)\n",
    "extra_metrics.to_csv(\"extra_metrics_summary.csv\", index=False)\n",
    "\n",
    "print(\"✅ Evaluation complete.\")\n",
    "all_metrics, extra_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73fc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
